{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Symbol recognition_pyTorchYolo_lightnet",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FenryrMKIII/objectDetection-detectron2/blob/master/Symbol_recognition_Detectron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRYl5_8tl6Rs",
        "colab_type": "text"
      },
      "source": [
        "# Optional : install some Python modules. Normally already available on colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTYmvl8IAOIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Install OpenCV lib\n",
        "# # necessary if OPENCV=1 option is chosen when compiling darknet\n",
        "\n",
        "# # First update\n",
        "# !apt-get update\n",
        "# !apt-get upgrade\n",
        "\n",
        "# # Then install bunch of stuff necessary to install opencv (don't know why, found that on internet)\n",
        "# !apt-get install build-essential\n",
        "# !apt-get install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev\n",
        "# !apt-get install libavcodec-dev libavformat-dev libswscale-d\n",
        "\n",
        "# # Eventually install opencv\n",
        "# !apt-get install libopencv-dev\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afrneaLXmHYj",
        "colab_type": "text"
      },
      "source": [
        "# Connect to google drive for storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3OG1P5v__k-",
        "colab_type": "code",
        "outputId": "a26ad809-b543-4ba1-c1c3-d1c914c56310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('gdrive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0NRj6HQ3Noj",
        "colab_type": "code",
        "outputId": "9fd1d367-b95d-4c61-fce0-243f4144cacf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Verify google drive's writing capabilities\n",
        "# may happen that colab connects to a \"shadow\" session impeding\n",
        "# data saving \n",
        "!touch \"/content/gdrive/My Drive/dataManagement/lightnet/backup/yalah.txt\"\n",
        "!ls \"/content/gdrive/My Drive/dataManagement/lightnet/backup/\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "touch: cannot touch '/content/gdrive/My Drive/dataManagement/lightnet/backup/yalah.txt': Transport endpoint is not connected\n",
            "ls: cannot access '/content/gdrive/My Drive/dataManagement/lightnet/backup/': Transport endpoint is not connected\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yqQnwq1rlB9",
        "colab_type": "text"
      },
      "source": [
        "# Check GPU capabilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ0t_V1lDtWh",
        "colab_type": "code",
        "outputId": "d70cc92f-c817-45fa-e5ba-f6b8c4571fd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# check you are on GPU\n",
        "# if command fails ... You are not on GPU !!\n",
        "\n",
        "!nvidia-smi\n",
        "# check cuda is installed\n",
        "!cat /proc/driver/nvidia/version # verify driver version\n",
        "!nvcc -V # verify cuda version"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Feb 10 17:02:28 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "NVRM version: NVIDIA UNIX x86_64 Kernel Module  418.67  Sat Apr  6 03:07:24 CDT 2019\n",
            "GCC version:  gcc version 4.9.x 20150123 (prerelease) (4.9.2_cos_gg_4.9.2-r200-ac6128e0a17a52f011797f33ac3e7d6273a9368d_4.9.2-r200) \n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYJA6gTpDDyN",
        "colab_type": "code",
        "outputId": "e7eb36bc-6bac-4b01-d74e-8c110db76677",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# check cuda version\n",
        "!/usr/local/cuda/bin/nvcc --version\n",
        "\n",
        "# check linux version\n",
        "!lsb_release -a"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n",
            "No LSB modules are available.\n",
            "Distributor ID:\tUbuntu\n",
            "Description:\tUbuntu 18.04.3 LTS\n",
            "Release:\t18.04\n",
            "Codename:\tbionic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKuVOr1HHBOd",
        "colab_type": "code",
        "outputId": "2ec00037-d9cf-4f31-f5c0-935348d2620b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# cuda is different from cuDNN\n",
        "# cuDNN stands for Deep Neural Networks !\n",
        "# Need to download cuDNN version applicable with installed cuda version !\n",
        "\n",
        "!mkdir -p \"/content/cudnn\" \n",
        "! cp -r \"/content/gdrive/My Drive/cuDNN/cudnn-10.0-linux-x64-v7.6.3.30.tgz\" \"/content/cudnn\"\n",
        "\n",
        "# cudnn archive was downloaded from nvidia cudnn website, requires free subscription to nvidia website\n",
        "# download archive for installed cuda version (see output cell above) and choose the \"linux library\" link (not the linux version specific)\n",
        "# to get a targz archive (not a deb !)\n",
        "\n",
        "%cd /content/cudnn\n",
        "!tar -xzvf cudnn-10.0-linux-x64-v7.6.3.30.tgz\n",
        "!cp cuda/include/cudnn.h /usr/local/cuda/include # required otherwise compilation of darknet wil fail\n",
        "!cp cuda/lib64/libcudnn* /usr/local/cuda/lib64 # same story !take care architecture dependent, here 64bits\n",
        "!chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn* # make file property adequate\n",
        "\n",
        "%cd /content"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat '/content/gdrive/My Drive/cuDNN/cudnn-10.0-linux-x64-v7.6.3.30.tgz': Transport endpoint is not connected\n",
            "/content/cudnn\n",
            "tar (child): cudnn-10.0-linux-x64-v7.6.3.30.tgz: Cannot open: No such file or directory\n",
            "tar (child): Error is not recoverable: exiting now\n",
            "tar: Child returned status 2\n",
            "tar: Error is not recoverable: exiting now\n",
            "cp: cannot stat 'cuda/include/cudnn.h': No such file or directory\n",
            "cp: cannot stat 'cuda/lib64/libcudnn*': No such file or directory\n",
            "chmod: cannot access '/usr/local/cuda/include/cudnn.h': No such file or directory\n",
            "chmod: cannot access '/usr/local/cuda/lib64/libcudnn*': No such file or directory\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WuJdsmErqq8",
        "colab_type": "text"
      },
      "source": [
        "# Download lightnet yolo implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKkqGssvGjwe",
        "colab_type": "code",
        "outputId": "b4b1f903-11cf-4ef6-cfb5-01ac24a69a55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git clone https://github.com/FenryrMKIII/objectDetection-lightnet.git\n",
        "%cd objectDetection-lightnet\n",
        "!sudo pip3 install -r develop.txt\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'objectDetection-lightnet'...\n",
            "remote: Enumerating objects: 2530, done.\u001b[K\n",
            "remote: Counting objects: 100% (2530/2530), done.\u001b[K\n",
            "remote: Compressing objects: 100% (866/866), done.\u001b[K\n",
            "remote: Total 2530 (delta 1649), reused 2522 (delta 1641), pack-reused 0\n",
            "Receiving objects: 100% (2530/2530), 5.74 MiB | 13.83 MiB/s, done.\n",
            "Resolving deltas: 100% (1649/1649), done.\n",
            "/content/objectDetection-lightnet\n",
            "Obtaining file:///content/objectDetection-lightnet (from -r develop.txt (line 13))\n",
            "Collecting brambox\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/70/b64e36c62dae1ebd5e721838f912d57e84f98dfbc76e15bbacb9af47c911/brambox-3.0.0-cp36-cp36m-manylinux2010_x86_64.whl (763kB)\n",
            "\u001b[K     |████████████████████████████████| 768kB 4.9MB/s \n",
            "\u001b[?25hCollecting pycodestyle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/0c/04a353e104d2f324f8ee5f4b32012618c1c86dd79e52a433b64fceed511b/pycodestyle-2.5.0-py2.py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from -r develop.txt (line 6)) (3.6.4)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.6/dist-packages (from -r develop.txt (line 7)) (1.8.5)\n",
            "Collecting sphinx_rtd_theme\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/b4/4df37087a1d36755e3a3bfd2a30263f358d2dea21938240fa02313d45f51/sphinx_rtd_theme-0.4.3-py2.py3-none-any.whl (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4MB 20.7MB/s \n",
            "\u001b[?25hCollecting recommonmark\n",
            "  Downloading https://files.pythonhosted.org/packages/94/de/334aaf73df8c0e77fb07f883d1e274344526196c137ef3479cb5e5aef086/recommonmark-0.6.0-py2.py3-none-any.whl\n",
            "Collecting nbsphinx\n",
            "  Downloading https://files.pythonhosted.org/packages/18/6b/52e25c46d8d815dcd6f70859cc468aa904b97a6e4d64e92a7cd9aa3afa4a/nbsphinx-0.5.1-py2.py3-none-any.whl\n",
            "Collecting sphinxcontrib-bibtex\n",
            "  Downloading https://files.pythonhosted.org/packages/60/de/831ec5de791ba30b842a26e27c479ed34259fb1823aa681d8028c551f4d0/sphinxcontrib_bibtex-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightnet==1.1.1->-r develop.txt (line 13)) (1.17.5)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from lightnet==1.1.1->-r develop.txt (line 13)) (0.5.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from lightnet==1.1.1->-r develop.txt (line 13)) (6.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from brambox->-r develop.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from brambox->-r develop.txt (line 2)) (0.25.3)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r develop.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r develop.txt (line 6)) (1.12.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r develop.txt (line 6)) (8.2.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r develop.txt (line 6)) (19.3.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->-r develop.txt (line 6)) (0.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->-r develop.txt (line 6)) (45.1.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r develop.txt (line 6)) (1.8.1)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx->-r develop.txt (line 7)) (1.2.0)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->-r develop.txt (line 7)) (2.11.1)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from sphinx->-r develop.txt (line 7)) (0.15.2)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->-r develop.txt (line 7)) (2.8.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx->-r develop.txt (line 7)) (2.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->-r develop.txt (line 7)) (2.21.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx->-r develop.txt (line 7)) (20.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx->-r develop.txt (line 7)) (0.7.12)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->-r develop.txt (line 7)) (2.1.3)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx->-r develop.txt (line 7)) (1.2.0)\n",
            "Collecting commonmark>=0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/92/dfd892312d822f36c55366118b95d914e5f16de11044a27cf10a7d71bbbf/commonmark-0.9.1-py2.py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from nbsphinx->-r develop.txt (line 10)) (5.0.4)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.6/dist-packages (from nbsphinx->-r develop.txt (line 10)) (4.3.3)\n",
            "Requirement already satisfied: nbconvert!=5.4 in /usr/local/lib/python3.6/dist-packages (from nbsphinx->-r develop.txt (line 10)) (5.6.1)\n",
            "Collecting pybtex-docutils>=0.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/97/066aa09efc1a1f969ffc6ca0e697787a3b8eb9e847a9b5973c0f73119318/pybtex_docutils-0.2.2-py2.py3-none-any.whl\n",
            "Collecting pybtex>=0.20\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/2a/11039970561f1bbc74fbaca89b59c26b398a0a70bba8caad553ac779b4f7/pybtex-0.22.2-py2.py3-none-any.whl (279kB)\n",
            "\u001b[K     |████████████████████████████████| 286kB 69.6MB/s \n",
            "\u001b[?25hCollecting oset>=0.1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/b1/a49498c699a3fda5d635cc1fa222ffc686ea3b5d04b84a3166c4cab0c57b/oset-0.1.3.tar.gz\n",
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.6/dist-packages (from torchvision->lightnet==1.1.1->-r develop.txt (line 13)) (1.4.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->brambox->-r develop.txt (line 2)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->brambox->-r develop.txt (line 2)) (2.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->sphinx->-r develop.txt (line 7)) (1.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->-r develop.txt (line 7)) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->-r develop.txt (line 7)) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->-r develop.txt (line 7)) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->-r develop.txt (line 7)) (2.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->sphinx->-r develop.txt (line 7)) (2.4.6)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->nbsphinx->-r develop.txt (line 10)) (2.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat->nbsphinx->-r develop.txt (line 10)) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat->nbsphinx->-r develop.txt (line 10)) (4.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets->nbsphinx->-r develop.txt (line 10)) (4.4.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert!=5.4->nbsphinx->-r develop.txt (line 10)) (0.6.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert!=5.4->nbsphinx->-r develop.txt (line 10)) (0.4.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert!=5.4->nbsphinx->-r develop.txt (line 10)) (3.1.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert!=5.4->nbsphinx->-r develop.txt (line 10)) (1.4.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert!=5.4->nbsphinx->-r develop.txt (line 10)) (0.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert!=5.4->nbsphinx->-r develop.txt (line 10)) (0.8.4)\n",
            "Collecting latexcodec>=1.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/8e/4f/6e7353dce0cfde419995117705035c4a0433a08aa7c49219ee589767766a/latexcodec-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML>=3.01 in /usr/local/lib/python3.6/dist-packages (from pybtex>=0.20->sphinxcontrib-bibtex->-r develop.txt (line 11)) (3.13)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert!=5.4->nbsphinx->-r develop.txt (line 10)) (0.5.1)\n",
            "Building wheels for collected packages: oset\n",
            "  Building wheel for oset (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oset: filename=oset-0.1.3-cp36-none-any.whl size=9661 sha256=50a9a3d169d530718c6484a4928e6740dc9076acee95fd2aba2cbbb2dba85418\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/87/c8/3dad2dca279f64fb68af5d9908c380fee2f16488a1b1da3499\n",
            "Successfully built oset\n",
            "\u001b[31mERROR: sphinxcontrib-bibtex 1.0.0 has requirement Sphinx>=2.0, but you'll have sphinx 1.8.5 which is incompatible.\u001b[0m\n",
            "Installing collected packages: brambox, pycodestyle, sphinx-rtd-theme, commonmark, recommonmark, nbsphinx, latexcodec, pybtex, pybtex-docutils, oset, sphinxcontrib-bibtex, lightnet\n",
            "  Running setup.py develop for lightnet\n",
            "Successfully installed brambox-3.0.0 commonmark-0.9.1 latexcodec-2.0.0 lightnet nbsphinx-0.5.1 oset-0.1.3 pybtex-0.22.2 pybtex-docutils-0.2.2 pycodestyle-2.5.0 recommonmark-0.6.0 sphinx-rtd-theme-0.4.3 sphinxcontrib-bibtex-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F725flTaUS8x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "044c80cc-4c21-4ebc-a3da-fa3e29b1fe7f"
      },
      "source": [
        "# check lightnetversion\n",
        "import lightnet\n",
        "print(lightnet.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DMm1UVXugPU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3154d75c-e228-4a0c-f331-13d45ae1b930"
      },
      "source": [
        "# in case changes are made to the repo\n",
        "%cd /content/objectDetection-lightnet\n",
        "!git pull\n",
        "%cd /content/objectDetection-lightnet/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/objectDetection-lightnet\n",
            "Already up to date.\n",
            "/content/objectDetection-lightnet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f3EN5kOkApgu"
      },
      "source": [
        "#Create training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjttXPT4A6qT",
        "colab_type": "code",
        "outputId": "b0f0df29-a011-49ef-c9b2-4315b55edc8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# create the dataset\n",
        "# using a homemade script to create \"overlayed\"\n",
        "# pictures. \n",
        "! git clone \"https://github.com/FenryrMKIII/objectDetection-overlay\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'objectDetection-overlay'...\n",
            "remote: Enumerating objects: 126, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/126)\u001b[K\rremote: Counting objects:   1% (2/126)\u001b[K\rremote: Counting objects:   2% (3/126)\u001b[K\rremote: Counting objects:   3% (4/126)\u001b[K\rremote: Counting objects:   4% (6/126)\u001b[K\rremote: Counting objects:   5% (7/126)\u001b[K\rremote: Counting objects:   6% (8/126)\u001b[K\rremote: Counting objects:   7% (9/126)\u001b[K\rremote: Counting objects:   8% (11/126)\u001b[K\rremote: Counting objects:   9% (12/126)\u001b[K\rremote: Counting objects:  10% (13/126)\u001b[K\rremote: Counting objects:  11% (14/126)\u001b[K\rremote: Counting objects:  12% (16/126)\u001b[K\rremote: Counting objects:  13% (17/126)\u001b[K\rremote: Counting objects:  14% (18/126)\u001b[K\rremote: Counting objects:  15% (19/126)\u001b[K\rremote: Counting objects:  16% (21/126)\u001b[K\rremote: Counting objects:  17% (22/126)\u001b[K\rremote: Counting objects:  18% (23/126)\u001b[K\rremote: Counting objects:  19% (24/126)\u001b[K\rremote: Counting objects:  20% (26/126)\u001b[K\rremote: Counting objects:  21% (27/126)\u001b[K\rremote: Counting objects:  22% (28/126)\u001b[K\rremote: Counting objects:  23% (29/126)\u001b[K\rremote: Counting objects:  24% (31/126)\u001b[K\rremote: Counting objects:  25% (32/126)\u001b[K\rremote: Counting objects:  26% (33/126)\u001b[K\rremote: Counting objects:  27% (35/126)\u001b[K\rremote: Counting objects:  28% (36/126)\u001b[K\rremote: Counting objects:  29% (37/126)\u001b[K\rremote: Counting objects:  30% (38/126)\u001b[K\rremote: Counting objects:  31% (40/126)\u001b[K\rremote: Counting objects:  32% (41/126)\u001b[K\rremote: Counting objects:  33% (42/126)\u001b[K\rremote: Counting objects:  34% (43/126)\u001b[K\rremote: Counting objects:  35% (45/126)\u001b[K\rremote: Counting objects:  36% (46/126)\u001b[K\rremote: Counting objects:  37% (47/126)\u001b[K\rremote: Counting objects:  38% (48/126)\u001b[K\rremote: Counting objects:  39% (50/126)\u001b[K\rremote: Counting objects:  40% (51/126)\u001b[K\rremote: Counting objects:  41% (52/126)\u001b[K\rremote: Counting objects:  42% (53/126)\u001b[K\rremote: Counting objects:  43% (55/126)\u001b[K\rremote: Counting objects:  44% (56/126)\u001b[K\rremote: Counting objects:  45% (57/126)\u001b[K\rremote: Counting objects:  46% (58/126)\u001b[K\rremote: Counting objects:  47% (60/126)\u001b[K\rremote: Counting objects:  48% (61/126)\u001b[K\rremote: Counting objects:  49% (62/126)\u001b[K\rremote: Counting objects:  50% (63/126)\u001b[K\rremote: Counting objects:  51% (65/126)\u001b[K\rremote: Counting objects:  52% (66/126)\u001b[K\rremote: Counting objects:  53% (67/126)\u001b[K\rremote: Counting objects:  54% (69/126)\u001b[K\rremote: Counting objects:  55% (70/126)\u001b[K\rremote: Counting objects:  56% (71/126)\u001b[K\rremote: Counting objects:  57% (72/126)\u001b[K\rremote: Counting objects:  58% (74/126)\u001b[K\rremote: Counting objects:  59% (75/126)\u001b[K\rremote: Counting objects:  60% (76/126)\u001b[K\rremote: Counting objects:  61% (77/126)\u001b[K\rremote: Counting objects:  62% (79/126)\u001b[K\rremote: Counting objects:  63% (80/126)\u001b[K\rremote: Counting objects:  64% (81/126)\u001b[K\rremote: Counting objects:  65% (82/126)\u001b[K\rremote: Counting objects:  66% (84/126)\u001b[K\rremote: Counting objects:  67% (85/126)\u001b[K\rremote: Counting objects:  68% (86/126)\u001b[K\rremote: Counting objects:  69% (87/126)\u001b[K\rremote: Counting objects:  70% (89/126)\u001b[K\rremote: Counting objects:  71% (90/126)\u001b[K\rremote: Counting objects:  72% (91/126)\u001b[K\rremote: Counting objects:  73% (92/126)\u001b[K\rremote: Counting objects:  74% (94/126)\u001b[K\rremote: Counting objects:  75% (95/126)\u001b[K\rremote: Counting objects:  76% (96/126)\u001b[K\rremote: Counting objects:  77% (98/126)\u001b[K\rremote: Counting objects:  78% (99/126)\u001b[K\rremote: Counting objects:  79% (100/126)\u001b[K\rremote: Counting objects:  80% (101/126)\u001b[K\rremote: Counting objects:  81% (103/126)\u001b[K\rremote: Counting objects:  82% (104/126)\u001b[K\rremote: Counting objects:  83% (105/126)\u001b[K\rremote: Counting objects:  84% (106/126)\u001b[K\rremote: Counting objects:  85% (108/126)\u001b[K\rremote: Counting objects:  86% (109/126)\u001b[K\rremote: Counting objects:  87% (110/126)\u001b[K\rremote: Counting objects:  88% (111/126)\u001b[K\rremote: Counting objects:  89% (113/126)\u001b[K\rremote: Counting objects:  90% (114/126)\u001b[K\rremote: Counting objects:  91% (115/126)\u001b[K\rremote: Counting objects:  92% (116/126)\u001b[K\rremote: Counting objects:  93% (118/126)\u001b[K\rremote: Counting objects:  94% (119/126)\u001b[K\rremote: Counting objects:  95% (120/126)\u001b[K\rremote: Counting objects:  96% (121/126)\u001b[K\rremote: Counting objects:  97% (123/126)\u001b[K\rremote: Counting objects:  98% (124/126)\u001b[K\rremote: Counting objects:  99% (125/126)\u001b[K\rremote: Counting objects: 100% (126/126)\u001b[K\rremote: Counting objects: 100% (126/126), done.\u001b[K\n",
            "remote: Compressing objects:   1% (1/96)\u001b[K\rremote: Compressing objects:   2% (2/96)\u001b[K\rremote: Compressing objects:   3% (3/96)\u001b[K\rremote: Compressing objects:   4% (4/96)\u001b[K\rremote: Compressing objects:   5% (5/96)\u001b[K\rremote: Compressing objects:   6% (6/96)\u001b[K\rremote: Compressing objects:   7% (7/96)\u001b[K\rremote: Compressing objects:   8% (8/96)\u001b[K\rremote: Compressing objects:   9% (9/96)\u001b[K\rremote: Compressing objects:  10% (10/96)\u001b[K\rremote: Compressing objects:  11% (11/96)\u001b[K\rremote: Compressing objects:  12% (12/96)\u001b[K\rremote: Compressing objects:  13% (13/96)\u001b[K\rremote: Compressing objects:  14% (14/96)\u001b[K\rremote: Compressing objects:  15% (15/96)\u001b[K\rremote: Compressing objects:  16% (16/96)\u001b[K\rremote: Compressing objects:  17% (17/96)\u001b[K\rremote: Compressing objects:  18% (18/96)\u001b[K\rremote: Compressing objects:  19% (19/96)\u001b[K\rremote: Compressing objects:  20% (20/96)\u001b[K\rremote: Compressing objects:  21% (21/96)\u001b[K\rremote: Compressing objects:  22% (22/96)\u001b[K\rremote: Compressing objects:  23% (23/96)\u001b[K\rremote: Compressing objects:  25% (24/96)\u001b[K\rremote: Compressing objects:  26% (25/96)\u001b[K\rremote: Compressing objects:  27% (26/96)\u001b[K\rremote: Compressing objects:  28% (27/96)\u001b[K\rremote: Compressing objects:  29% (28/96)\u001b[K\rremote: Compressing objects:  30% (29/96)\u001b[K\rremote: Compressing objects:  31% (30/96)\u001b[K\rremote: Compressing objects:  32% (31/96)\u001b[K\rremote: Compressing objects:  33% (32/96)\u001b[K\rremote: Compressing objects:  34% (33/96)\u001b[K\rremote: Compressing objects:  35% (34/96)\u001b[K\rremote: Compressing objects:  36% (35/96)\u001b[K\rremote: Compressing objects:  37% (36/96)\u001b[K\rremote: Compressing objects:  38% (37/96)\u001b[K\rremote: Compressing objects:  39% (38/96)\u001b[K\rremote: Compressing objects:  40% (39/96)\u001b[K\rremote: Compressing objects:  41% (40/96)\u001b[K\rremote: Compressing objects:  42% (41/96)\u001b[K\rremote: Compressing objects:  43% (42/96)\u001b[K\rremote: Compressing objects:  44% (43/96)\u001b[K\rremote: Compressing objects:  45% (44/96)\u001b[K\rremote: Compressing objects:  46% (45/96)\u001b[K\rremote: Compressing objects:  47% (46/96)\u001b[K\rremote: Compressing objects:  48% (47/96)\u001b[K\rremote: Compressing objects:  50% (48/96)\u001b[K\rremote: Compressing objects:  51% (49/96)\u001b[K\rremote: Compressing objects:  52% (50/96)\u001b[K\rremote: Compressing objects:  53% (51/96)\u001b[K\rremote: Compressing objects:  54% (52/96)\u001b[K\rremote: Compressing objects:  55% (53/96)\u001b[K\rremote: Compressing objects:  56% (54/96)\u001b[K\rremote: Compressing objects:  57% (55/96)\u001b[K\rremote: Compressing objects:  58% (56/96)\u001b[K\rremote: Compressing objects:  59% (57/96)\u001b[K\rremote: Compressing objects:  60% (58/96)\u001b[K\rremote: Compressing objects:  61% (59/96)\u001b[K\rremote: Compressing objects:  62% (60/96)\u001b[K\rremote: Compressing objects:  63% (61/96)\u001b[K\rremote: Compressing objects:  64% (62/96)\u001b[K\rremote: Compressing objects:  65% (63/96)\u001b[K\rremote: Compressing objects:  66% (64/96)\u001b[K\rremote: Compressing objects:  67% (65/96)\u001b[K\rremote: Compressing objects:  68% (66/96)\u001b[K\rremote: Compressing objects:  69% (67/96)\u001b[K\rremote: Compressing objects:  70% (68/96)\u001b[K\rremote: Compressing objects:  71% (69/96)\u001b[K\rremote: Compressing objects:  72% (70/96)\u001b[K\rremote: Compressing objects:  73% (71/96)\u001b[K\rremote: Compressing objects:  75% (72/96)\u001b[K\rremote: Compressing objects:  76% (73/96)\u001b[K\rremote: Compressing objects:  77% (74/96)\u001b[K\rremote: Compressing objects:  78% (75/96)\u001b[K\rremote: Compressing objects:  79% (76/96)\u001b[K\rremote: Compressing objects:  80% (77/96)\u001b[K\rremote: Compressing objects:  81% (78/96)\u001b[K\rremote: Compressing objects:  82% (79/96)\u001b[K\rremote: Compressing objects:  83% (80/96)\u001b[K\rremote: Compressing objects:  84% (81/96)\u001b[K\rremote: Compressing objects:  85% (82/96)\u001b[K\rremote: Compressing objects:  86% (83/96)\u001b[K\rremote: Compressing objects:  87% (84/96)\u001b[K\rremote: Compressing objects:  88% (85/96)\u001b[K\rremote: Compressing objects:  89% (86/96)\u001b[K\rremote: Compressing objects:  90% (87/96)\u001b[K\rremote: Compressing objects:  91% (88/96)\u001b[K\rremote: Compressing objects:  92% (89/96)\u001b[K\rremote: Compressing objects:  93% (90/96)\u001b[K\rremote: Compressing objects:  94% (91/96)\u001b[K\rremote: Compressing objects:  95% (92/96)\u001b[K\rremote: Compressing objects:  96% (93/96)\u001b[K\rremote: Compressing objects:  97% (94/96)\u001b[K\rremote: Compressing objects:  98% (95/96)\u001b[K\rremote: Compressing objects: 100% (96/96)\u001b[K\rremote: Compressing objects: 100% (96/96), done.\u001b[K\n",
            "Receiving objects:   0% (1/126)   \rReceiving objects:   1% (2/126)   \rReceiving objects:   2% (3/126)   \rReceiving objects:   3% (4/126)   \rReceiving objects:   4% (6/126)   \rReceiving objects:   5% (7/126)   \rReceiving objects:   6% (8/126)   \rReceiving objects:   7% (9/126)   \rReceiving objects:   8% (11/126)   \rReceiving objects:   9% (12/126)   \rReceiving objects:  10% (13/126)   \rReceiving objects:  11% (14/126)   \rReceiving objects:  12% (16/126)   \rReceiving objects:  13% (17/126)   \rReceiving objects:  14% (18/126)   \rReceiving objects:  15% (19/126)   \rReceiving objects:  16% (21/126)   \rReceiving objects:  17% (22/126)   \rReceiving objects:  18% (23/126)   \rReceiving objects:  19% (24/126)   \rReceiving objects:  20% (26/126)   \rReceiving objects:  21% (27/126)   \rReceiving objects:  22% (28/126)   \rReceiving objects:  23% (29/126)   \rReceiving objects:  24% (31/126)   \rReceiving objects:  25% (32/126)   \rReceiving objects:  26% (33/126)   \rReceiving objects:  27% (35/126)   \rReceiving objects:  28% (36/126)   \rReceiving objects:  29% (37/126)   \rReceiving objects:  30% (38/126)   \rReceiving objects:  31% (40/126)   \rReceiving objects:  32% (41/126)   \rReceiving objects:  33% (42/126)   \rReceiving objects:  34% (43/126)   \rReceiving objects:  35% (45/126)   \rReceiving objects:  36% (46/126)   \rReceiving objects:  37% (47/126)   \rReceiving objects:  38% (48/126)   \rReceiving objects:  39% (50/126)   \rReceiving objects:  40% (51/126)   \rReceiving objects:  41% (52/126)   \rReceiving objects:  42% (53/126)   \rReceiving objects:  43% (55/126)   \rReceiving objects:  44% (56/126)   \rReceiving objects:  45% (57/126)   \rReceiving objects:  46% (58/126)   \rReceiving objects:  47% (60/126)   \rReceiving objects:  48% (61/126)   \rReceiving objects:  49% (62/126)   \rReceiving objects:  50% (63/126)   \rReceiving objects:  51% (65/126)   \rReceiving objects:  52% (66/126)   \rReceiving objects:  53% (67/126)   \rReceiving objects:  54% (69/126)   \rReceiving objects:  55% (70/126)   \rReceiving objects:  56% (71/126)   \rReceiving objects:  57% (72/126)   \rReceiving objects:  58% (74/126)   \rReceiving objects:  59% (75/126)   \rReceiving objects:  60% (76/126)   \rReceiving objects:  61% (77/126)   \rReceiving objects:  62% (79/126)   \rReceiving objects:  63% (80/126)   \rReceiving objects:  64% (81/126)   \rReceiving objects:  65% (82/126)   \rReceiving objects:  66% (84/126)   \rReceiving objects:  67% (85/126)   \rReceiving objects:  68% (86/126)   \rReceiving objects:  69% (87/126)   \rremote: Total 126 (delta 36), reused 114 (delta 24), pack-reused 0\n",
            "Receiving objects:  70% (89/126)   \rReceiving objects:  71% (90/126)   \rReceiving objects:  72% (91/126)   \rReceiving objects:  73% (92/126)   \rReceiving objects:  74% (94/126)   \rReceiving objects:  75% (95/126)   \rReceiving objects:  76% (96/126)   \rReceiving objects:  77% (98/126)   \rReceiving objects:  78% (99/126)   \rReceiving objects:  79% (100/126)   \rReceiving objects:  80% (101/126)   \rReceiving objects:  81% (103/126)   \rReceiving objects:  82% (104/126)   \rReceiving objects:  83% (105/126)   \rReceiving objects:  84% (106/126)   \rReceiving objects:  85% (108/126)   \rReceiving objects:  86% (109/126)   \rReceiving objects:  87% (110/126)   \rReceiving objects:  88% (111/126)   \rReceiving objects:  89% (113/126)   \rReceiving objects:  90% (114/126)   \rReceiving objects:  91% (115/126)   \rReceiving objects:  92% (116/126)   \rReceiving objects:  93% (118/126)   \rReceiving objects:  94% (119/126)   \rReceiving objects:  95% (120/126)   \rReceiving objects:  96% (121/126)   \rReceiving objects:  97% (123/126)   \rReceiving objects:  98% (124/126)   \rReceiving objects:  99% (125/126)   \rReceiving objects: 100% (126/126)   \rReceiving objects: 100% (126/126), 2.51 MiB | 8.28 MiB/s, done.\n",
            "Resolving deltas:   0% (0/36)   \rResolving deltas:   2% (1/36)   \rResolving deltas:   5% (2/36)   \rResolving deltas:  11% (4/36)   \rResolving deltas:  30% (11/36)   \rResolving deltas:  36% (13/36)   \rResolving deltas:  41% (15/36)   \rResolving deltas:  47% (17/36)   \rResolving deltas:  61% (22/36)   \rResolving deltas:  66% (24/36)   \rResolving deltas:  69% (25/36)   \rResolving deltas: 100% (36/36)   \rResolving deltas: 100% (36/36), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_viC4JYBVWX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "1e4a8cf9-3f5a-4e01-88b5-6de89f637c0d"
      },
      "source": [
        "# in case changes are made to the repo\n",
        "%cd /content/objectDetection-lightnet/objectDetection-overlay\n",
        "!git pull\n",
        "%cd /content/objectDetection-lightnet/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/objectDetection-lightnet/objectDetection-overlay'\n",
            "/content\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "[Errno 2] No such file or directory: '/content/objectDetection-lightnet/'\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibQJGt2AA_Of",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "outputId": "2e53db7b-7712-4dac-9f90-031b62ebc385"
      },
      "source": [
        "# install albumentations\n",
        "!pip install -U git+https://github.com/albu/albumentations"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/albu/albumentations\n",
            "  Cloning https://github.com/albu/albumentations to /tmp/pip-req-build-jacvhz3c\n",
            "  Running command git clone -q https://github.com/albu/albumentations /tmp/pip-req-build-jacvhz3c\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.4) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.4) (1.4.1)\n",
            "Collecting imgaug<0.2.7,>=0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.4) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: opencv-python>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.4) (4.1.2.30)\n",
            "Requirement already satisfied, skipping upgrade: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.4.4) (0.16.2)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.4.4) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.4) (2.4)\n",
            "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.4) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.4) (6.2.2)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.4) (3.1.3)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.4) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.4) (4.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.4) (2.4.6)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.4) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.4) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.4) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.4) (45.1.0)\n",
            "Building wheels for collected packages: albumentations, imgaug\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.4-cp36-none-any.whl size=64202 sha256=6cdf0f787f93ae45ed9f6c77dc28451b8a191eaa18fa18a7827ebb6a1b4cc6bf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ob_9e7or/wheels/45/8b/e4/2837bbcf517d00732b8e394f8646f22b8723ac00993230188b\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.6-cp36-none-any.whl size=654020 sha256=2c9ad588dc0f3309ce2ece96ae6510690f41965e8dd1c4becbb06ba6485b7af0\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n",
            "Successfully built albumentations imgaug\n",
            "Installing collected packages: imgaug, albumentations\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.4.4 imgaug-0.2.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXwQQaE2BXr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create dataset with the tool\n",
        "!python3 objectDetection-overlay/overlay.py  -t \"overlay\" -o \"objectDetection-overlay/rawSymbols\" -b \"objectDetection-overlay/backGrounds\" --noAlpha"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIutbQXr1PJf",
        "colab_type": "code",
        "outputId": "be94e07f-53e8-4485-c9c0-045539e4d518",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# put dataset at appropriate location for training\n",
        "!rm -r data/images/valves/\n",
        "!mkdir --parents data/images/valves/\n",
        "!mv trainingSet/* data/images/valves/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'data/images/valves/': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgrnM2dKWG1-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2096b63f-7de4-4b54-af26-4be8dd25c241"
      },
      "source": [
        "# save trainingset to drive for possible further usage\n",
        "!mkdir \"/content/gdrive/My Drive/dataManagement/lightnet/backup/trainingSet\"\n",
        "!cp -r data/images/valves/. \"/content/gdrive/My Drive/dataManagement/lightnet/backup/trainingSet/.\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/gdrive/My Drive/dataManagement/lightnet/backup/trainingSet’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHE7EVxvZd_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bring back trainingSet from drive\n",
        "!mkdir --parents data/images/valves/\n",
        "!cp -rf --verbose \"/content/gdrive/My Drive/dataManagement/lightnet/backup/trainingSet/.\" data/images/valves/."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKv3h_yjNEyH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "353ab50b-9a72-417c-db66-ec71041b9d15"
      },
      "source": [
        "# install brambox\n",
        "pip install brambox "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: brambox in /usr/local/lib/python3.6/dist-packages (3.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from brambox) (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from brambox) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from brambox) (0.25.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->brambox) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->brambox) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->brambox) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj1vhAjSjs0j",
        "colab_type": "code",
        "outputId": "ce088c53-1f5a-4404-e243-add5be922438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        }
      },
      "source": [
        "# check some generated pictures along with bounding box\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import brambox\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "path = Path(r\"data/images/valves/\")\n",
        "\n",
        "anno = []\n",
        "images = []\n",
        "\n",
        "for file in path.iterdir():\n",
        "    if file.suffix == \".txt\":\n",
        "        anno.append(file)\n",
        "    elif file.suffix == \".png\":\n",
        "        images.append(file)\n",
        "\n",
        "def getImageDims(id):\n",
        "    root = Path(r\"data/images/valves/\")\n",
        "    im = Image.open(Path.joinpath(root, id + \".png\"))\n",
        "    width, height = im.size\n",
        "    return (width, height)\n",
        "\n",
        "class_label_map = [\"rob\", \"valve\"]\n",
        "samples = np.random.choice(np.arange(0,len(anno)), size = 3)\n",
        "samples = [anno[i] for i in samples]\n",
        "test = brambox.io.load(brambox.io.parser.annotation.DarknetParser(getImageDims, class_label_map), samples)\n",
        "\n",
        "drawer = brambox.util.BoxDrawer(\n",
        "    images=lambda img: Path.joinpath(path, img + \".png\"),  # Function to retrieve image path from image column name\n",
        "    boxes=test,\n",
        "    label=test.class_label,                 # Write class_label above boxes\n",
        ")\n",
        "\n",
        "vizu = True\n",
        "for i, thing in enumerate(drawer) :\n",
        "    plt.axis('off')\n",
        "    gdrivePath = Path(r\"/content/gdrive/My Drive/dataManagement/lightnet/backup/examplesBBOX\")\n",
        "    if not gdrivePath.exists():\n",
        "      gdrivePath.mkdir()\n",
        "    savePath = Path(r\"/content/gdrive/My Drive/dataManagement/lightnet/backup/examplesBBOX\").joinpath(str(i)+'.png')\n",
        "    cv2.imwrite(str(savePath), np.asarray(thing))\n",
        "\n",
        "    plt.imshow(np.asarray(thing))\n",
        "    if vizu : \n",
        "      plt.show()\n",
        "    \n",
        "    \n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAADnCAYAAAB43B+BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dfXAU9R0/8PcRUJSYGEGQByXo5Xiw\nSG0EJUREScwckZ90fOiInXZ0fpN0bGdiO4M6rVNjqx2mzLQ563Sazm+cqa221nGMlWSFBNBwQUTR\nRjDi3YkhIlIiYEIwgCH7+yPssne3D7d7e7d7e+/XTIbL7nd3v0nuPnyfvz5RFEFERNrGOZ0BIiK3\nY6AkIjLAQElEZICBkojIAAMlEZEBo0ApKr/C4bD82ufziYnn7fjy+XwZu7dbvhJ/Rp/PJ9bX16d8\nvSAIrvodKfPjpnzZ/TcLhUKO58Nq3tU+V1b+VrFYzLb7pPszCYKQUjq1Z/l8vrh4pvhSNV7rhJ7e\n3l4AQEdHh5XLAQDV1dWora3Fww8/rHreyr1Pnz6NCy+80HKeMmVwcBBFRUWorq5Ge3u7fLyjo0P+\n+e+5556kn7mpqQmtra1x1wDAqlWr5OvtyFe6JkyYEJefdPPl1r/jX/7yF1x77bVOZ0P2fztO4/9V\nXYihoSEUFhYafqaA5L+N2b9VdXV13HW7du3SvI/e++vhhx9GU1OTqWcn+uCDD+T3np7e3l45ZgGA\n3+9PSuPz+VBXV4fm5mb1m4iiqPcVZ/v27fK/UERhq6Dxv4BVBw4csHxtoqamJtvuJf3eKioqVH9e\nvWfZ/TtSy5cd7MybnX9HURTFurq6tO9h9+9eFEVx9qMb5S/p+1SuSbz+/fffV82n8quioiLuPtFo\nVPMZbW1tSccSf/5U3r/bt28X6+rq5HTS3wFA3POVv1O9+yV+fhLzqXyO3t/rn//8p5y/xHuLGrHQ\nVKDcuXNn3AMKCgrSfuMof6h8ofyDq70pEzU1NSW92dxI8WbzJOnvYBczAdKMTHymEu8nPcMo4Crf\n33V1dWI0GhXb2trigqHyvnrvocSAqry3VtBUI8UvKZ4lPkbty1SgTHwQEeU3vSCvF6gTg67av2rX\naAVAMyV+g/ilGgt9ov4URtWT4XAYlZWVetcRkc1KH2vVPd+7vtaxfKg92+fzQSu+SOeWLVuGrq6u\npPR61wJAKBRCQ0OD7r21GMQvn9pBS505RJQ+vcCnFfS0jhsFUbv1rq+19EwpwEmBbMeOHXHnfT7V\nOJWkp6dHThuNRlU7aOzEQEnkILXAl+2gZ5aUZ6MSrCiK8Pl8ciBLLOkpvxcEIakUqCxtKtNL/yp7\nqJctW4bHH38cZWVlaGtrS/tnTMRASZSDzp49i4KCgqw/12wpWBn8EgOh8vtgMJh0rTJIKtOrVauV\naTNRumSgJHIBo3a1RFKQNHudHXKxFJwuBkoiB8ViMfj9/pSCnVq74OxHN6L0sdasdeTkKwZKIoeY\n7bAxOucUn8+H2Y9udDobGcVFMYjIkm+++QaAepuh17BESUSmeL09Uo3lQCm1rRBR/nBj1d+MUCiE\n8vJy09dZrnozSBJRrtGazWOEbZSUdz755BOns0A5hoGSiMgAAyURkQEGSiIiAwyURPmqsdjpHOQM\n746jlN4EjQPO5oPILRIDIz8bKfNmoGwsHnsTNBbzzUEkkd77ciGiOP6c9LmhJN4KlMo/dGKJktUM\nSnDo0CHMmDHD6Wxkn1YwZJDU5LFAORD/r9o5onMGBwfzK1DqFRac/nzE1QIHXFfa9U6gdPObgMgl\nfE8OJi9i4abalvKzqmw+c/gz7J1ACTj+y6TcMnnyZKezkHXKrRRcJfGzq1c7dIC3AmUCV74hiJzU\nWAzxiSJ3lSJzgHcCZWK7BnD+DeGS/5XcJBaLobW1FYFAAMDYniWhUAiA/sIB0WgUZWVlpp/X0dGB\nqqoqa5l1mN7WqDnFzZ+DxmLtZgEX5Ns7gRJwxS80V/j9/qQPfyrBoKysDC0tLSgsLDT1vGPHjgEA\nfv/73+ORRx5BR0dHUhq3BdIXX3wRa9eu9UaQzAGubRaA1wIlZVQoFMKKFSuwZs0a09e+/fbbAIBH\nHnkEgPuCYjgcxrRp01BSUoIpU6YAANauXauZtrKyMpvZyw8ubhZgoMxDaqW5VFx77bVYtGiRpWuX\nLl2KUCiEQCCAsrIyeT3T+vr6uP2ZnXTixAmUlZWZbiYQBAGRSIQlz3S4vDboMyjmqp7k/6jktBde\neAH333+/bhqpKpfok08+wdy5c9Hf34/LL7887lwsFpPbYaPRqOp+05TbDOJX8hsGLFFSjpo9e7Zh\nGrUgacTv98ul3Wys4i91oPX09MQ1aUQiEQCQO9ukY7W1tYhGo4hEIvI1DOaZx0BJlAVazR1a1XW1\n4Ccd8/v9DI5ZxkBJBPXq2JtvvokVK1YkpZV6w81wW+cVmcNASXmrs7MTxcVjPayff/45Kisr0dbW\nhlWrVsklQLWS4KWXXgoA+POf/4yHHnpIt3Oss7MThw8fxl//+lcAYx0/LA3mHnbmUE5K5z2o15lD\n3sfOHCIbSLOWamtrsWHDBtXhS9K+9tK/giCgpaXF9FAntVk/UgePmtraWvl5ymFWlFkZLVGWPtaa\n8xumkztls0TpmSmMBMBaidL2PXNKH2tV/ZcoXTt37jRMEw6HbXve888/DyC1qZ3kbZYDZSwWUz0u\nlSB719fKX0ThcBiiKOKTTz6xfI/Tp08bpjl16pSle0sBVtkx86Mf/Ugz7fDwMLq7uw3v+9JLL+Gt\nt96Sv9f63FB2WP39Ww6UbBshMw4fPgyfz4e5c+fK877NePrppzF9+nQ5kKlVnU6dOoXXXnsN77zz\njun7nzx5EsDYMJ49e/bopu3p6cFFF12ERYsWYXh4WDftD37wA9xyyy3y9/zcOMvq79/Wzhy9ajZL\nlvnt7rvvljsgvv76a9Ptftu3b8f27dvxxhtvaKa588474fP5cOONN5rOX01NDYCxEsfBgwdx0UUX\naU5hrKurk38WaZaM0c9y/Phx1eMlJSWm80rZZ3uvtxQQpeljoiiynZIAnJ9ZEo1GEQgETC2IIQXI\nxIU1pLnZwWAQmzZtMkxjxO/3o7W11TD4SfeSeseNfhatgCj1cCvXBVUel/Kg/F4QBABAS0sLpzBm\nia293lq93Oz9JqsSB2hLQQKAvIBw4hAeozRO9Hrv379f9fjVV1+d1n3JPCu93hBFUe9L1fbt21WP\nz350o/x67NbJxymz2tra5Nd1dXViXV2dg7mx7j//+Y8oimJK+W9qahKbmppSvve+fftEURTFI0eO\nyMfeeOMN+fWHH34oiqIobt26VfX65uZm+fU333yT8nPJHbTi1zmqsdD2qrdUzZ796MacrHKfPHkS\nkyZNcjoblkklKEEQXLPOoxWrV68GADQ3N+Ps2bMoKCjQTBsIBBAMBjE0NGR65XWJ9Dfv7OzE8uXL\nAQC33nqratoFCxbgzJkz6OnpwXe/+13d+7700ku44oor4jp0KAdpRVDRQonSC4aGhkRRHCuZSaUU\nsyUWSiaVEEVRFN98803NdO3t7fLrHTt2iIcPH9a9r9F5NWolSsofrihRekUwGJTbxsy0T23cuBF3\n3HFHprKVtmwvyiC1B5WUlGB0dBTHjh3TLV1VVVWhs7MTU6ZMweLFizF+vP5bdNq0abbmV1qtXNLT\n06NaMpc6jJSdPm5arZ1sphVBxTwvUZohtQsODw/bnZ20VVRUOFoaduN7xW0lSqnGEo1Gxbq6urh2\nZulvJ51THsvV9menWSlRMlB62G9/+1vVD1MsFkv5Hps3b04rD8r3SjQaFUVx7D8W6Ustf1KgkAKC\nMnDYwW2BkrLLSqDkMmuUUW58r6gNDwqHwygqKsK8efNQUFCg23kUDocxOjqK5cuX47PPPsOcOXOy\nlXWygSsWxaD8sWPHDqezYKv+/n5ccMEFKe1SeeWVVwIYW/DXyzZv3ux0FlyBgTJPdXR0WN621osq\nKyuxcuVKxGIxXHPNNYjFYnED1xPT7tu3D7FYDDNmzIhLp3VNrrr99tudzoIrMFDmqVmzZmH69OlO\nZ8N1pCmMra2tuqMDgsGgnBYY6/Em7+LwoDw1b948AOdX6pZYXak7XR0dHa7ZgMvMcDAprRRUOe/a\nm1iizFN79+7Fxx9/nLTsVDAYdGQsoFuCZCpeeeUVp7NAWcYSZZ5KZRFcOm/37t3ya2ma5IYNG7Bu\n3bq4c1rKy8sN7+tGUr537dqlOxIglXvkMgbKPOWFN282qf2+1q1bp3kunfu6zejoKJYsWeJ0NhzF\nQElkgdS2W19fjzVr1gAYWx9ywYIFnttjZ9w4ttAxUBJZILXtKttz2ZHjXfyvwoN8Ph+eeOIJp7NB\n5BkMlB4kiiKefPJJAGOr3Eg7z4VCobgB0T6fDz6fD4IgxB2XxgTW19dDEAQsW7Ysi7l3v3A4jK++\n+srSrJzE3zXlCK1J4CIXxchZf/jDH3TPd3d3ixibxy+OHz9eNU1FRYXhc7q6ugzTZOu9YuU5VhfF\neOGFF+TXVtbDzCUdHR1OZ8F2VhbFYInSg37xi1/otpddd911KCgoQGlpKb799lvVNF1dXZnKXs5b\nu3YtBEFALBbDiRMn4kqI0iZgXrFy5Uqns+AKDJQeJIqiYfVuZGQEn332WZZy5D1aUxil3RTJW9jr\nTZQGTmHMD5ZLlGyQdq9c3NTNaa+//rr8uq+vTzfts88+K78eHR3NWJ7IflabRiyXKPk/p7skBker\ne6nnw74v9fX1WLduHb7++mucOHECwFhzBXB+cQ6tfbgBYP78+RgdHUVXVxduvvlm3bQSrf27U7nW\nSbNnz0ZBQQGi0ajlKYxu2ru8oaEB4XDY9HWsenuAFCR719fGvTZr586dtubLrdasWYPW1lasXbtW\nXuH8qquuAnB+cQ69D/dVV12FcePG4eabbzZMa8RNQUTLtm3bNLfuzRcMlB6gDIpmAuTx48fjvp87\ndy7Wr18vHy8pKbEngy4jTTVUknZ7lHZhrK2tRWtrq+oujOPHj4/bhbG2tlaezujF0ni+B0kA3DPH\nC7TaJK2UKs3YsWMHKioqdNNk671i5TnKPXOc4vZV5qUS9qZNmyxXvd22hJ6VPXPyo0TZWHzu34Gx\n140D8celczksMSiyQyc3uC2IJPriiy8giiJqamqczoqj8mMcpVpgTDxHRElmzpyJWbNmOZ0Nx+VH\noATOlSYH4gOjHEC9FSx9PtXaQ5JNmzaldZ9U5oBLHR5Gz3n66acN09lFmvtOlKr8qnqrnvNWkATG\nhrqkUvWuqamR11WUOicAyHvmRKNRAGMdHMFgUA4w0hJjv/rVr+LOC4KAsrKyuO0l7rnnHjmNJDHt\nf//7XyxatEg3jZ0OHDhg+z3J47QmgYteWhTjiSJRFEVx7McVz78+dzzXzX50o/xa+hmVx9Ts2rVL\nPHDggG4an8+ne175+8x0GiNm3pNDQ0Pi4OCg5UUxKLdZWRQjP0qU54iiiKlTp6K/v39sgLFOSTOd\nvUyyubx/fX09UPJ/5BLk7Ec3plSaHDduHPr7++Xxg4mi0SiWLl2qef3x48exePFiw+eUl5fjj3/8\nI37+859rpqmoqMBNN92UtXGckyZNAgCcOnUqK8+j3Jc/gfJcUDzyEAAU6QbJjz/+GOXl5QiFQnHL\n+ktVTLexMgzIKJiXlZXpriBUUlKCpqYmw+c0NTUZDttxw0pF3d3dWLRokdPZIJfKj0Bpoh2yvb0d\n1dXVAJL3d041SGZzZ726ujrLz9MKlqmMjwSQ0hjEqVOnppyfkZEReeB3NnR3d8uD6qPRKBYtWoSN\nGzfijjvuSPqd5sImYJQ5HHCu4v3338f3vvc909dJHSNeIs19zpQ9e/Zg4cKFad8nVwecU/ZxwLlN\nrARJAJ4LkkD8gOjNmzfj9ttvT/uep0+fRiQSwcKFC20Jknarr6/HggULUFtbiw0bNmR8WqK0oo00\nXTIUCsnTIpWjEgDIUyslUjrKLJYoybSBgQHs27cPN954o6nr3n333ZQ6gKxgidKYV+eim8USJWVF\ncXGxHCSNquYHDx7ExIkTMWXKlIwFyVyWjbner776Kt566y3ccsst+OlPf4rvf//7KV+b6lzvxYsX\no7hYZ7xyjmOgpLQkBsldu3ZhcHBQPu7F6W/hcBjTpk3D9OnTUVhYmPJ1agPoszHXu7S0FIFAQL+a\nrlwDIcGRI0cM53r39fXFBcrEESO5joGSbLVkyRKns5BxQ0NDctUtGo2irKwspeuk5d2UASRbIyQq\nKysxMDAgP6/89dvO52H1VpQr8iKd2716q5zGaGvexCaMnp4eO7LtGmyjJE/IdhulVDoEgNbWVjn4\nuXWsrabEFbSkkqVOCVNNX19f0uSFxCmvbsE2Ssp727Ztk2fczJ8/H6WlpRl5jhQMpTnyVjtKEvdw\naWhoiKu2xmIxRKNRRCIRABno9U4MhjYuFOO2AJkOlijJdf71r39hypQppq6ZMWOGvGq5tLiGtLiH\nlmz2emt12ji2HqXNC8WolSjdiiVK8oSKigrLHzqpStza2oqLL77Y5pyNaW5ulvfxTpXTC/Qqx2bK\n1AJiQgBN5z+TgwcPeqYzj4GSPCUYDGJ0dBT33XefqemTRpSdLlJ1vq2tDatWrUqpQ0aaAmm1DdPq\nrppAeutvXn755RgcHERRUZHpa2fNmoWzZ89a3kLCTVj1JtfJVjXOamnp66+/xqWXXmpLHpzaM6cq\nfJfmuY7KV0zfLxAIsOpNlEukvbIztRXspZdeGrcLYyAQQDAY1O3Q0dq/u7S0VO6sCQQCcrOBdE9l\nZ08gEEBLSwvWrFmTfs96lXY7pJVGgr6+Put5yQGWS5S7d+/21IBScg87SpR79+7Fd77zHd00uTSF\n0amdNlOVK505giDgkksuyV6JUto2gMiNvv32W6ezYLve9bXyPkZiitt9ULxIJGJpyTzLm4vl1KBa\nyrpQKARBEOJ6hxPHDGbK3r17cf3112fs/uFwWG5b3LJlS8rX2fHzS1sTkDVWa8H5swsjZVVDQwOC\nwWBcm122mmqUVW5pTKUgCLbuvqgs2aVKqoUpN1Fzu87OTqez4ArszCFPePvtt1X3+JFqPnbWgCor\nK+XAW1paGjeTRmsxiI6ODkyYMCHuX8BMZ44zs1yWL1/uyHPdhoGSPGHp0qUYHR3FuHHZqSRpTWHU\narvXGnAuCII8PTESicjzxyORCILBoNyzDmh36FDmcRwluY6ZHlSt92Iq4xMXLlyIadOmmc6fFU5O\nYTx69CgmT56c0WfkSq834LJxlGfOnMGePXsydfu8xo2uztNaZT2VANTf32/pmTt37sRNN91k6hon\npzBmOkjmg4wFygsuuIAfaMq4CRMmAMhuLWdkZATRaBRXXHEFLrnkkqw8MyUml0ZLhTR9URRFuQMr\nH7GNksgk1zQ7NRaj9NSLAIDeiWvHXj/Wit6JaxVp0gucRUVFntxd1CwGSiILtKYwAjC1LqVyvUnT\nUxgbB9ALxAVMACg99eLYjB29pdRMyPcgCTBQElkiDQFSDjuysnCvclFevV5v6XmRSEQ+J5MCZqLG\ngdxbcd2lGCiJskBrKbZgMJgUyJTjMBPPx43RTGHx3ZaWFgZKGzBQEmGsM2jevHk4fvy44WZh4XAY\nRUVFmD9/Pnw+H8aPN/4YZapjU65mKzUWy+tXrlu3LiPPzTecwkh0zokTJ1BWVobXX39dN93IyAjm\nzp2LCRMmuGK3QWVv9NmzZ+POpdu+2NbWpnve7ErvuYqBkghjPdlz5sxBLBbD/PnzEYvFNOdkr1ix\nAlu3bkUsFsPFF1+ctcU+tIhPFJ0bGlSMgt9eFncu3UC2atUq3fPr1q3DsmXL0npGLmDVmzzBriE7\nfr9fDnx6i3gopzDW1tamtQuj8jnS92rBNyk/jQPAY61A4wB8Pp881lEUxbHjsNbBZIbf78e9996b\n0We4Aacwkuu4fSsIN9Gb/53NRX0dn8IodWylMG7UVVMYiXLJli1bsHLlSgBji/5KM37UPPfcc3jw\nwQezlTVdRsHQ88ODlAHyXPND/Hl7ZioxUJIp0gdPWTWsra1FNBpFMBiUZ3FIA7KVaZO2S3VYd3c3\nSkpKAJyf971p0ybU1NTo7qw4c+ZMAMALL7yA+++/P+VdGLWWYCOLlEExsURp02B7Cave5DrZqsbt\n27cP8+bNA2BuD+rPPvsMc+bMMf08r5bu2tvbMXfuXK4eRO7i1Ban2ZKp3RP1SEFSuT4kAPT09CR1\niMyZMyduCqNUSqyvr8eCBQs0S41uD5KCIKCsrEyuEdTWjlXr/X6/HOQFQZCnUT711FN4/PHHEQwG\n4fP5UFdXJ//8Uvr6+np5yuWyZcvwt7/9zb5ahVap0eaFQQCWKMmFnChROkVqlujp6cGaNWvk41Kw\nVi4EHIlE5GaOSCQiX2NXABYEAQ888AAA4M4770RzczPKy8sxPDyM5cuXo7OzEyUlJVi4cCH27NmD\ne++9F88//zxmz56NpUuX4pFHHkFTUxMefvhhVFRU4Msvv8T+/ftRXl6OG264QQ6uXV1d6WdWZaUk\nucffAEuURCZkc51GrVqAmdKndMzv96ccHM1W9w8fPiyXJkOhEHbv3i23O0ul7UAggPnz56OhoUEO\n1pMmTYIoihAEAW1tbfIzBUHAU089JZcubQmSKlINkpbvzxIluY3bhweFw2EMDw+juroa7e3tqK6u\nzkDu7GFmiTRlUF22bBnuvfdeuelBqpb/+Mc/Vg12WR8elMI8dy0sURK5mBOdOVbaA6WSXywWi5ui\nuWHDBgDaG6hlVQbaIXVJ+wRrfKnavn271imitB04cCArzzly5Ijla9va2sRoNCpGo1GxqalJPq58\n7QZ1dXVZeU62/mZ2MIhfqrGQJUoiC8zuwqhFrXSmN3dcGouq7KHWY9cUxlOnTmHixIm23CsXsY2S\nXMftbZT56OTJk5g0aZLmecenMKYoFovh8OHDptsouXoQ5Y1//OMfttynt7fXlvtk22uvvZY3y6Jp\nsTqGk4GS8sYPf/hDW+5z8OBBfPXVV/j8889NXSct2xaLxWzJRyqU1XhpbKSRaDQKYGz+O41hGyWR\nSVabnZTjILNlwYIFpq8pKyuTS57jxo3Drbfeane2cg4DJZEFWlMY161bpxoItRbOyNQWERKrYzyl\nkud7771nZ3ZyFgMlkQVmd2HMdEBUc/r0abz33nsYHh7GpEmTMDIygptvvtnwupGREXkfoOuvvz7T\n2cwJDJSUlzo6OlBVVeV0NmwniiK+/PJLzJgxAxdeeKHmNg3btm3TrFIrN0srKCjISD5zDTtzKC9V\nVVWhvb0doVBI7mSROj7c1jOszM/u3bs1q/Fnz56Fz+fDjBkzDO+p1+4obSiWuFFZPmOJkvLWzJkz\n49rwpOp0pveZMSNxR0itKvyOHTtQUVFhyzNXrVolB+e1a9filltuseW+uYwlSspLHR0dlnqE7c7D\nF198oZtm9erVcYG7tbUVu3btynTW0NzcjObm5ritcPMZAyXlHUEQUFVVJW//oJXGTuFwOO77gwcP\noqqqCjNnztRcgq2jowNffvml/P2uXbtQW1uLJUuWoLVVe1MxSWdnp/yv8rWRt99+W369fPlyw/T5\ngIGS8k5LS4stadIxa9YshEIhxGIxfPTRR6ppJk6ciOnTp8vfL1myRH49d+5c+bVWUJeC3PLly+Ne\nG1m6dKlhmkytK+lWDJSUd5qbm7F161bDNK+++mrG8tDZ2YmGhgb4/X7DJcvefffdpGPKsZp2L93W\n398PQRB0ZxDl2/hKduZQXrrkkkvwwQcf4Pbbb9dMc/ToUVx//fX44IMP0n7eyZMn46rY0tCkV155\nBXfddVdS9buqqgpbtmxBZWUl3n//fQwMJK+/KG27cOjQIbz22mv45ptvDPOxcuVKw3bHyy+/XC5R\nP/DAA7jpppvkc4ODgygqKnJ+Pcps01p/TeR6lOSQTK9tuGXLFvn12EdAW2FhoS3PTPzM9Pf3p3zt\n/v37k4719PSIoji2/mVFRYXY1dWVXgY1bNu2TRRFURwaGtJN5/X1KFn1prxz4YUXAkBKPbpPPvkk\ngOSFLPTWjEyk1oY4ZcoU+Z719fXyeM7E+9bX18u7PirPzZ8/H8DYkKZMtBeGw2EcO3YMK1asUD2v\n1xHmSVoRVGSJkhySjdIJxtZaFZ977jnDdHbI9GfGzhLlp59+Ko6OjoodHR3yscQSZeLq8CxREnmI\nNJBaFEUcOXJE3p5VazaOtORYOsyUPu0gCIL88yhLs6ku73b11VfjJz/5Cf79738bdnrlCwZKyiuJ\ns27q6+vlbRyU7Axubuj4MLMbI3B+wHlxcfJuh3aPMc0F7PWmvPDpp5/immuuSTquNV1RCm7ZXDvS\nLsFgUB4yZGUNzNHRUYwbN1aGWrRokXx83759mDdvHsrKymzMbW5goKS8oBYksyWbK5pbcfz48ZTS\nTZs2DcePH8fkyZPx1Vdfxa0yNDAwkPJ91IyMjLh6/yIGSqIM8/v9OHz4sNPZ0FRSUpL2NVbuoeT2\nXnS2UVJO6erqSpo3rZbGaMjM/v37ceDAATuz5inKOebA2ID5THJzaRJgoKQcU1NTg7///e+6aV56\n6SWsXLlSN83s2bNxww032Jk1Tdnu9bbDyZMnIQgCDh065HRWXIFVb8opQ0NDAM73vEYiEQQCAQBj\nm2L5/X4888wzeOaZZ+LSNDQ0QBAEOU1BQQG2bduGK6+8Mq6jQxAEtLS0uGpNSif4/X74/X50d3en\ntBCw52kNsBQ54Jwcojd4ecKECeLdd9+te/19990nFhQU6KY5ceKEpbxZ9eCDD2b0/pmawigNNDea\nwphLsjrgPBerE5T7zpw5g5dfflk3zYsvvoiRkRHdNIWFhVntQJAGtmeCUZttOiZNmpSxezvB6ggE\ny4FSqu4QkTt9/PHHAIAPP/zQ4Zy4RyoLHquxHCjtXgOPiKwZHh7GiRMnko4fPXoUAHDdddeZut//\n/vc/HDp0yJPTF63OkmJnDlGOq66uxo4dO2y737Rp0+Lmvt9222223TtXcXgQkQdUVFRYmoOttV+P\nNNc73YHkXsFASeQRwWAQRyelpXMAAAXWSURBVI8exejoqGHa7u5uAOdXWtcyb948W/KW61j1JvKQ\nyZMny68jkQjGjRuHwsJCnDlzBsPDwygvL8fFF18ct9iFnosuuihTWc0pDJTkuNLHWtG7vtYw3ZYt\nWwxn3Cht2rQJNTU16WTNdaTtZrV2UxQEQe5oDQQCqKioUE2nVeXWku/b1jJQkiNKHxsbpiEFyFSC\npRQkjxw5gqlTp+qm3bNnj+eC5P79+zFjxgz4/X4MDw+rlvYikYg8+0iPUZWb4rGNkhzTu75WDphm\nTJ06VbNEJJW4Fi5cmFbe3Ojqq6+WA6BWlbihoQF79+7VvU9NTQ1WrVple/68jCVKcoRUekylyq1G\nKhENDAzErcLt5SriRx99hGuvvRYAcOzYMVx22WWq6dasWaN7n02bNqW0sRqdx0BJWWdUiux8KPXS\nYHFxcdyK3G4l7ZqYDilIAtAMkqn62c9+BmBsSp80W6WhoQGhUMgVW1e4DQMlOUKrJGmlKu5227Zt\nw6233up0NmS/+93v8Oyzz+JPf/oT/H5/XGBkkFTn7v+GiTxAGSQzuYBFqn75y19CFEWns5FTGCjJ\nFdhmRm7GQEmOKSoqkl9ns4Rz6tQpAMB7772XV1uvxmIxzf3LSR/bKCnrpGFBlz30z6Q2yd71tejr\n68vo8/fs2YPFixfn3QpYfr/fsEec1DFQkiOsDguyg9qSZPmCUxKtYdWb8s5tt92GrVu35uXGWStW\nrHA6CzmJJUrKS1xjkcxgiZKIyAADJRGRAQZKIiIDDJRERAbYmUOUYcrFdHOBIAiIRCLy95z/zRIl\nESVgkEyWGyXKxmKgccDpXBBZEolEHClRVlZWWrqOwTGZ5RJlKBSyMx/xGosTvgbOHyfKMW4MPO3t\n7U5nwRGxWMzSdZYDZSAQsHqpscaB+BIkAyZ5hNVSnt2qq6udzoIjNmzYYOk6n8GqLaonw+Gwa/7g\n5D19fX246qqrUk6fCyuc55Ldu3dbuu706dOauz66ilTokgpcygJY44Dqen/ubKPUKzGyrZIsSHVL\nXDq/uHBPTw+am5tNXfv6669j9erVmciWbcJVragEkmOJTmxxZ6AE4jLt8/nG1itklZtU+Hw+zVLQ\nXS8fll9bLSnlm3TaVFevXp1zw6FS4d5AifMBksvWkx6fz4fy8vK4Y3IJ8uVWef3LxDRkv82bN7s+\nSFZ21ALqux1rlird2UbJqndeM9tGSWSKomNYrq2eP55LbZQMhpQevd0c2VZJUmFMfKIopSY9dwZK\nIhsoA6JUcvDidrhkTriq1XSNmGMqPIxB4Ty2c1M6GCg9RhkcWcUEzp49C4Db4VJ6GCg9hsExXkFB\ngdNZIA9gGyW5XigUihvbJwgCysrK0No6VnoOBAKqQ1KUpevZj27koHOyjIHSY7TaJXM5QCQGyWAw\niFgsJq83oLY6Ty7/vOQ+DJQe5OUgIQVEv98Pv98fd4woU9hGSURkgIGSiMgAA6XH5eKwmJkzZzqd\nBaI4bKP0oFzv7eWQHnIbBkqPyaWASJQrWPUmIjLAQElEZICBkojIAAMlEZEBBkoiIgMMlEREBhgo\niYgMWA6UgiDYmQ8iIteyHCi5YgsR5QtWvYmIDDBQEhEZYKAkIjLAQEmU7xqL4/+VXktfxEBJRFAP\niI0D2c+HS3GZNaJ8pxYQpWMMlgBYoiQiMsRASZTPGovx61//Ou6QIAhsm0zAQEmU537zm98AOL+/\nEieTJGMbJVG+O1d6FJ8oYklSg6lA+c477+DGG2/MVF6IKNvyuLPGTDwzVfX+9ttvLWVITywWs+1e\nfX19tt3LTuFw2OksqHJrvtz6dyRvMRPPLFW9Z82ahY6ODiuXqurt7bXlPqdPn0YkErHlXnYaHBy0\n9fdlF7fmy81/x6KiIqezkWRoaAiFhYVOZyOJW39ffr/f9DWWAmVpaSlKS0utXEpElHN8oig6nQci\nIlfj8CAiIgMMlEREBhgoiYgMMFASERlgoCQiMsBASURk4P8DTF3YZ9ezd4QAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAADnCAYAAAB43B+BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAADnCAYAAAB43B+BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIhID7dqDFhn",
        "colab_type": "text"
      },
      "source": [
        "# Configure architecture, parameters, training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbHOflv005zp",
        "colab_type": "text"
      },
      "source": [
        "### Compute anchors on dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqMbGgAQv8Qp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "0a33855e-d4e9-491e-c1b1-0884cce1773b"
      },
      "source": [
        "# clone alexeyAB darknet\n",
        "!git clone https://github.com/AlexeyAB/darknet.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'darknet'...\n",
            "remote: Enumerating objects: 12441, done.\u001b[K\n",
            "Receiving objects:   0% (1/12441)   \rReceiving objects:   1% (125/12441)   \rReceiving objects:   2% (249/12441)   \rReceiving objects:   3% (374/12441)   \rReceiving objects:   4% (498/12441)   \rReceiving objects:   5% (623/12441)   \rReceiving objects:   6% (747/12441)   \rReceiving objects:   7% (871/12441)   \rReceiving objects:   8% (996/12441)   \rReceiving objects:   9% (1120/12441)   \rReceiving objects:  10% (1245/12441)   \rReceiving objects:  11% (1369/12441)   \rReceiving objects:  12% (1493/12441)   \rReceiving objects:  13% (1618/12441)   \rReceiving objects:  14% (1742/12441)   \rReceiving objects:  15% (1867/12441)   \rReceiving objects:  16% (1991/12441)   \rReceiving objects:  17% (2115/12441)   \rReceiving objects:  18% (2240/12441)   \rReceiving objects:  19% (2364/12441)   \rReceiving objects:  20% (2489/12441)   \rReceiving objects:  21% (2613/12441)   \rReceiving objects:  22% (2738/12441)   \rReceiving objects:  23% (2862/12441)   \rReceiving objects:  24% (2986/12441)   \rReceiving objects:  25% (3111/12441)   \rReceiving objects:  26% (3235/12441)   \rReceiving objects:  27% (3360/12441)   \rReceiving objects:  28% (3484/12441)   \rReceiving objects:  29% (3608/12441)   \rReceiving objects:  30% (3733/12441)   \rReceiving objects:  31% (3857/12441)   \rReceiving objects:  32% (3982/12441)   \rReceiving objects:  33% (4106/12441)   \rReceiving objects:  34% (4230/12441)   \rReceiving objects:  35% (4355/12441)   \rReceiving objects:  36% (4479/12441)   \rReceiving objects:  37% (4604/12441)   \rReceiving objects:  38% (4728/12441)   \rReceiving objects:  39% (4852/12441)   \rReceiving objects:  40% (4977/12441)   \rReceiving objects:  41% (5101/12441)   \rReceiving objects:  42% (5226/12441)   \rReceiving objects:  43% (5350/12441)   \rReceiving objects:  44% (5475/12441)   \rReceiving objects:  45% (5599/12441)   \rReceiving objects:  46% (5723/12441)   \rReceiving objects:  47% (5848/12441)   \rReceiving objects:  48% (5972/12441)   \rReceiving objects:  49% (6097/12441)   \rReceiving objects:  50% (6221/12441)   \rReceiving objects:  51% (6345/12441)   \rReceiving objects:  52% (6470/12441)   \rReceiving objects:  53% (6594/12441)   \rReceiving objects:  54% (6719/12441)   \rReceiving objects:  55% (6843/12441)   \rReceiving objects:  56% (6967/12441)   \rReceiving objects:  57% (7092/12441)   \rReceiving objects:  58% (7216/12441)   \rReceiving objects:  59% (7341/12441)   \rReceiving objects:  60% (7465/12441)   \rReceiving objects:  61% (7590/12441)   \rReceiving objects:  62% (7714/12441)   \rReceiving objects:  63% (7838/12441)   \rReceiving objects:  64% (7963/12441)   \rReceiving objects:  65% (8087/12441)   \rReceiving objects:  66% (8212/12441)   \rReceiving objects:  67% (8336/12441)   \rReceiving objects:  68% (8460/12441)   \rReceiving objects:  69% (8585/12441)   \rReceiving objects:  70% (8709/12441)   \rReceiving objects:  71% (8834/12441)   \rReceiving objects:  72% (8958/12441)   \rReceiving objects:  73% (9082/12441)   \rReceiving objects:  74% (9207/12441)   \rReceiving objects:  75% (9331/12441)   \rReceiving objects:  76% (9456/12441)   \rReceiving objects:  77% (9580/12441)   \rReceiving objects:  78% (9704/12441)   \rReceiving objects:  79% (9829/12441)   \rReceiving objects:  80% (9953/12441)   \rReceiving objects:  81% (10078/12441)   \rReceiving objects:  82% (10202/12441)   \rReceiving objects:  83% (10327/12441)   \rReceiving objects:  84% (10451/12441)   \rReceiving objects:  85% (10575/12441)   \rReceiving objects:  86% (10700/12441)   \rReceiving objects:  87% (10824/12441)   \rReceiving objects:  88% (10949/12441)   \rReceiving objects:  89% (11073/12441)   \rReceiving objects:  90% (11197/12441)   \rReceiving objects:  91% (11322/12441)   \rReceiving objects:  92% (11446/12441)   \rReceiving objects:  93% (11571/12441)   \rReceiving objects:  94% (11695/12441)   \rReceiving objects:  95% (11819/12441)   \rReceiving objects:  96% (11944/12441)   \rReceiving objects:  97% (12068/12441)   \rremote: Total 12441 (delta 0), reused 0 (delta 0), pack-reused 12441\u001b[K\n",
            "Receiving objects:  98% (12193/12441)   \rReceiving objects:  99% (12317/12441)   \rReceiving objects: 100% (12441/12441)   \rReceiving objects: 100% (12441/12441), 11.38 MiB | 23.40 MiB/s, done.\n",
            "Resolving deltas:   0% (0/8488)   \rResolving deltas:   1% (90/8488)   \rResolving deltas:   2% (170/8488)   \rResolving deltas:   3% (272/8488)   \rResolving deltas:   4% (357/8488)   \rResolving deltas:   5% (430/8488)   \rResolving deltas:   6% (529/8488)   \rResolving deltas:   7% (598/8488)   \rResolving deltas:   8% (700/8488)   \rResolving deltas:   9% (781/8488)   \rResolving deltas:  10% (864/8488)   \rResolving deltas:  11% (938/8488)   \rResolving deltas:  12% (1042/8488)   \rResolving deltas:  13% (1113/8488)   \rResolving deltas:  14% (1192/8488)   \rResolving deltas:  15% (1277/8488)   \rResolving deltas:  16% (1422/8488)   \rResolving deltas:  17% (1446/8488)   \rResolving deltas:  18% (1567/8488)   \rResolving deltas:  19% (1614/8488)   \rResolving deltas:  20% (1740/8488)   \rResolving deltas:  21% (1789/8488)   \rResolving deltas:  22% (1878/8488)   \rResolving deltas:  23% (1956/8488)   \rResolving deltas:  24% (2045/8488)   \rResolving deltas:  25% (2140/8488)   \rResolving deltas:  26% (2250/8488)   \rResolving deltas:  27% (2294/8488)   \rResolving deltas:  28% (2377/8488)   \rResolving deltas:  29% (2462/8488)   \rResolving deltas:  30% (2548/8488)   \rResolving deltas:  31% (2646/8488)   \rResolving deltas:  32% (2736/8488)   \rResolving deltas:  33% (2819/8488)   \rResolving deltas:  34% (2886/8488)   \rResolving deltas:  35% (3039/8488)   \rResolving deltas:  36% (3072/8488)   \rResolving deltas:  37% (3142/8488)   \rResolving deltas:  38% (3230/8488)   \rResolving deltas:  39% (3344/8488)   \rResolving deltas:  40% (3415/8488)   \rResolving deltas:  41% (3562/8488)   \rResolving deltas:  42% (3592/8488)   \rResolving deltas:  43% (3663/8488)   \rResolving deltas:  44% (3764/8488)   \rResolving deltas:  45% (3830/8488)   \rResolving deltas:  46% (3933/8488)   \rResolving deltas:  47% (3992/8488)   \rResolving deltas:  48% (4095/8488)   \rResolving deltas:  49% (4161/8488)   \rResolving deltas:  50% (4247/8488)   \rResolving deltas:  51% (4333/8488)   \rResolving deltas:  52% (4424/8488)   \rResolving deltas:  53% (4510/8488)   \rResolving deltas:  54% (4590/8488)   \rResolving deltas:  55% (4669/8488)   \rResolving deltas:  56% (4754/8488)   \rResolving deltas:  57% (4845/8488)   \rResolving deltas:  58% (4943/8488)   \rResolving deltas:  59% (5010/8488)   \rResolving deltas:  60% (5122/8488)   \rResolving deltas:  61% (5178/8488)   \rResolving deltas:  62% (5270/8488)   \rResolving deltas:  63% (5357/8488)   \rResolving deltas:  64% (5434/8488)   \rResolving deltas:  65% (5525/8488)   \rResolving deltas:  66% (5608/8488)   \rResolving deltas:  67% (5722/8488)   \rResolving deltas:  68% (5789/8488)   \rResolving deltas:  69% (5867/8488)   \rResolving deltas:  70% (5942/8488)   \rResolving deltas:  71% (6028/8488)   \rResolving deltas:  72% (6116/8488)   \rResolving deltas:  74% (6301/8488)   \rResolving deltas:  75% (6393/8488)   \rResolving deltas:  76% (6451/8488)   \rResolving deltas:  77% (6558/8488)   \rResolving deltas:  78% (6642/8488)   \rResolving deltas:  79% (6711/8488)   \rResolving deltas:  80% (6796/8488)   \rResolving deltas:  81% (6959/8488)   \rResolving deltas:  82% (6962/8488)   \rResolving deltas:  83% (7047/8488)   \rResolving deltas:  85% (7222/8488)   \rResolving deltas:  86% (7304/8488)   \rResolving deltas:  87% (7385/8488)   \rResolving deltas:  88% (7470/8488)   \rResolving deltas:  89% (7555/8488)   \rResolving deltas:  90% (7655/8488)   \rResolving deltas:  91% (7731/8488)   \rResolving deltas:  92% (7818/8488)   \rResolving deltas:  93% (7897/8488)   \rResolving deltas:  94% (8001/8488)   \rResolving deltas:  95% (8066/8488)   \rResolving deltas:  96% (8152/8488)   \rResolving deltas:  97% (8244/8488)   \rResolving deltas:  98% (8319/8488)   \rResolving deltas:  99% (8453/8488)   \rResolving deltas: 100% (8488/8488)   \rResolving deltas: 100% (8488/8488), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD-8P5e-0-hg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "768d1ef0-4d4b-4141-9fdf-a5abc0423022"
      },
      "source": [
        "%cd darknet\n",
        "!make"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/objectDetection-lightnet/darknet\n",
            "mkdir -p ./obj/\n",
            "mkdir -p backup\n",
            "mkdir -p results\n",
            "chmod +x *.sh\n",
            "g++ -std=c++11 -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/image_opencv.cpp -o obj/image_opencv.o\n",
            "g++ -std=c++11 -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/http_stream.cpp -o obj/http_stream.o\n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kbool JSON_sender::write(const char*)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:247:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "                 int \u001b[01;35m\u001b[Kn\u001b[m\u001b[K = _write(client, outputbuf, outlen);\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/gemm.c -o obj/gemm.o\n",
            "\u001b[01m\u001b[K./src/gemm.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kconvolution_2d\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/gemm.c:2039:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kout_w\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     const int \u001b[01;35m\u001b[Kout_w\u001b[m\u001b[K = (w + 2 * pad - ksize) / stride + 1;    // output_width=input_width for stride=1 and pad=1\n",
            "               \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/gemm.c:2038:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kout_h\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     const int \u001b[01;35m\u001b[Kout_h\u001b[m\u001b[K = (h + 2 * pad - ksize) / stride + 1;    // output_height=input_height for stride=1 and pad=1\n",
            "               \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/utils.c -o obj/utils.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/dark_cuda.c -o obj/dark_cuda.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/convolutional_layer.c -o obj/convolutional_layer.o\n",
            "\u001b[01m\u001b[K./src/convolutional_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kresize_convolutional_layer\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/convolutional_layer.c:758:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kold_h\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     int \u001b[01;35m\u001b[Kold_h\u001b[m\u001b[K = l->h;\n",
            "         \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/convolutional_layer.c:757:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kold_w\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     int \u001b[01;35m\u001b[Kold_w\u001b[m\u001b[K = l->w;\n",
            "         \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/convolutional_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kforward_convolutional_layer\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/convolutional_layer.c:1202:32:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kt_intput_size\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "                         size_t \u001b[01;35m\u001b[Kt_intput_size\u001b[m\u001b[K = binary_transpose_align_input(k, n, state.workspace, &l.t_bit_input, ldb_align, l.bit_align);\n",
            "                                \u001b[01;35m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/list.c -o obj/list.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/image.c -o obj/image.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/activations.c -o obj/activations.o\n",
            "\u001b[01m\u001b[K./src/activations.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kactivate\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/activations.c:73:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KSWISH\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kswitch\u001b[m\u001b[K(a){\n",
            "     \u001b[01;35m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/activations.c:73:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KMISH\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "\u001b[01m\u001b[K./src/activations.c:73:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KNORM_CHAN\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "\u001b[01m\u001b[K./src/activations.c:73:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KNORM_CHAN_SOFTMAX\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "\u001b[01m\u001b[K./src/activations.c:73:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KNORM_CHAN_SOFTMAX_MAXVAL\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "\u001b[01m\u001b[K./src/activations.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kgradient\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/activations.c:281:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KSWISH\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kswitch\u001b[m\u001b[K(a){\n",
            "     \u001b[01;35m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/activations.c:281:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KMISH\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/im2col.c -o obj/im2col.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/col2im.c -o obj/col2im.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/blas.c -o obj/blas.o\n",
            "\u001b[01m\u001b[K./src/blas.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kbackward_shortcut_multilayer_cpu\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/blas.c:205:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kout_index\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "                 int \u001b[01;35m\u001b[Kout_index\u001b[m\u001b[K = id;\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/crop_layer.c -o obj/crop_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/dropout_layer.c -o obj/dropout_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/maxpool_layer.c -o obj/maxpool_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/softmax_layer.c -o obj/softmax_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/data.c -o obj/data.o\n",
            "\u001b[01m\u001b[K./src/data.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kload_data_detection\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/data.c:1266:19:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kscale\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "             float \u001b[01;35m\u001b[Kscale\u001b[m\u001b[K = rand_precalc_random(.25, 2, r_scale); // unused currently\n",
            "                   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/data.c:1266:19:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kr_scale\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
            "             float \u001b[01;35m\u001b[Kscale\u001b[m\u001b[K = rand_precalc_random(.25, 2, r_scale); // unused currently\n",
            "                   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/matrix.c -o obj/matrix.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/network.c -o obj/network.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/connected_layer.c -o obj/connected_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/cost_layer.c -o obj/cost_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/parser.c -o obj/parser.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/option_list.c -o obj/option_list.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/darknet.c -o obj/darknet.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/detection_layer.c -o obj/detection_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/captcha.c -o obj/captcha.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/route_layer.c -o obj/route_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/writing.c -o obj/writing.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/box.c -o obj/box.o\n",
            "\u001b[01m\u001b[K./src/box.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kdiounms_sort\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/box.c:886:27:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kbeta_prob\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "                     float \u001b[01;35m\u001b[Kbeta_prob\u001b[m\u001b[K = pow(dets[j].prob[k], 2) / sum_prob;\n",
            "                           \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/box.c:885:27:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kalpha_prob\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "                     float \u001b[01;35m\u001b[Kalpha_prob\u001b[m\u001b[K = pow(dets[i].prob[k], 2) / sum_prob;\n",
            "                           \u001b[01;35m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/nightmare.c -o obj/nightmare.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/normalization_layer.c -o obj/normalization_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/avgpool_layer.c -o obj/avgpool_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/coco.c -o obj/coco.o\n",
            "\u001b[01m\u001b[K./src/coco.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvalidate_coco_recall\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/coco.c:248:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kbase\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     char *\u001b[01;35m\u001b[Kbase\u001b[m\u001b[K = \"results/comp4_det_test_\";\n",
            "           \u001b[01;35m\u001b[K^~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/dice.c -o obj/dice.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/yolo.c -o obj/yolo.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/detector.c -o obj/detector.o\n",
            "\u001b[01m\u001b[K./src/detector.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Ktrain_detector\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/detector.c:264:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Kdraw_precision\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K-Wunused-but-set-variable\u001b[m\u001b[K]\n",
            "         int \u001b[01;35m\u001b[Kdraw_precision\u001b[m\u001b[K = 0;\n",
            "             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/detector.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Keliminate_bdd\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/detector.c:481:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kstatement with no effect [\u001b[01;35m\u001b[K-Wunused-value\u001b[m\u001b[K]\n",
            "                     \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K (k; buf[k + n] != '\\0'; k++)\n",
            "                     \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/detector.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvalidate_detector\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/detector.c:592:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kmkd2\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "         int \u001b[01;35m\u001b[Kmkd2\u001b[m\u001b[K = make_directory(buff2, 0777);\n",
            "             \u001b[01;35m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/detector.c:590:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kmkd\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "         int \u001b[01;35m\u001b[Kmkd\u001b[m\u001b[K = make_directory(buff, 0777);\n",
            "             \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/detector.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvalidate_detector_map\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/detector.c:1211:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kclass_recall\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "         float \u001b[01;35m\u001b[Kclass_recall\u001b[m\u001b[K = (float)tp_for_thresh_per_class[i] / ((float)tp_for_thresh_per_class[i] + (float)(truth_classes_count[i] - tp_for_thresh_per_class[i]));\n",
            "               \u001b[01;35m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/detector.c:1210:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kclass_precision\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "         float \u001b[01;35m\u001b[Kclass_precision\u001b[m\u001b[K = (float)tp_for_thresh_per_class[i] / ((float)tp_for_thresh_per_class[i] + (float)fp_for_thresh_per_class[i]);\n",
            "               \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/layer.c -o obj/layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/compare.c -o obj/compare.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/classifier.c -o obj/classifier.o\n",
            "\u001b[01m\u001b[K./src/classifier.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Ktrain_classifier\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/classifier.c:175:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Kdraw_precision\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K-Wunused-but-set-variable\u001b[m\u001b[K]\n",
            "         int \u001b[01;35m\u001b[Kdraw_precision\u001b[m\u001b[K = 0;\n",
            "             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/classifier.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kpredict_classifier\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/classifier.c:818:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ktime\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     clock_t \u001b[01;35m\u001b[Ktime\u001b[m\u001b[K;\n",
            "             \u001b[01;35m\u001b[K^~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/local_layer.c -o obj/local_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/swag.c -o obj/swag.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/shortcut_layer.c -o obj/shortcut_layer.o\n",
            "\u001b[01m\u001b[K./src/shortcut_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kmake_shortcut_layer\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/shortcut_layer.c:54:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kscale\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "         float \u001b[01;35m\u001b[Kscale\u001b[m\u001b[K = sqrt(2. / l.nweights);\n",
            "               \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/activation_layer.c -o obj/activation_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/rnn_layer.c -o obj/rnn_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/gru_layer.c -o obj/gru_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/rnn.c -o obj/rnn.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/rnn_vid.c -o obj/rnn_vid.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/crnn_layer.c -o obj/crnn_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/demo.c -o obj/demo.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/tag.c -o obj/tag.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/cifar.c -o obj/cifar.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/go.c -o obj/go.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/batchnorm_layer.c -o obj/batchnorm_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/art.c -o obj/art.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/region_layer.c -o obj/region_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/reorg_layer.c -o obj/reorg_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/reorg_old_layer.c -o obj/reorg_old_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/super.c -o obj/super.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/voxel.c -o obj/voxel.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/tree.c -o obj/tree.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/yolo_layer.c -o obj/yolo_layer.o\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kforward_yolo_layer\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:357:25:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Kbest_match_t\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K-Wunused-but-set-variable\u001b[m\u001b[K]\n",
            "                     int \u001b[01;35m\u001b[Kbest_match_t\u001b[m\u001b[K = 0;\n",
            "                         \u001b[01;35m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/gaussian_yolo_layer.c -o obj/gaussian_yolo_layer.o\n",
            "\u001b[01m\u001b[K./src/gaussian_yolo_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kforward_gaussian_yolo_layer\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/gaussian_yolo_layer.c:451:25:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Kbest_match_t\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K-Wunused-but-set-variable\u001b[m\u001b[K]\n",
            "                     int \u001b[01;35m\u001b[Kbest_match_t\u001b[m\u001b[K = 0;\n",
            "                         \u001b[01;35m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/upsample_layer.c -o obj/upsample_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/lstm_layer.c -o obj/lstm_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/conv_lstm_layer.c -o obj/conv_lstm_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/scale_channels_layer.c -o obj/scale_channels_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -c ./src/sam_layer.c -o obj/sam_layer.o\n",
            "g++ -std=c++11 -Iinclude/ -I3rdparty/stb/include -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast obj/image_opencv.o obj/http_stream.o obj/gemm.o obj/utils.o obj/dark_cuda.o obj/convolutional_layer.o obj/list.o obj/image.o obj/activations.o obj/im2col.o obj/col2im.o obj/blas.o obj/crop_layer.o obj/dropout_layer.o obj/maxpool_layer.o obj/softmax_layer.o obj/data.o obj/matrix.o obj/network.o obj/connected_layer.o obj/cost_layer.o obj/parser.o obj/option_list.o obj/darknet.o obj/detection_layer.o obj/captcha.o obj/route_layer.o obj/writing.o obj/box.o obj/nightmare.o obj/normalization_layer.o obj/avgpool_layer.o obj/coco.o obj/dice.o obj/yolo.o obj/detector.o obj/layer.o obj/compare.o obj/classifier.o obj/local_layer.o obj/swag.o obj/shortcut_layer.o obj/activation_layer.o obj/rnn_layer.o obj/gru_layer.o obj/rnn.o obj/rnn_vid.o obj/crnn_layer.o obj/demo.o obj/tag.o obj/cifar.o obj/go.o obj/batchnorm_layer.o obj/art.o obj/region_layer.o obj/reorg_layer.o obj/reorg_old_layer.o obj/super.o obj/voxel.o obj/tree.o obj/yolo_layer.o obj/gaussian_yolo_layer.o obj/upsample_layer.o obj/lstm_layer.o obj/conv_lstm_layer.o obj/scale_channels_layer.o obj/sam_layer.o -o darknet -lm -pthread\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE4rb6TL1EuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create training file \n",
        "from pathlib import Path\n",
        "fileNames = []\n",
        "with open(r'data/symbolPerso.txt', 'w') as f:\n",
        "  for file in Path(r'/content/objectDetection-lightnet/data/images/valves').iterdir():\n",
        "    if file.suffix == '.png':\n",
        "      f.write(str(file.parent.joinpath(file.name +'\\n'))) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJmCN4y63mVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(r'data/valves.names', 'w') as f:\n",
        "  f.write('rob\\n')\n",
        "  f.write('valve\\n')\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BJ1aWK92OnR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b42e752c-efdc-4abf-b0c2-b180fb413726"
      },
      "source": [
        "# save edited file\n",
        "# valid data are dummy data\n",
        "%%writefile data/symbolPerso.data\n",
        "classes= 80\n",
        "train  = data/symbolPerso.txt\n",
        "valid  = data/coco_testdev \n",
        "names = data/coco.names\n",
        "backup = backup/"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing data/symbolPerso.data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWYKCXQ838Wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "a77c0afc-488c-4c78-ce7f-4bff528d83e6"
      },
      "source": [
        "# compute anchors using already available coco setting of AlexeyAB darknet\n",
        "!./darknet detector calc_anchors data/symbolPerso.data -num_of_clusters 9 -width 416 -height 416"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " OpenCV isn't used \n",
            "\n",
            " num_of_clusters = 9, width = 416, height = 416 \n",
            " read labels from 100 images \n",
            "\r loaded \t image: 1 \t box: 1\r loaded \t image: 1 \t box: 2\r loaded \t image: 1 \t box: 3\r loaded \t image: 1 \t box: 4\r loaded \t image: 1 \t box: 5\r loaded \t image: 1 \t box: 6\r loaded \t image: 1 \t box: 7\r loaded \t image: 1 \t box: 8\r loaded \t image: 1 \t box: 9\r loaded \t image: 1 \t box: 10\r loaded \t image: 2 \t box: 11\r loaded \t image: 2 \t box: 12\r loaded \t image: 2 \t box: 13\r loaded \t image: 2 \t box: 14\r loaded \t image: 2 \t box: 15\r loaded \t image: 2 \t box: 16\r loaded \t image: 2 \t box: 17\r loaded \t image: 2 \t box: 18\r loaded \t image: 2 \t box: 19\r loaded \t image: 2 \t box: 20\r loaded \t image: 2 \t box: 21\r loaded \t image: 2 \t box: 22\r loaded \t image: 2 \t box: 23\r loaded \t image: 2 \t box: 24\r loaded \t image: 2 \t box: 25\r loaded \t image: 2 \t box: 26\r loaded \t image: 3 \t box: 27\r loaded \t image: 3 \t box: 28\r loaded \t image: 3 \t box: 29\r loaded \t image: 3 \t box: 30\r loaded \t image: 3 \t box: 31\r loaded \t image: 3 \t box: 32\r loaded \t image: 3 \t box: 33\r loaded \t image: 3 \t box: 34\r loaded \t image: 3 \t box: 35\r loaded \t image: 3 \t box: 36\r loaded \t image: 4 \t box: 37\r loaded \t image: 4 \t box: 38\r loaded \t image: 4 \t box: 39\r loaded \t image: 4 \t box: 40\r loaded \t image: 4 \t box: 41\r loaded \t image: 4 \t box: 42\r loaded \t image: 4 \t box: 43\r loaded \t image: 4 \t box: 44\r loaded \t image: 4 \t box: 45\r loaded \t image: 4 \t box: 46\r loaded \t image: 5 \t box: 47\r loaded \t image: 5 \t box: 48\r loaded \t image: 5 \t box: 49\r loaded \t image: 5 \t box: 50\r loaded \t image: 5 \t box: 51\r loaded \t image: 5 \t box: 52\r loaded \t image: 5 \t box: 53\r loaded \t image: 5 \t box: 54\r loaded \t image: 5 \t box: 55\r loaded \t image: 5 \t box: 56\r loaded \t image: 6 \t box: 57\r loaded \t image: 6 \t box: 58\r loaded \t image: 6 \t box: 59\r loaded \t image: 6 \t box: 60\r loaded \t image: 6 \t box: 61\r loaded \t image: 6 \t box: 62\r loaded \t image: 6 \t box: 63\r loaded \t image: 6 \t box: 64\r loaded \t image: 6 \t box: 65\r loaded \t image: 6 \t box: 66\r loaded \t image: 7 \t box: 67\r loaded \t image: 7 \t box: 68\r loaded \t image: 7 \t box: 69\r loaded \t image: 7 \t box: 70\r loaded \t image: 7 \t box: 71\r loaded \t image: 7 \t box: 72\r loaded \t image: 7 \t box: 73\r loaded \t image: 7 \t box: 74\r loaded \t image: 7 \t box: 75\r loaded \t image: 7 \t box: 76\r loaded \t image: 7 \t box: 77\r loaded \t image: 7 \t box: 78\r loaded \t image: 8 \t box: 79\r loaded \t image: 8 \t box: 80\r loaded \t image: 8 \t box: 81\r loaded \t image: 8 \t box: 82\r loaded \t image: 8 \t box: 83\r loaded \t image: 8 \t box: 84\r loaded \t image: 8 \t box: 85\r loaded \t image: 8 \t box: 86\r loaded \t image: 8 \t box: 87\r loaded \t image: 8 \t box: 88\r loaded \t image: 8 \t box: 89\r loaded \t image: 8 \t box: 90\r loaded \t image: 8 \t box: 91\r loaded \t image: 8 \t box: 92\r loaded \t image: 8 \t box: 93\r loaded \t image: 8 \t box: 94\r loaded \t image: 8 \t box: 95\r loaded \t image: 8 \t box: 96\r loaded \t image: 9 \t box: 97\r loaded \t image: 9 \t box: 98\r loaded \t image: 9 \t box: 99\r loaded \t image: 9 \t box: 100\r loaded \t image: 9 \t box: 101\r loaded \t image: 9 \t box: 102\r loaded \t image: 9 \t box: 103\r loaded \t image: 9 \t box: 104\r loaded \t image: 9 \t box: 105\r loaded \t image: 9 \t box: 106\r loaded \t image: 9 \t box: 107\r loaded \t image: 9 \t box: 108\r loaded \t image: 10 \t box: 109\r loaded \t image: 10 \t box: 110\r loaded \t image: 10 \t box: 111\r loaded \t image: 10 \t box: 112\r loaded \t image: 10 \t box: 113\r loaded \t image: 10 \t box: 114\r loaded \t image: 10 \t box: 115\r loaded \t image: 10 \t box: 116\r loaded \t image: 10 \t box: 117\r loaded \t image: 10 \t box: 118\r loaded \t image: 11 \t box: 119\r loaded \t image: 11 \t box: 120\r loaded \t image: 11 \t box: 121\r loaded \t image: 11 \t box: 122\r loaded \t image: 11 \t box: 123\r loaded \t image: 11 \t box: 124\r loaded \t image: 11 \t box: 125\r loaded \t image: 11 \t box: 126\r loaded \t image: 11 \t box: 127\r loaded \t image: 11 \t box: 128\r loaded \t image: 11 \t box: 129\r loaded \t image: 11 \t box: 130\r loaded \t image: 11 \t box: 131\r loaded \t image: 11 \t box: 132\r loaded \t image: 11 \t box: 133\r loaded \t image: 11 \t box: 134\r loaded \t image: 12 \t box: 135\r loaded \t image: 12 \t box: 136\r loaded \t image: 12 \t box: 137\r loaded \t image: 12 \t box: 138\r loaded \t image: 12 \t box: 139\r loaded \t image: 12 \t box: 140\r loaded \t image: 12 \t box: 141\r loaded \t image: 12 \t box: 142\r loaded \t image: 12 \t box: 143\r loaded \t image: 12 \t box: 144\r loaded \t image: 13 \t box: 145\r loaded \t image: 13 \t box: 146\r loaded \t image: 13 \t box: 147\r loaded \t image: 13 \t box: 148\r loaded \t image: 13 \t box: 149\r loaded \t image: 13 \t box: 150\r loaded \t image: 13 \t box: 151\r loaded \t image: 13 \t box: 152\r loaded \t image: 13 \t box: 153\r loaded \t image: 13 \t box: 154\r loaded \t image: 13 \t box: 155\r loaded \t image: 13 \t box: 156\r loaded \t image: 13 \t box: 157\r loaded \t image: 13 \t box: 158\r loaded \t image: 13 \t box: 159\r loaded \t image: 13 \t box: 160\r loaded \t image: 14 \t box: 161\r loaded \t image: 14 \t box: 162\r loaded \t image: 14 \t box: 163\r loaded \t image: 14 \t box: 164\r loaded \t image: 14 \t box: 165\r loaded \t image: 14 \t box: 166\r loaded \t image: 14 \t box: 167\r loaded \t image: 14 \t box: 168\r loaded \t image: 14 \t box: 169\r loaded \t image: 14 \t box: 170\r loaded \t image: 14 \t box: 171\r loaded \t image: 14 \t box: 172\r loaded \t image: 14 \t box: 173\r loaded \t image: 14 \t box: 174\r loaded \t image: 14 \t box: 175\r loaded \t image: 14 \t box: 176\r loaded \t image: 14 \t box: 177\r loaded \t image: 14 \t box: 178\r loaded \t image: 15 \t box: 179\r loaded \t image: 15 \t box: 180\r loaded \t image: 15 \t box: 181\r loaded \t image: 15 \t box: 182\r loaded \t image: 15 \t box: 183\r loaded \t image: 15 \t box: 184\r loaded \t image: 15 \t box: 185\r loaded \t image: 15 \t box: 186\r loaded \t image: 15 \t box: 187\r loaded \t image: 15 \t box: 188\r loaded \t image: 16 \t box: 189\r loaded \t image: 16 \t box: 190\r loaded \t image: 16 \t box: 191\r loaded \t image: 16 \t box: 192\r loaded \t image: 16 \t box: 193\r loaded \t image: 16 \t box: 194\r loaded \t image: 16 \t box: 195\r loaded \t image: 16 \t box: 196\r loaded \t image: 16 \t box: 197\r loaded \t image: 16 \t box: 198\r loaded \t image: 17 \t box: 199\r loaded \t image: 17 \t box: 200\r loaded \t image: 17 \t box: 201\r loaded \t image: 17 \t box: 202\r loaded \t image: 17 \t box: 203\r loaded \t image: 17 \t box: 204\r loaded \t image: 17 \t box: 205\r loaded \t image: 17 \t box: 206\r loaded \t image: 17 \t box: 207\r loaded \t image: 17 \t box: 208\r loaded \t image: 17 \t box: 209\r loaded \t image: 17 \t box: 210\r loaded \t image: 17 \t box: 211\r loaded \t image: 17 \t box: 212\r loaded \t image: 17 \t box: 213\r loaded \t image: 17 \t box: 214\r loaded \t image: 18 \t box: 215\r loaded \t image: 18 \t box: 216\r loaded \t image: 18 \t box: 217\r loaded \t image: 18 \t box: 218\r loaded \t image: 18 \t box: 219\r loaded \t image: 18 \t box: 220\r loaded \t image: 18 \t box: 221\r loaded \t image: 18 \t box: 222\r loaded \t image: 18 \t box: 223\r loaded \t image: 18 \t box: 224\r loaded \t image: 19 \t box: 225\r loaded \t image: 19 \t box: 226\r loaded \t image: 19 \t box: 227\r loaded \t image: 19 \t box: 228\r loaded \t image: 19 \t box: 229\r loaded \t image: 19 \t box: 230\r loaded \t image: 19 \t box: 231\r loaded \t image: 19 \t box: 232\r loaded \t image: 19 \t box: 233\r loaded \t image: 19 \t box: 234\r loaded \t image: 20 \t box: 235\r loaded \t image: 20 \t box: 236\r loaded \t image: 20 \t box: 237\r loaded \t image: 20 \t box: 238\r loaded \t image: 20 \t box: 239\r loaded \t image: 20 \t box: 240\r loaded \t image: 20 \t box: 241\r loaded \t image: 20 \t box: 242\r loaded \t image: 20 \t box: 243\r loaded \t image: 20 \t box: 244\r loaded \t image: 21 \t box: 245\r loaded \t image: 21 \t box: 246\r loaded \t image: 21 \t box: 247\r loaded \t image: 21 \t box: 248\r loaded \t image: 21 \t box: 249\r loaded \t image: 21 \t box: 250\r loaded \t image: 21 \t box: 251\r loaded \t image: 21 \t box: 252\r loaded \t image: 21 \t box: 253\r loaded \t image: 21 \t box: 254\r loaded \t image: 21 \t box: 255\r loaded \t image: 21 \t box: 256\r loaded \t image: 21 \t box: 257\r loaded \t image: 21 \t box: 258\r loaded \t image: 22 \t box: 259\r loaded \t image: 22 \t box: 260\r loaded \t image: 22 \t box: 261\r loaded \t image: 22 \t box: 262\r loaded \t image: 22 \t box: 263\r loaded \t image: 22 \t box: 264\r loaded \t image: 22 \t box: 265\r loaded \t image: 22 \t box: 266\r loaded \t image: 22 \t box: 267\r loaded \t image: 22 \t box: 268\r loaded \t image: 23 \t box: 269\r loaded \t image: 23 \t box: 270\r loaded \t image: 23 \t box: 271\r loaded \t image: 23 \t box: 272\r loaded \t image: 23 \t box: 273\r loaded \t image: 23 \t box: 274\r loaded \t image: 23 \t box: 275\r loaded \t image: 23 \t box: 276\r loaded \t image: 23 \t box: 277\r loaded \t image: 23 \t box: 278\r loaded \t image: 23 \t box: 279\r loaded \t image: 23 \t box: 280\r loaded \t image: 24 \t box: 281\r loaded \t image: 24 \t box: 282\r loaded \t image: 24 \t box: 283\r loaded \t image: 24 \t box: 284\r loaded \t image: 24 \t box: 285\r loaded \t image: 24 \t box: 286\r loaded \t image: 24 \t box: 287\r loaded \t image: 24 \t box: 288\r loaded \t image: 24 \t box: 289\r loaded \t image: 24 \t box: 290\r loaded \t image: 24 \t box: 291\r loaded \t image: 24 \t box: 292\r loaded \t image: 25 \t box: 293\r loaded \t image: 25 \t box: 294\r loaded \t image: 25 \t box: 295\r loaded \t image: 25 \t box: 296\r loaded \t image: 25 \t box: 297\r loaded \t image: 25 \t box: 298\r loaded \t image: 25 \t box: 299\r loaded \t image: 25 \t box: 300\r loaded \t image: 25 \t box: 301\r loaded \t image: 25 \t box: 302\r loaded \t image: 25 \t box: 303\r loaded \t image: 25 \t box: 304\r loaded \t image: 25 \t box: 305\r loaded \t image: 25 \t box: 306\r loaded \t image: 25 \t box: 307\r loaded \t image: 25 \t box: 308\r loaded \t image: 25 \t box: 309\r loaded \t image: 25 \t box: 310\r loaded \t image: 25 \t box: 311\r loaded \t image: 25 \t box: 312\r loaded \t image: 26 \t box: 313\r loaded \t image: 26 \t box: 314\r loaded \t image: 26 \t box: 315\r loaded \t image: 26 \t box: 316\r loaded \t image: 26 \t box: 317\r loaded \t image: 26 \t box: 318\r loaded \t image: 26 \t box: 319\r loaded \t image: 26 \t box: 320\r loaded \t image: 26 \t box: 321\r loaded \t image: 26 \t box: 322\r loaded \t image: 26 \t box: 323\r loaded \t image: 26 \t box: 324\r loaded \t image: 26 \t box: 325\r loaded \t image: 26 \t box: 326\r loaded \t image: 27 \t box: 327\r loaded \t image: 27 \t box: 328\r loaded \t image: 27 \t box: 329\r loaded \t image: 27 \t box: 330\r loaded \t image: 27 \t box: 331\r loaded \t image: 27 \t box: 332\r loaded \t image: 27 \t box: 333\r loaded \t image: 27 \t box: 334\r loaded \t image: 27 \t box: 335\r loaded \t image: 27 \t box: 336\r loaded \t image: 28 \t box: 337\r loaded \t image: 28 \t box: 338\r loaded \t image: 28 \t box: 339\r loaded \t image: 28 \t box: 340\r loaded \t image: 28 \t box: 341\r loaded \t image: 28 \t box: 342\r loaded \t image: 28 \t box: 343\r loaded \t image: 28 \t box: 344\r loaded \t image: 28 \t box: 345\r loaded \t image: 28 \t box: 346\r loaded \t image: 29 \t box: 347\r loaded \t image: 29 \t box: 348\r loaded \t image: 29 \t box: 349\r loaded \t image: 29 \t box: 350\r loaded \t image: 29 \t box: 351\r loaded \t image: 29 \t box: 352\r loaded \t image: 29 \t box: 353\r loaded \t image: 29 \t box: 354\r loaded \t image: 29 \t box: 355\r loaded \t image: 29 \t box: 356\r loaded \t image: 30 \t box: 357\r loaded \t image: 30 \t box: 358\r loaded \t image: 30 \t box: 359\r loaded \t image: 30 \t box: 360\r loaded \t image: 30 \t box: 361\r loaded \t image: 30 \t box: 362\r loaded \t image: 30 \t box: 363\r loaded \t image: 30 \t box: 364\r loaded \t image: 30 \t box: 365\r loaded \t image: 30 \t box: 366\r loaded \t image: 31 \t box: 367\r loaded \t image: 31 \t box: 368\r loaded \t image: 31 \t box: 369\r loaded \t image: 31 \t box: 370\r loaded \t image: 31 \t box: 371\r loaded \t image: 31 \t box: 372\r loaded \t image: 31 \t box: 373\r loaded \t image: 31 \t box: 374\r loaded \t image: 31 \t box: 375\r loaded \t image: 31 \t box: 376\r loaded \t image: 31 \t box: 377\r loaded \t image: 31 \t box: 378\r loaded \t image: 31 \t box: 379\r loaded \t image: 31 \t box: 380\r loaded \t image: 31 \t box: 381\r loaded \t image: 31 \t box: 382\r loaded \t image: 32 \t box: 383\r loaded \t image: 32 \t box: 384\r loaded \t image: 32 \t box: 385\r loaded \t image: 32 \t box: 386\r loaded \t image: 32 \t box: 387\r loaded \t image: 32 \t box: 388\r loaded \t image: 32 \t box: 389\r loaded \t image: 32 \t box: 390\r loaded \t image: 32 \t box: 391\r loaded \t image: 32 \t box: 392\r loaded \t image: 32 \t box: 393\r loaded \t image: 32 \t box: 394\r loaded \t image: 32 \t box: 395\r loaded \t image: 32 \t box: 396\r loaded \t image: 32 \t box: 397\r loaded \t image: 32 \t box: 398\r loaded \t image: 33 \t box: 399\r loaded \t image: 33 \t box: 400\r loaded \t image: 33 \t box: 401\r loaded \t image: 33 \t box: 402\r loaded \t image: 33 \t box: 403\r loaded \t image: 33 \t box: 404\r loaded \t image: 33 \t box: 405\r loaded \t image: 33 \t box: 406\r loaded \t image: 33 \t box: 407\r loaded \t image: 33 \t box: 408\r loaded \t image: 34 \t box: 409\r loaded \t image: 34 \t box: 410\r loaded \t image: 34 \t box: 411\r loaded \t image: 34 \t box: 412\r loaded \t image: 34 \t box: 413\r loaded \t image: 34 \t box: 414\r loaded \t image: 34 \t box: 415\r loaded \t image: 34 \t box: 416\r loaded \t image: 34 \t box: 417\r loaded \t image: 34 \t box: 418\r loaded \t image: 35 \t box: 419\r loaded \t image: 35 \t box: 420\r loaded \t image: 35 \t box: 421\r loaded \t image: 35 \t box: 422\r loaded \t image: 35 \t box: 423\r loaded \t image: 35 \t box: 424\r loaded \t image: 35 \t box: 425\r loaded \t image: 35 \t box: 426\r loaded \t image: 35 \t box: 427\r loaded \t image: 35 \t box: 428\r loaded \t image: 36 \t box: 429\r loaded \t image: 36 \t box: 430\r loaded \t image: 36 \t box: 431\r loaded \t image: 36 \t box: 432\r loaded \t image: 36 \t box: 433\r loaded \t image: 36 \t box: 434\r loaded \t image: 36 \t box: 435\r loaded \t image: 36 \t box: 436\r loaded \t image: 36 \t box: 437\r loaded \t image: 36 \t box: 438\r loaded \t image: 37 \t box: 439\r loaded \t image: 37 \t box: 440\r loaded \t image: 37 \t box: 441\r loaded \t image: 37 \t box: 442\r loaded \t image: 37 \t box: 443\r loaded \t image: 37 \t box: 444\r loaded \t image: 37 \t box: 445\r loaded \t image: 37 \t box: 446\r loaded \t image: 37 \t box: 447\r loaded \t image: 37 \t box: 448\r loaded \t image: 38 \t box: 449\r loaded \t image: 38 \t box: 450\r loaded \t image: 38 \t box: 451\r loaded \t image: 38 \t box: 452\r loaded \t image: 38 \t box: 453\r loaded \t image: 38 \t box: 454\r loaded \t image: 38 \t box: 455\r loaded \t image: 38 \t box: 456\r loaded \t image: 38 \t box: 457\r loaded \t image: 38 \t box: 458\r loaded \t image: 39 \t box: 459\r loaded \t image: 39 \t box: 460\r loaded \t image: 39 \t box: 461\r loaded \t image: 39 \t box: 462\r loaded \t image: 39 \t box: 463\r loaded \t image: 39 \t box: 464\r loaded \t image: 39 \t box: 465\r loaded \t image: 39 \t box: 466\r loaded \t image: 39 \t box: 467\r loaded \t image: 39 \t box: 468\r loaded \t image: 40 \t box: 469\r loaded \t image: 40 \t box: 470\r loaded \t image: 40 \t box: 471\r loaded \t image: 40 \t box: 472\r loaded \t image: 40 \t box: 473\r loaded \t image: 40 \t box: 474\r loaded \t image: 40 \t box: 475\r loaded \t image: 40 \t box: 476\r loaded \t image: 40 \t box: 477\r loaded \t image: 40 \t box: 478\r loaded \t image: 40 \t box: 479\r loaded \t image: 40 \t box: 480\r loaded \t image: 41 \t box: 481\r loaded \t image: 41 \t box: 482\r loaded \t image: 41 \t box: 483\r loaded \t image: 41 \t box: 484\r loaded \t image: 41 \t box: 485\r loaded \t image: 41 \t box: 486\r loaded \t image: 41 \t box: 487\r loaded \t image: 41 \t box: 488\r loaded \t image: 41 \t box: 489\r loaded \t image: 41 \t box: 490\r loaded \t image: 41 \t box: 491\r loaded \t image: 41 \t box: 492\r loaded \t image: 42 \t box: 493\r loaded \t image: 42 \t box: 494\r loaded \t image: 42 \t box: 495\r loaded \t image: 42 \t box: 496\r loaded \t image: 42 \t box: 497\r loaded \t image: 42 \t box: 498\r loaded \t image: 42 \t box: 499\r loaded \t image: 42 \t box: 500\r loaded \t image: 42 \t box: 501\r loaded \t image: 42 \t box: 502\r loaded \t image: 42 \t box: 503\r loaded \t image: 42 \t box: 504\r loaded \t image: 42 \t box: 505\r loaded \t image: 42 \t box: 506\r loaded \t image: 42 \t box: 507\r loaded \t image: 42 \t box: 508\r loaded \t image: 43 \t box: 509\r loaded \t image: 43 \t box: 510\r loaded \t image: 43 \t box: 511\r loaded \t image: 43 \t box: 512\r loaded \t image: 43 \t box: 513\r loaded \t image: 43 \t box: 514\r loaded \t image: 43 \t box: 515\r loaded \t image: 43 \t box: 516\r loaded \t image: 43 \t box: 517\r loaded \t image: 43 \t box: 518\r loaded \t image: 44 \t box: 519\r loaded \t image: 44 \t box: 520\r loaded \t image: 44 \t box: 521\r loaded \t image: 44 \t box: 522\r loaded \t image: 44 \t box: 523\r loaded \t image: 44 \t box: 524\r loaded \t image: 44 \t box: 525\r loaded \t image: 44 \t box: 526\r loaded \t image: 44 \t box: 527\r loaded \t image: 44 \t box: 528\r loaded \t image: 44 \t box: 529\r loaded \t image: 44 \t box: 530\r loaded \t image: 44 \t box: 531\r loaded \t image: 44 \t box: 532\r loaded \t image: 44 \t box: 533\r loaded \t image: 44 \t box: 534\r loaded \t image: 45 \t box: 535\r loaded \t image: 45 \t box: 536\r loaded \t image: 45 \t box: 537\r loaded \t image: 45 \t box: 538\r loaded \t image: 45 \t box: 539\r loaded \t image: 45 \t box: 540\r loaded \t image: 45 \t box: 541\r loaded \t image: 45 \t box: 542\r loaded \t image: 45 \t box: 543\r loaded \t image: 45 \t box: 544\r loaded \t image: 45 \t box: 545\r loaded \t image: 45 \t box: 546\r loaded \t image: 45 \t box: 547\r loaded \t image: 45 \t box: 548\r loaded \t image: 45 \t box: 549\r loaded \t image: 45 \t box: 550\r loaded \t image: 46 \t box: 551\r loaded \t image: 46 \t box: 552\r loaded \t image: 46 \t box: 553\r loaded \t image: 46 \t box: 554\r loaded \t image: 46 \t box: 555\r loaded \t image: 46 \t box: 556\r loaded \t image: 46 \t box: 557\r loaded \t image: 46 \t box: 558\r loaded \t image: 46 \t box: 559\r loaded \t image: 46 \t box: 560\r loaded \t image: 46 \t box: 561\r loaded \t image: 46 \t box: 562\r loaded \t image: 46 \t box: 563\r loaded \t image: 46 \t box: 564\r loaded \t image: 46 \t box: 565\r loaded \t image: 46 \t box: 566\r loaded \t image: 47 \t box: 567\r loaded \t image: 47 \t box: 568\r loaded \t image: 47 \t box: 569\r loaded \t image: 47 \t box: 570\r loaded \t image: 47 \t box: 571\r loaded \t image: 47 \t box: 572\r loaded \t image: 47 \t box: 573\r loaded \t image: 47 \t box: 574\r loaded \t image: 47 \t box: 575\r loaded \t image: 47 \t box: 576\r loaded \t image: 48 \t box: 577\r loaded \t image: 48 \t box: 578\r loaded \t image: 48 \t box: 579\r loaded \t image: 48 \t box: 580\r loaded \t image: 48 \t box: 581\r loaded \t image: 48 \t box: 582\r loaded \t image: 48 \t box: 583\r loaded \t image: 48 \t box: 584\r loaded \t image: 48 \t box: 585\r loaded \t image: 48 \t box: 586\r loaded \t image: 49 \t box: 587\r loaded \t image: 49 \t box: 588\r loaded \t image: 49 \t box: 589\r loaded \t image: 49 \t box: 590\r loaded \t image: 49 \t box: 591\r loaded \t image: 49 \t box: 592\r loaded \t image: 49 \t box: 593\r loaded \t image: 49 \t box: 594\r loaded \t image: 49 \t box: 595\r loaded \t image: 49 \t box: 596\r loaded \t image: 49 \t box: 597\r loaded \t image: 49 \t box: 598\r loaded \t image: 49 \t box: 599\r loaded \t image: 49 \t box: 600\r loaded \t image: 49 \t box: 601\r loaded \t image: 49 \t box: 602\r loaded \t image: 50 \t box: 603\r loaded \t image: 50 \t box: 604\r loaded \t image: 50 \t box: 605\r loaded \t image: 50 \t box: 606\r loaded \t image: 50 \t box: 607\r loaded \t image: 50 \t box: 608\r loaded \t image: 50 \t box: 609\r loaded \t image: 50 \t box: 610\r loaded \t image: 50 \t box: 611\r loaded \t image: 50 \t box: 612\r loaded \t image: 50 \t box: 613\r loaded \t image: 50 \t box: 614\r loaded \t image: 51 \t box: 615\r loaded \t image: 51 \t box: 616\r loaded \t image: 51 \t box: 617\r loaded \t image: 51 \t box: 618\r loaded \t image: 51 \t box: 619\r loaded \t image: 51 \t box: 620\r loaded \t image: 51 \t box: 621\r loaded \t image: 51 \t box: 622\r loaded \t image: 51 \t box: 623\r loaded \t image: 51 \t box: 624\r loaded \t image: 51 \t box: 625\r loaded \t image: 51 \t box: 626\r loaded \t image: 52 \t box: 627\r loaded \t image: 52 \t box: 628\r loaded \t image: 52 \t box: 629\r loaded \t image: 52 \t box: 630\r loaded \t image: 52 \t box: 631\r loaded \t image: 52 \t box: 632\r loaded \t image: 52 \t box: 633\r loaded \t image: 52 \t box: 634\r loaded \t image: 52 \t box: 635\r loaded \t image: 52 \t box: 636\r loaded \t image: 53 \t box: 637\r loaded \t image: 53 \t box: 638\r loaded \t image: 53 \t box: 639\r loaded \t image: 53 \t box: 640\r loaded \t image: 53 \t box: 641\r loaded \t image: 53 \t box: 642\r loaded \t image: 53 \t box: 643\r loaded \t image: 53 \t box: 644\r loaded \t image: 53 \t box: 645\r loaded \t image: 53 \t box: 646\r loaded \t image: 53 \t box: 647\r loaded \t image: 53 \t box: 648\r loaded \t image: 53 \t box: 649\r loaded \t image: 53 \t box: 650\r loaded \t image: 53 \t box: 651\r loaded \t image: 53 \t box: 652\r loaded \t image: 53 \t box: 653\r loaded \t image: 53 \t box: 654\r loaded \t image: 53 \t box: 655\r loaded \t image: 53 \t box: 656\r loaded \t image: 54 \t box: 657\r loaded \t image: 54 \t box: 658\r loaded \t image: 54 \t box: 659\r loaded \t image: 54 \t box: 660\r loaded \t image: 54 \t box: 661\r loaded \t image: 54 \t box: 662\r loaded \t image: 54 \t box: 663\r loaded \t image: 54 \t box: 664\r loaded \t image: 54 \t box: 665\r loaded \t image: 54 \t box: 666\r loaded \t image: 55 \t box: 667\r loaded \t image: 55 \t box: 668\r loaded \t image: 55 \t box: 669\r loaded \t image: 55 \t box: 670\r loaded \t image: 55 \t box: 671\r loaded \t image: 55 \t box: 672\r loaded \t image: 55 \t box: 673\r loaded \t image: 55 \t box: 674\r loaded \t image: 55 \t box: 675\r loaded \t image: 55 \t box: 676\r loaded \t image: 55 \t box: 677\r loaded \t image: 55 \t box: 678\r loaded \t image: 56 \t box: 679\r loaded \t image: 56 \t box: 680\r loaded \t image: 56 \t box: 681\r loaded \t image: 56 \t box: 682\r loaded \t image: 56 \t box: 683\r loaded \t image: 56 \t box: 684\r loaded \t image: 56 \t box: 685\r loaded \t image: 56 \t box: 686\r loaded \t image: 56 \t box: 687\r loaded \t image: 56 \t box: 688\r loaded \t image: 57 \t box: 689\r loaded \t image: 57 \t box: 690\r loaded \t image: 57 \t box: 691\r loaded \t image: 57 \t box: 692\r loaded \t image: 57 \t box: 693\r loaded \t image: 57 \t box: 694\r loaded \t image: 57 \t box: 695\r loaded \t image: 57 \t box: 696\r loaded \t image: 57 \t box: 697\r loaded \t image: 57 \t box: 698\r loaded \t image: 57 \t box: 699\r loaded \t image: 57 \t box: 700\r loaded \t image: 57 \t box: 701\r loaded \t image: 57 \t box: 702\r loaded \t image: 57 \t box: 703\r loaded \t image: 57 \t box: 704\r loaded \t image: 57 \t box: 705\r loaded \t image: 57 \t box: 706\r loaded \t image: 58 \t box: 707\r loaded \t image: 58 \t box: 708\r loaded \t image: 58 \t box: 709\r loaded \t image: 58 \t box: 710\r loaded \t image: 58 \t box: 711\r loaded \t image: 58 \t box: 712\r loaded \t image: 58 \t box: 713\r loaded \t image: 58 \t box: 714\r loaded \t image: 58 \t box: 715\r loaded \t image: 58 \t box: 716\r loaded \t image: 58 \t box: 717\r loaded \t image: 58 \t box: 718\r loaded \t image: 58 \t box: 719\r loaded \t image: 58 \t box: 720\r loaded \t image: 58 \t box: 721\r loaded \t image: 58 \t box: 722\r loaded \t image: 58 \t box: 723\r loaded \t image: 58 \t box: 724\r loaded \t image: 58 \t box: 725\r loaded \t image: 58 \t box: 726\r loaded \t image: 59 \t box: 727\r loaded \t image: 59 \t box: 728\r loaded \t image: 59 \t box: 729\r loaded \t image: 59 \t box: 730\r loaded \t image: 59 \t box: 731\r loaded \t image: 59 \t box: 732\r loaded \t image: 59 \t box: 733\r loaded \t image: 59 \t box: 734\r loaded \t image: 59 \t box: 735\r loaded \t image: 59 \t box: 736\r loaded \t image: 60 \t box: 737\r loaded \t image: 60 \t box: 738\r loaded \t image: 60 \t box: 739\r loaded \t image: 60 \t box: 740\r loaded \t image: 60 \t box: 741\r loaded \t image: 60 \t box: 742\r loaded \t image: 60 \t box: 743\r loaded \t image: 60 \t box: 744\r loaded \t image: 60 \t box: 745\r loaded \t image: 60 \t box: 746\r loaded \t image: 60 \t box: 747\r loaded \t image: 60 \t box: 748\r loaded \t image: 61 \t box: 749\r loaded \t image: 61 \t box: 750\r loaded \t image: 61 \t box: 751\r loaded \t image: 61 \t box: 752\r loaded \t image: 61 \t box: 753\r loaded \t image: 61 \t box: 754\r loaded \t image: 61 \t box: 755\r loaded \t image: 61 \t box: 756\r loaded \t image: 61 \t box: 757\r loaded \t image: 61 \t box: 758\r loaded \t image: 62 \t box: 759\r loaded \t image: 62 \t box: 760\r loaded \t image: 62 \t box: 761\r loaded \t image: 62 \t box: 762\r loaded \t image: 62 \t box: 763\r loaded \t image: 62 \t box: 764\r loaded \t image: 62 \t box: 765\r loaded \t image: 62 \t box: 766\r loaded \t image: 62 \t box: 767\r loaded \t image: 62 \t box: 768\r loaded \t image: 63 \t box: 769\r loaded \t image: 63 \t box: 770\r loaded \t image: 63 \t box: 771\r loaded \t image: 63 \t box: 772\r loaded \t image: 63 \t box: 773\r loaded \t image: 63 \t box: 774\r loaded \t image: 63 \t box: 775\r loaded \t image: 63 \t box: 776\r loaded \t image: 63 \t box: 777\r loaded \t image: 63 \t box: 778\r loaded \t image: 63 \t box: 779\r loaded \t image: 63 \t box: 780\r loaded \t image: 64 \t box: 781\r loaded \t image: 64 \t box: 782\r loaded \t image: 64 \t box: 783\r loaded \t image: 64 \t box: 784\r loaded \t image: 64 \t box: 785\r loaded \t image: 64 \t box: 786\r loaded \t image: 64 \t box: 787\r loaded \t image: 64 \t box: 788\r loaded \t image: 64 \t box: 789\r loaded \t image: 64 \t box: 790\r loaded \t image: 64 \t box: 791\r loaded \t image: 64 \t box: 792\r loaded \t image: 64 \t box: 793\r loaded \t image: 64 \t box: 794\r loaded \t image: 64 \t box: 795\r loaded \t image: 64 \t box: 796\r loaded \t image: 64 \t box: 797\r loaded \t image: 64 \t box: 798\r loaded \t image: 64 \t box: 799\r loaded \t image: 64 \t box: 800\r loaded \t image: 65 \t box: 801\r loaded \t image: 65 \t box: 802\r loaded \t image: 65 \t box: 803\r loaded \t image: 65 \t box: 804\r loaded \t image: 65 \t box: 805\r loaded \t image: 65 \t box: 806\r loaded \t image: 65 \t box: 807\r loaded \t image: 65 \t box: 808\r loaded \t image: 65 \t box: 809\r loaded \t image: 65 \t box: 810\r loaded \t image: 65 \t box: 811\r loaded \t image: 65 \t box: 812\r loaded \t image: 65 \t box: 813\r loaded \t image: 65 \t box: 814\r loaded \t image: 66 \t box: 815\r loaded \t image: 66 \t box: 816\r loaded \t image: 66 \t box: 817\r loaded \t image: 66 \t box: 818\r loaded \t image: 66 \t box: 819\r loaded \t image: 66 \t box: 820\r loaded \t image: 66 \t box: 821\r loaded \t image: 66 \t box: 822\r loaded \t image: 66 \t box: 823\r loaded \t image: 66 \t box: 824\r loaded \t image: 66 \t box: 825\r loaded \t image: 66 \t box: 826\r loaded \t image: 66 \t box: 827\r loaded \t image: 66 \t box: 828\r loaded \t image: 66 \t box: 829\r loaded \t image: 66 \t box: 830\r loaded \t image: 67 \t box: 831\r loaded \t image: 67 \t box: 832\r loaded \t image: 67 \t box: 833\r loaded \t image: 67 \t box: 834\r loaded \t image: 67 \t box: 835\r loaded \t image: 67 \t box: 836\r loaded \t image: 67 \t box: 837\r loaded \t image: 67 \t box: 838\r loaded \t image: 67 \t box: 839\r loaded \t image: 67 \t box: 840\r loaded \t image: 67 \t box: 841\r loaded \t image: 67 \t box: 842\r loaded \t image: 67 \t box: 843\r loaded \t image: 67 \t box: 844\r loaded \t image: 67 \t box: 845\r loaded \t image: 67 \t box: 846\r loaded \t image: 67 \t box: 847\r loaded \t image: 67 \t box: 848\r loaded \t image: 68 \t box: 849\r loaded \t image: 68 \t box: 850\r loaded \t image: 68 \t box: 851\r loaded \t image: 68 \t box: 852\r loaded \t image: 68 \t box: 853\r loaded \t image: 68 \t box: 854\r loaded \t image: 68 \t box: 855\r loaded \t image: 68 \t box: 856\r loaded \t image: 68 \t box: 857\r loaded \t image: 68 \t box: 858\r loaded \t image: 69 \t box: 859\r loaded \t image: 69 \t box: 860\r loaded \t image: 69 \t box: 861\r loaded \t image: 69 \t box: 862\r loaded \t image: 69 \t box: 863\r loaded \t image: 69 \t box: 864\r loaded \t image: 69 \t box: 865\r loaded \t image: 69 \t box: 866\r loaded \t image: 69 \t box: 867\r loaded \t image: 69 \t box: 868\r loaded \t image: 70 \t box: 869\r loaded \t image: 70 \t box: 870\r loaded \t image: 70 \t box: 871\r loaded \t image: 70 \t box: 872\r loaded \t image: 70 \t box: 873\r loaded \t image: 70 \t box: 874\r loaded \t image: 70 \t box: 875\r loaded \t image: 70 \t box: 876\r loaded \t image: 70 \t box: 877\r loaded \t image: 70 \t box: 878\r loaded \t image: 70 \t box: 879\r loaded \t image: 70 \t box: 880\r loaded \t image: 71 \t box: 881\r loaded \t image: 71 \t box: 882\r loaded \t image: 71 \t box: 883\r loaded \t image: 71 \t box: 884\r loaded \t image: 71 \t box: 885\r loaded \t image: 71 \t box: 886\r loaded \t image: 71 \t box: 887\r loaded \t image: 71 \t box: 888\r loaded \t image: 71 \t box: 889\r loaded \t image: 71 \t box: 890\r loaded \t image: 72 \t box: 891\r loaded \t image: 72 \t box: 892\r loaded \t image: 72 \t box: 893\r loaded \t image: 72 \t box: 894\r loaded \t image: 72 \t box: 895\r loaded \t image: 72 \t box: 896\r loaded \t image: 72 \t box: 897\r loaded \t image: 72 \t box: 898\r loaded \t image: 72 \t box: 899\r loaded \t image: 72 \t box: 900\r loaded \t image: 73 \t box: 901\r loaded \t image: 73 \t box: 902\r loaded \t image: 73 \t box: 903\r loaded \t image: 73 \t box: 904\r loaded \t image: 73 \t box: 905\r loaded \t image: 73 \t box: 906\r loaded \t image: 73 \t box: 907\r loaded \t image: 73 \t box: 908\r loaded \t image: 73 \t box: 909\r loaded \t image: 73 \t box: 910\r loaded \t image: 74 \t box: 911\r loaded \t image: 74 \t box: 912\r loaded \t image: 74 \t box: 913\r loaded \t image: 74 \t box: 914\r loaded \t image: 74 \t box: 915\r loaded \t image: 74 \t box: 916\r loaded \t image: 74 \t box: 917\r loaded \t image: 74 \t box: 918\r loaded \t image: 74 \t box: 919\r loaded \t image: 74 \t box: 920\r loaded \t image: 75 \t box: 921\r loaded \t image: 75 \t box: 922\r loaded \t image: 75 \t box: 923\r loaded \t image: 75 \t box: 924\r loaded \t image: 75 \t box: 925\r loaded \t image: 75 \t box: 926\r loaded \t image: 75 \t box: 927\r loaded \t image: 75 \t box: 928\r loaded \t image: 75 \t box: 929\r loaded \t image: 75 \t box: 930\r loaded \t image: 76 \t box: 931\r loaded \t image: 76 \t box: 932\r loaded \t image: 76 \t box: 933\r loaded \t image: 76 \t box: 934\r loaded \t image: 76 \t box: 935\r loaded \t image: 76 \t box: 936\r loaded \t image: 76 \t box: 937\r loaded \t image: 76 \t box: 938\r loaded \t image: 76 \t box: 939\r loaded \t image: 76 \t box: 940\r loaded \t image: 77 \t box: 941\r loaded \t image: 77 \t box: 942\r loaded \t image: 77 \t box: 943\r loaded \t image: 77 \t box: 944\r loaded \t image: 77 \t box: 945\r loaded \t image: 77 \t box: 946\r loaded \t image: 77 \t box: 947\r loaded \t image: 77 \t box: 948\r loaded \t image: 77 \t box: 949\r loaded \t image: 77 \t box: 950\r loaded \t image: 77 \t box: 951\r loaded \t image: 77 \t box: 952\r loaded \t image: 77 \t box: 953\r loaded \t image: 77 \t box: 954\r loaded \t image: 77 \t box: 955\r loaded \t image: 77 \t box: 956\r loaded \t image: 78 \t box: 957\r loaded \t image: 78 \t box: 958\r loaded \t image: 78 \t box: 959\r loaded \t image: 78 \t box: 960\r loaded \t image: 78 \t box: 961\r loaded \t image: 78 \t box: 962\r loaded \t image: 78 \t box: 963\r loaded \t image: 78 \t box: 964\r loaded \t image: 78 \t box: 965\r loaded \t image: 78 \t box: 966\r loaded \t image: 78 \t box: 967\r loaded \t image: 78 \t box: 968\r loaded \t image: 78 \t box: 969\r loaded \t image: 78 \t box: 970\r loaded \t image: 78 \t box: 971\r loaded \t image: 78 \t box: 972\r loaded \t image: 79 \t box: 973\r loaded \t image: 79 \t box: 974\r loaded \t image: 79 \t box: 975\r loaded \t image: 79 \t box: 976\r loaded \t image: 79 \t box: 977\r loaded \t image: 79 \t box: 978\r loaded \t image: 79 \t box: 979\r loaded \t image: 79 \t box: 980\r loaded \t image: 79 \t box: 981\r loaded \t image: 79 \t box: 982\r loaded \t image: 79 \t box: 983\r loaded \t image: 79 \t box: 984\r loaded \t image: 79 \t box: 985\r loaded \t image: 79 \t box: 986\r loaded \t image: 79 \t box: 987\r loaded \t image: 79 \t box: 988\r loaded \t image: 80 \t box: 989\r loaded \t image: 80 \t box: 990\r loaded \t image: 80 \t box: 991\r loaded \t image: 80 \t box: 992\r loaded \t image: 80 \t box: 993\r loaded \t image: 80 \t box: 994\r loaded \t image: 80 \t box: 995\r loaded \t image: 80 \t box: 996\r loaded \t image: 80 \t box: 997\r loaded \t image: 80 \t box: 998\r loaded \t image: 81 \t box: 999\r loaded \t image: 81 \t box: 1000\r loaded \t image: 81 \t box: 1001\r loaded \t image: 81 \t box: 1002\r loaded \t image: 81 \t box: 1003\r loaded \t image: 81 \t box: 1004\r loaded \t image: 81 \t box: 1005\r loaded \t image: 81 \t box: 1006\r loaded \t image: 81 \t box: 1007\r loaded \t image: 81 \t box: 1008\r loaded \t image: 81 \t box: 1009\r loaded \t image: 81 \t box: 1010\r loaded \t image: 81 \t box: 1011\r loaded \t image: 81 \t box: 1012\r loaded \t image: 81 \t box: 1013\r loaded \t image: 81 \t box: 1014\r loaded \t image: 81 \t box: 1015\r loaded \t image: 81 \t box: 1016\r loaded \t image: 81 \t box: 1017\r loaded \t image: 81 \t box: 1018\r loaded \t image: 82 \t box: 1019\r loaded \t image: 82 \t box: 1020\r loaded \t image: 82 \t box: 1021\r loaded \t image: 82 \t box: 1022\r loaded \t image: 82 \t box: 1023\r loaded \t image: 82 \t box: 1024\r loaded \t image: 82 \t box: 1025\r loaded \t image: 82 \t box: 1026\r loaded \t image: 82 \t box: 1027\r loaded \t image: 82 \t box: 1028\r loaded \t image: 83 \t box: 1029\r loaded \t image: 83 \t box: 1030\r loaded \t image: 83 \t box: 1031\r loaded \t image: 83 \t box: 1032\r loaded \t image: 83 \t box: 1033\r loaded \t image: 83 \t box: 1034\r loaded \t image: 83 \t box: 1035\r loaded \t image: 83 \t box: 1036\r loaded \t image: 83 \t box: 1037\r loaded \t image: 83 \t box: 1038\r loaded \t image: 83 \t box: 1039\r loaded \t image: 83 \t box: 1040\r loaded \t image: 83 \t box: 1041\r loaded \t image: 83 \t box: 1042\r loaded \t image: 84 \t box: 1043\r loaded \t image: 84 \t box: 1044\r loaded \t image: 84 \t box: 1045\r loaded \t image: 84 \t box: 1046\r loaded \t image: 84 \t box: 1047\r loaded \t image: 84 \t box: 1048\r loaded \t image: 84 \t box: 1049\r loaded \t image: 84 \t box: 1050\r loaded \t image: 84 \t box: 1051\r loaded \t image: 84 \t box: 1052\r loaded \t image: 85 \t box: 1053\r loaded \t image: 85 \t box: 1054\r loaded \t image: 85 \t box: 1055\r loaded \t image: 85 \t box: 1056\r loaded \t image: 85 \t box: 1057\r loaded \t image: 85 \t box: 1058\r loaded \t image: 85 \t box: 1059\r loaded \t image: 85 \t box: 1060\r loaded \t image: 85 \t box: 1061\r loaded \t image: 85 \t box: 1062\r loaded \t image: 85 \t box: 1063\r loaded \t image: 85 \t box: 1064\r loaded \t image: 85 \t box: 1065\r loaded \t image: 85 \t box: 1066\r loaded \t image: 85 \t box: 1067\r loaded \t image: 85 \t box: 1068\r loaded \t image: 86 \t box: 1069\r loaded \t image: 86 \t box: 1070\r loaded \t image: 86 \t box: 1071\r loaded \t image: 86 \t box: 1072\r loaded \t image: 86 \t box: 1073\r loaded \t image: 86 \t box: 1074\r loaded \t image: 86 \t box: 1075\r loaded \t image: 86 \t box: 1076\r loaded \t image: 86 \t box: 1077\r loaded \t image: 86 \t box: 1078\r loaded \t image: 87 \t box: 1079\r loaded \t image: 87 \t box: 1080\r loaded \t image: 87 \t box: 1081\r loaded \t image: 87 \t box: 1082\r loaded \t image: 87 \t box: 1083\r loaded \t image: 87 \t box: 1084\r loaded \t image: 87 \t box: 1085\r loaded \t image: 87 \t box: 1086\r loaded \t image: 87 \t box: 1087\r loaded \t image: 87 \t box: 1088\r loaded \t image: 88 \t box: 1089\r loaded \t image: 88 \t box: 1090\r loaded \t image: 88 \t box: 1091\r loaded \t image: 88 \t box: 1092\r loaded \t image: 88 \t box: 1093\r loaded \t image: 88 \t box: 1094\r loaded \t image: 88 \t box: 1095\r loaded \t image: 88 \t box: 1096\r loaded \t image: 88 \t box: 1097\r loaded \t image: 88 \t box: 1098\r loaded \t image: 89 \t box: 1099\r loaded \t image: 89 \t box: 1100\r loaded \t image: 89 \t box: 1101\r loaded \t image: 89 \t box: 1102\r loaded \t image: 89 \t box: 1103\r loaded \t image: 89 \t box: 1104\r loaded \t image: 89 \t box: 1105\r loaded \t image: 89 \t box: 1106\r loaded \t image: 89 \t box: 1107\r loaded \t image: 89 \t box: 1108\r loaded \t image: 90 \t box: 1109\r loaded \t image: 90 \t box: 1110\r loaded \t image: 90 \t box: 1111\r loaded \t image: 90 \t box: 1112\r loaded \t image: 90 \t box: 1113\r loaded \t image: 90 \t box: 1114\r loaded \t image: 90 \t box: 1115\r loaded \t image: 90 \t box: 1116\r loaded \t image: 90 \t box: 1117\r loaded \t image: 90 \t box: 1118\r loaded \t image: 91 \t box: 1119\r loaded \t image: 91 \t box: 1120\r loaded \t image: 91 \t box: 1121\r loaded \t image: 91 \t box: 1122\r loaded \t image: 91 \t box: 1123\r loaded \t image: 91 \t box: 1124\r loaded \t image: 91 \t box: 1125\r loaded \t image: 91 \t box: 1126\r loaded \t image: 91 \t box: 1127\r loaded \t image: 91 \t box: 1128\r loaded \t image: 92 \t box: 1129\r loaded \t image: 92 \t box: 1130\r loaded \t image: 92 \t box: 1131\r loaded \t image: 92 \t box: 1132\r loaded \t image: 92 \t box: 1133\r loaded \t image: 92 \t box: 1134\r loaded \t image: 92 \t box: 1135\r loaded \t image: 92 \t box: 1136\r loaded \t image: 92 \t box: 1137\r loaded \t image: 92 \t box: 1138\r loaded \t image: 92 \t box: 1139\r loaded \t image: 92 \t box: 1140\r loaded \t image: 92 \t box: 1141\r loaded \t image: 92 \t box: 1142\r loaded \t image: 92 \t box: 1143\r loaded \t image: 92 \t box: 1144\r loaded \t image: 92 \t box: 1145\r loaded \t image: 92 \t box: 1146\r loaded \t image: 93 \t box: 1147\r loaded \t image: 93 \t box: 1148\r loaded \t image: 93 \t box: 1149\r loaded \t image: 93 \t box: 1150\r loaded \t image: 93 \t box: 1151\r loaded \t image: 93 \t box: 1152\r loaded \t image: 93 \t box: 1153\r loaded \t image: 93 \t box: 1154\r loaded \t image: 93 \t box: 1155\r loaded \t image: 93 \t box: 1156\r loaded \t image: 94 \t box: 1157\r loaded \t image: 94 \t box: 1158\r loaded \t image: 94 \t box: 1159\r loaded \t image: 94 \t box: 1160\r loaded \t image: 94 \t box: 1161\r loaded \t image: 94 \t box: 1162\r loaded \t image: 94 \t box: 1163\r loaded \t image: 94 \t box: 1164\r loaded \t image: 94 \t box: 1165\r loaded \t image: 94 \t box: 1166\r loaded \t image: 94 \t box: 1167\r loaded \t image: 94 \t box: 1168\r loaded \t image: 94 \t box: 1169\r loaded \t image: 94 \t box: 1170\r loaded \t image: 94 \t box: 1171\r loaded \t image: 94 \t box: 1172\r loaded \t image: 94 \t box: 1173\r loaded \t image: 94 \t box: 1174\r loaded \t image: 95 \t box: 1175\r loaded \t image: 95 \t box: 1176\r loaded \t image: 95 \t box: 1177\r loaded \t image: 95 \t box: 1178\r loaded \t image: 95 \t box: 1179\r loaded \t image: 95 \t box: 1180\r loaded \t image: 95 \t box: 1181\r loaded \t image: 95 \t box: 1182\r loaded \t image: 95 \t box: 1183\r loaded \t image: 95 \t box: 1184\r loaded \t image: 96 \t box: 1185\r loaded \t image: 96 \t box: 1186\r loaded \t image: 96 \t box: 1187\r loaded \t image: 96 \t box: 1188\r loaded \t image: 96 \t box: 1189\r loaded \t image: 96 \t box: 1190\r loaded \t image: 96 \t box: 1191\r loaded \t image: 96 \t box: 1192\r loaded \t image: 96 \t box: 1193\r loaded \t image: 96 \t box: 1194\r loaded \t image: 97 \t box: 1195\r loaded \t image: 97 \t box: 1196\r loaded \t image: 97 \t box: 1197\r loaded \t image: 97 \t box: 1198\r loaded \t image: 97 \t box: 1199\r loaded \t image: 97 \t box: 1200\r loaded \t image: 97 \t box: 1201\r loaded \t image: 97 \t box: 1202\r loaded \t image: 97 \t box: 1203\r loaded \t image: 97 \t box: 1204\r loaded \t image: 97 \t box: 1205\r loaded \t image: 97 \t box: 1206\r loaded \t image: 97 \t box: 1207\r loaded \t image: 97 \t box: 1208\r loaded \t image: 98 \t box: 1209\r loaded \t image: 98 \t box: 1210\r loaded \t image: 98 \t box: 1211\r loaded \t image: 98 \t box: 1212\r loaded \t image: 98 \t box: 1213\r loaded \t image: 98 \t box: 1214\r loaded \t image: 98 \t box: 1215\r loaded \t image: 98 \t box: 1216\r loaded \t image: 98 \t box: 1217\r loaded \t image: 98 \t box: 1218\r loaded \t image: 99 \t box: 1219\r loaded \t image: 99 \t box: 1220\r loaded \t image: 99 \t box: 1221\r loaded \t image: 99 \t box: 1222\r loaded \t image: 99 \t box: 1223\r loaded \t image: 99 \t box: 1224\r loaded \t image: 99 \t box: 1225\r loaded \t image: 99 \t box: 1226\r loaded \t image: 99 \t box: 1227\r loaded \t image: 99 \t box: 1228\r loaded \t image: 99 \t box: 1229\r loaded \t image: 99 \t box: 1230\r loaded \t image: 99 \t box: 1231\r loaded \t image: 99 \t box: 1232\r loaded \t image: 100 \t box: 1233\r loaded \t image: 100 \t box: 1234\r loaded \t image: 100 \t box: 1235\r loaded \t image: 100 \t box: 1236\r loaded \t image: 100 \t box: 1237\r loaded \t image: 100 \t box: 1238\r loaded \t image: 100 \t box: 1239\r loaded \t image: 100 \t box: 1240\r loaded \t image: 100 \t box: 1241\r loaded \t image: 100 \t box: 1242\n",
            " all loaded. \n",
            "\n",
            " calculating k-means++ ...\n",
            "\n",
            " iterations = 6 \n",
            "\n",
            "\n",
            " avg IoU = 96.31 % \n",
            "\n",
            "Saving anchors to the file: anchors.txt \n",
            "anchors =   8,  4,   8,  4,   8,  4,   8,  8,   8,  8,   8,  8,   8,  8,   8,  8,   6, 12\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1-iarna4GUP",
        "colab_type": "text"
      },
      "source": [
        "### Configure training files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6-oZzb_DJMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show\n",
        "%pycat example/cfg/yolo.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKyTZzW7DiU0",
        "colab_type": "code",
        "outputId": "0d2f5423-dc4e-4129-821c-53d62fcf3ec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# write configuration file with desired modifictions\n",
        "%%writefile example/cfg/yolo.py\n",
        "\n",
        "import lightnet as ln\n",
        "import torch\n",
        "\n",
        "__all__ = ['params']\n",
        "\n",
        "\n",
        "params = ln.engine.HyperParameters( \n",
        "    # Network\n",
        "    class_label_map = ['rob', 'valve'],\n",
        "    _input_dimension = (1024, 1024),\n",
        "    _batch_size = 32,\n",
        "    _mini_batch_size = 4,\n",
        "    _max_batches = 80200,\n",
        "\n",
        "    # Dataset\n",
        "    _train_set = 'train.h5',\n",
        "    _test_set = 'test.h5',\n",
        "    _filter_anno = 'ignore',\n",
        "\n",
        "    # Data Augmentation\n",
        "    _jitter = 0.0,\n",
        "    _flip = 0.0,\n",
        "    _hue = 0.0,\n",
        "    _saturation = 0.0,\n",
        "    _value = 0.0,\n",
        ")\n",
        "\n",
        "# Network\n",
        "def init_weights(m):\n",
        "    if isinstance(m, torch.nn.Conv2d):\n",
        "        torch.nn.init.kaiming_normal_(m.weight, nonlinearity='leaky_relu')\n",
        "\n",
        "params.network = ln.models.YoloV3(len(params.class_label_map))\n",
        "params.network.apply(init_weights)\n",
        "params.network.anchors = [[(8, 4), (8, 4), (8, 4)], [(8, 8), (8, 8), (8, 8)], [(8, 8), (8, 8), (6, 12)]] \n",
        "\n",
        "\n",
        "# Loss\n",
        "params.loss = ln.network.loss.MultiScaleRegionLoss(\n",
        "    len(params.class_label_map),\n",
        "    params.network.anchors,\n",
        "    params.network.stride,\n",
        ")\n",
        "\n",
        "# Postprocessing\n",
        "params._post = ln.data.transform.Compose([\n",
        "    ln.data.transform.GetMultiScaleBoundingBoxes(len(params.class_label_map), params.network.anchors, 0.001),\n",
        "    ln.data.transform.NonMaxSuppression(0.5),\n",
        "    ln.data.transform.TensorToBrambox(params.input_dimension, params.class_label_map),\n",
        "])\n",
        "\n",
        "# Optimizer\n",
        "params.optimizer = torch.optim.SGD(\n",
        "    params.network.parameters(),\n",
        "    lr = .001,\n",
        "    momentum = .9,\n",
        "    weight_decay = .0005,\n",
        "    dampening = 0,\n",
        ")\n",
        "\n",
        "# Scheduler\n",
        "burn_in = torch.optim.lr_scheduler.LambdaLR(\n",
        "    params.optimizer,\n",
        "    lambda b: (b / 1000) ** 4,\n",
        ")\n",
        "step = torch.optim.lr_scheduler.MultiStepLR(\n",
        "    params.optimizer,\n",
        "    milestones = [40000, 60000],\n",
        "    gamma = .1,\n",
        ")\n",
        "params.scheduler = ln.engine.SchedulerCompositor(\n",
        "#   batch   scheduler\n",
        "    (0,     burn_in),\n",
        "    (1000,  step),\n",
        ")\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting example/cfg/yolo.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZ84t4q4O6S2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show\n",
        "%pycat example/bin/train.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqWQQDA6O9r5",
        "colab_type": "code",
        "outputId": "b6b9b95e-eebb-4381-9801-658f04fd0757",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile example/bin/train.py\n",
        "\n",
        "#!/usr/bin/env python\n",
        "import os\n",
        "import logging\n",
        "import time\n",
        "import argparse\n",
        "from math import isinf, isnan\n",
        "from statistics import mean\n",
        "import torch\n",
        "import visdom\n",
        "import numpy as np\n",
        "import lightnet as ln\n",
        "from datasetPerso import valveDataset\n",
        "from pathlib import Path\n",
        "import brambox as bb\n",
        "from PIL import Image\n",
        "\n",
        "log = logging.getLogger('lightnet.VOC.train')\n",
        "\n",
        "\n",
        "class TrainEngine(ln.engine.Engine):\n",
        "    def start(self):\n",
        "        self.params.to(self.device)\n",
        "        self.dataloader.change_input_dim()\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        self.train_loss = {'tot': [], 'coord': [], 'conf': [], 'cls': []}\n",
        "        self.plot_train_loss = ln.engine.LinePlotter(self.visdom, 'train_loss', opts=dict(xlabel='Batch', ylabel='Loss', title='Training Loss', showlegend=True, legend=['Total loss', 'Coordinate loss', 'Confidence loss', 'Class loss']))\n",
        "        self.plot_lr = ln.engine.LinePlotter(self.visdom, 'learning_rate', name='Learning Rate', opts=dict(xlabel='Batch', ylabel='Learning Rate', title='Learning Rate Schedule'))\n",
        "        self.batch_end(self.plot_rate)(self.plot)\n",
        "\n",
        "    def process_batch(self, data):\n",
        "        data, target = data\n",
        "        data = data.to(self.device)\n",
        "\n",
        "        out = self.network(data)\n",
        "        loss = self.loss(out, target) / self.batch_subdivisions\n",
        "        loss.backward()\n",
        "\n",
        "        self.train_loss['tot'].append(self.loss.loss_tot.item())\n",
        "        self.train_loss['coord'].append(self.loss.loss_coord.item())\n",
        "        self.train_loss['conf'].append(self.loss.loss_conf.item())\n",
        "        self.train_loss['cls'].append(self.loss.loss_cls.item())\n",
        "\n",
        "    def train_batch(self):\n",
        "        self.optimizer.step()\n",
        "        self.optimizer.zero_grad()\n",
        "        self.scheduler.step(self.batch, epoch=self.batch)\n",
        "\n",
        "        # Get values from last batch\n",
        "        tot = mean(self.train_loss['tot'][-self.batch_subdivisions:])\n",
        "        coord = mean(self.train_loss['coord'][-self.batch_subdivisions:])\n",
        "        conf = mean(self.train_loss['conf'][-self.batch_subdivisions:])\n",
        "        cls = mean(self.train_loss['cls'][-self.batch_subdivisions:])\n",
        "        self.log(f'{self.batch} Loss:{tot:.5f} (Coord:{coord:.2f} Conf:{conf:.2f} Cls:{cls:.2f})')\n",
        "\n",
        "        if isinf(tot) or isnan(tot):\n",
        "            log.error('Infinite loss')\n",
        "            self.sigint = True\n",
        "            return\n",
        "\n",
        "    def plot(self):\n",
        "        tot = mean(self.train_loss['tot'])\n",
        "        coord = mean(self.train_loss['coord'])\n",
        "        conf = mean(self.train_loss['conf'])\n",
        "        cls = mean(self.train_loss['cls'])\n",
        "        self.train_loss = {'tot': [], 'coord': [], 'conf': [], 'cls': []}\n",
        "\n",
        "        self.plot_train_loss(np.array([[tot, coord, conf, cls]]), np.array([self.batch]))\n",
        "        self.plot_lr(np.array([self.optimizer.param_groups[0]['lr']]), np.array([self.batch]))\n",
        "\n",
        "    @ln.engine.Engine.batch_end(500)\n",
        "    def backup(self):\n",
        "        self.params.save(os.path.join(self.backup_folder, f'weights_{self.batch}.state.pt'))\n",
        "        log.info(f'Saved backup')\n",
        "\n",
        "    @ln.engine.Engine.batch_end(10)\n",
        "    def resize(self):\n",
        "        if self.batch >= self.max_batches - 200:\n",
        "        \tself.dataloader.change_input_dim(self.input_dimension, None)\n",
        "        else:\n",
        "        \tself.dataloader.change_input_dim()\n",
        "\n",
        "    def quit(self):\n",
        "        if self.batch >= self.max_batches:\n",
        "            self.params.network.save(os.path.join(self.backup_folder, 'final.pt'))\n",
        "            return True\n",
        "        elif self.sigint:\n",
        "            self.params.save(os.path.join(self.backup_folder, 'backup.state.pt'))\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description='Train network',\n",
        "        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n",
        "    )\n",
        "    parser.add_argument('weight', help='Path to weight file', default=None, nargs='?')\n",
        "    parser.add_argument('-n', '--network', help='network config file', required=True)\n",
        "    parser.add_argument('-c', '--cuda', action='store_true', help='Use cuda')\n",
        "    parser.add_argument('-b', '--backup', metavar='folder', help='Backup folder', default='./backup')\n",
        "    parser.add_argument('-v', '--visdom', action='store_true', help='Visualize training data with visdom')\n",
        "    parser.add_argument('-e', '--visdom_env', help='Visdom environment to plot to', default='main')\n",
        "    parser.add_argument('-p', '--visdom_port', help='Port of the visdom server', type=int, default=8080)\n",
        "    parser.add_argument('-r', '--visdom_rate', help='How often to plot to visdom (batches)', type=int, default=1)\n",
        "    parser.add_argument('-a', '--anno', help='annotation folder', default='./data')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Parse arguments\n",
        "    device = torch.device('cpu')\n",
        "    if args.cuda:\n",
        "        if torch.cuda.is_available():\n",
        "            log.debug('CUDA enabled')\n",
        "            device = torch.device('cuda')\n",
        "        else:\n",
        "            log.error('CUDA not available')\n",
        "\n",
        "    if not os.path.isdir(args.backup):\n",
        "        if not os.path.exists(args.backup):\n",
        "            log.warning('Backup folder does not exist, creating...')\n",
        "            os.makedirs(args.backup)\n",
        "        else:\n",
        "            raise ValueError('Backup path is not a folder')\n",
        "    \n",
        "    if args.visdom:\n",
        "        visdom = visdom.Visdom(port=args.visdom_port, env=args.visdom_env)\n",
        "    else:\n",
        "        visdom = None\n",
        "\n",
        "    params = ln.engine.HyperParameters.from_file(args.network)\n",
        "    if args.weight is not None:\n",
        "        if args.weight.endswith('.state.pt'):\n",
        "            params.load(args.weight)\n",
        "        else:\n",
        "            params.network.load(args.weight, strict=False)  # Disable strict mode for loading partial weights\n",
        "\n",
        "   # Dataloader\n",
        "    dataPath = Path(args.anno)\n",
        "    training_loader = ln.data.DataLoader(\n",
        "        valveDataset(dataPath, params, False),\n",
        "        batch_size = params.mini_batch_size,\n",
        "        shuffle = True,\n",
        "        drop_last = True,\n",
        "        num_workers = 1,\n",
        "        pin_memory = True,\n",
        "        collate_fn = ln.data.brambox_collate,\n",
        "    )\n",
        "\n",
        "    # Start training\n",
        "    eng = TrainEngine(\n",
        "        params, training_loader,\n",
        "        device=device, visdom=visdom, plot_rate=args.visdom_rate, backup_folder=args.backup\n",
        "    )\n",
        "    b1 = eng.batch\n",
        "    t1 = time.time()\n",
        "    eng()\n",
        "    t2 = time.time()\n",
        "    b2 = eng.batch\n",
        "    log.info(f'Training {b2-b1} batches took {t2-t1:.2f} seconds [{(t2-t1)/(b2-b1):.3f} sec/batch]')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting example/bin/train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nEX5GJeptuO",
        "colab_type": "text"
      },
      "source": [
        "# Configure path to pictures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3FU8KwkpvAw",
        "colab_type": "code",
        "outputId": "688cc7b6-701a-44ad-fa4b-213b5be0a3b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Modify datasetPerso.py to correctly\n",
        "# identify the path where images & annotations are stored\n",
        "# no automated way at the moment\n",
        "\n",
        "%%writefile example/bin/datasetPerso.py\n",
        "\n",
        "import copy\n",
        "import logging\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms as tf\n",
        "import brambox as bb\n",
        "import lightnet as ln\n",
        "from pathlib import Path\n",
        "\n",
        "__all__ = ['valveDataset']\n",
        "log = logging.getLogger('lightnet.valve.dataset')\n",
        "\n",
        "# one needs to define  this function at the top of the module\n",
        "# otherwhise, Python raises a \"Can't picle local object error\"\n",
        "# when going multiprocessing\n",
        "# This is apparently specific to Windows ... ?\n",
        "\n",
        "def identify_file(img_id):\n",
        "    root = Path(r\"/content/objectDetection-lightnet/data/images/valves\")\n",
        "    return Path.joinpath(root, img_id + '.png')\n",
        "\n",
        "class valveDataset(ln.models.BramboxDataset):\n",
        "    \"\"\" valves dataset, with annotations generated by `brambox.io.parser.DarknetParser`\n",
        "\n",
        "    Args:\n",
        "        anno_path (str or Path): Path to annotation location (must be parseable by DarknetParser)\n",
        "        params (lightnet.engine.HyperParameters): Hyperparameters for this data (See Note)\n",
        "        augment (boolean): Whether to perform data augmentation\n",
        "        kwargs (optional): extra keyword arguments to pass on to the `brambox.io.load()` function\n",
        "\n",
        "    Note:\n",
        "        The hyperparameters object should at least contain the following attributes:\n",
        "\n",
        "        - params.input_dimension (tuple): tuple containing base (width,height) for the network\n",
        "        - params.class_label_map (list): List of class_labels (can be **None**, but this might lead to undeterministic behaviour)\n",
        "        - params.anno_filter (str, optional): How to filter difficult annotations: ['ignore', 'rm', 'none']; Default **'none'**\n",
        "        - params.flip (float): chance to flip the image\n",
        "        - params.jitter (float): jitter percentage\n",
        "        - params.hue (float): Hue change percentage\n",
        "        - params.saturation (float): Saturation change percentage\n",
        "        - params.value (float): Value change percentage\n",
        "    \"\"\"\n",
        "    def __init__(self, anno_path, params, augment, **kwargs):        \n",
        "        \n",
        "        anno_path = Path(anno_path)\n",
        "        anno = []\n",
        "        for file in anno_path.iterdir():\n",
        "            if file.suffix == \".txt\":\n",
        "                anno.append(file)\n",
        "\n",
        "        # Create dataframe containig all annotations data\n",
        "        # data has to be structured as expected i.e.\n",
        "        # one data folder containing images & annotations structured like \n",
        "        #\n",
        "        # image000.txt, image000.png\n",
        "        # image001.txt, image000.png\n",
        "        #\n",
        "        # the names don't matter BUT they must be consistent between annotation & related picture\n",
        "        # also the annotations must be in Darknet brambox format i.e.\n",
        "        #\n",
        "        # label xcenter ycenter width height\n",
        "        #\n",
        "        # all expressed relative to the total image width and height\n",
        "        # origin for the coordinates is the bottom left corner of the picture\n",
        "\n",
        "        def getImageDims(id):\n",
        "            # hardcoded at the moment ... did not yet find/implemented a proper way\n",
        "            root = Path(r\"/content/objectDetection-lightnet/data/images/valves\")\n",
        "            im = Image.open(Path.joinpath(root, id + \".png\"))\n",
        "            width, height = im.size\n",
        "            return (width, height)\n",
        "            \n",
        "        annos = bb.io.load(bb.io.parser.annotation.DarknetParser(getImageDims, params.class_label_map), anno)\n",
        "\n",
        "        img_tf = ln.data.transform.Compose([tf.ToTensor()])\n",
        "        anno_tf = None\n",
        "        if augment :\n",
        "            rf  = ln.data.transform.RandomFlip(params.flip)\n",
        "            rc  = ln.data.transform.RandomJitter(params.jitter, True, 0.1)\n",
        "            hsv = ln.data.transform.RandomHSV(params.hue, params.saturation, params.value)\n",
        "            img_tf[0:0] = [hsv, rc, rf]\n",
        "            anno_tf[0:0] = [rc, rf]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        super().__init__(annos, params.input_dimension, params.class_label_map, identify_file, img_tf, anno_tf)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting example/bin/datasetPerso.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAqxanCq4N8J",
        "colab_type": "text"
      },
      "source": [
        "# Train on personal dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h77HQ85clFAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fetch pre-trained weights\n",
        "# those weights are stored on drive and were downloaded from lightnet repo https://gitlab.com/EAVISE/lightnet/blob/master/docs/notes/02-C-pascal_voc.rst\n",
        "!mkdir /content/objectDetection-lightnet/data/weights\n",
        "!cp -r \"/content/gdrive/My Drive/dataManagement/lightnet/backup/yolov3-coco.pt\" /content/objectDetection-lightnet/data/weights/."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3iY_XIPMgi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# or fetch weights from previous training\n",
        "!mkdir /content/objectDetection-lightnet/data/weights\n",
        "!cp -r \"/content/gdrive/My Drive/dataManagement/lightnet/backup/weights_21000.state.pt\" \"/content/objectDetection-lightnet/data/weights/.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhW5apEKntaW",
        "colab_type": "code",
        "outputId": "2f6a8268-6f1f-4838-ca29-12168b153ed9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "# install missing packages\n",
        "pip install visdom"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting visdom\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/75/e078f5a2e1df7e0d3044749089fc2823e62d029cc027ed8ae5d71fafcbdc/visdom-0.1.8.9.tar.gz (676kB)\n",
            "\r\u001b[K     |▌                               | 10kB 7.7MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 3.3MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51kB 3.4MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 4.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71kB 4.3MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81kB 4.5MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92kB 5.0MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 112kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 143kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 174kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 194kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 204kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 225kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 235kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 256kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 266kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 286kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 307kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 327kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 348kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 358kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 368kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 378kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 389kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 399kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 409kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 419kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 430kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 440kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 450kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 460kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 471kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 481kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 491kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 501kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 512kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 522kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 532kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 542kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 552kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 563kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 573kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 583kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 593kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 604kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 614kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 624kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 634kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 645kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 655kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 665kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 675kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 686kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.6/dist-packages (from visdom) (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from visdom) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from visdom) (2.21.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from visdom) (4.5.3)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from visdom) (17.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from visdom) (1.12.0)\n",
            "Collecting jsonpatch\n",
            "  Downloading https://files.pythonhosted.org/packages/82/53/73ca86f2a680c705dcd1708be4887c559dfe9ed250486dd3ccd8821b8ccb/jsonpatch-1.25-py2.py3-none-any.whl\n",
            "Collecting torchfile\n",
            "  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n",
            "Collecting websocket-client\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 24.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from visdom) (6.2.2)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->visdom) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->visdom) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->visdom) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->visdom) (2019.11.28)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading https://files.pythonhosted.org/packages/18/b0/a80d29577c08eea401659254dfaed87f1af45272899e1812d7e01b679bc5/jsonpointer-2.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: visdom, torchfile\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.9-cp36-none-any.whl size=655250 sha256=e8d8593ae1a87c5f78b36ad2f1c0cadb76de0b9f623c51f8292060fce367f50f\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/19/a7/6d589ed967f4dfefd33bc166d081257bd4ed0cb618dccfd62a\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-cp36-none-any.whl size=5712 sha256=fc2721ebafe54d5812bde395a42542767ec1f49cd3c65249990837afa0fde10c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n",
            "Successfully built visdom torchfile\n",
            "Installing collected packages: jsonpointer, jsonpatch, torchfile, websocket-client, visdom\n",
            "Successfully installed jsonpatch-1.25 jsonpointer-2.0 torchfile-0.1.0 visdom-0.1.8.9 websocket-client-0.57.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyT0IkfTmDcz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "outputId": "a7a6b8f8-794e-465c-b833-e7c9da69a6d1"
      },
      "source": [
        "# check some training pictures\n",
        "from google.colab.patches import cv2_imshow\n",
        "im = cv2.imread('data/images/valves/train_sample_0.png')\n",
        "cv2_imshow(im)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABAAAAALACAIAAACCR5daAADEfElEQVR4nOzdeXxT1503/iMbYxsb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\nv3/+Df4/cHLgIks7qqIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=1024x704 at 0x7F52CF1F0AC8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5bD4PjWwCBr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e12751a-e122-499c-852c-85e0d3dfda3e"
      },
      "source": [
        "%%writefile lightnet/network/loss/_regionloss.py\n",
        "#   Darknet RegionLoss\n",
        "#   Copyright EAVISE\n",
        "#\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from distutils.version import LooseVersion\n",
        "\n",
        "try:\n",
        "    import pandas as pd\n",
        "except ModuleNotFoundError:\n",
        "    pd = None\n",
        "\n",
        "__all__ = ['RegionLoss']\n",
        "\n",
        "torchversion = LooseVersion(torch.__version__)\n",
        "version120 = LooseVersion(\"1.2.0\")\n",
        "\n",
        "\n",
        "class RegionLoss(nn.modules.loss._Loss):\n",
        "    \"\"\" Computes region loss from darknet network output and target annotation.\n",
        "\n",
        "    Args:\n",
        "        num_classes (int): number of classes to detect\n",
        "        anchors (list): 2D list representing anchor boxes (see :class:`lightnet.network.Darknet`)\n",
        "        stride (optional, int): The downsampling factor of the network (input_dimension / output_dimension); Default **32**\n",
        "        seen (optional, torch.Tensor): How many images the network has already been trained on; Default **0**\n",
        "        coord_scale (optional, float): weight of bounding box coordinates; Default **1.0**\n",
        "        noobject_scale (optional, float): weight of regions without target boxes; Default **1.0**\n",
        "        object_scale (optional, float): weight of regions with target boxes; Default **5.0**\n",
        "        class_scale (optional, float): weight of categorical predictions; Default **1.0**\n",
        "        thresh (optional, float): minimum iou between a predicted box and ground truth for them to be considered matching; Default **0.6**\n",
        "        coord_prefill (optional, int): This parameter controls for how many images the network will prefill the target coordinates, biassing the network to predict the center at **.5,.5**; Default **12800**\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes, anchors, stride=32, seen=0, coord_scale=1.0, noobject_scale=1.0, object_scale=5.0, class_scale=1.0, thresh=0.6, coord_prefill=12800):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.num_anchors = len(anchors)\n",
        "        self.anchor_step = len(anchors[0])\n",
        "        self.anchors = torch.Tensor(anchors)\n",
        "        self.stride = stride\n",
        "        self.register_buffer('seen', torch.tensor(seen))\n",
        "\n",
        "        self.coord_scale = coord_scale\n",
        "        self.noobject_scale = noobject_scale\n",
        "        self.object_scale = object_scale\n",
        "        self.class_scale = class_scale\n",
        "        self.thresh = thresh\n",
        "        self.coord_prefill = coord_prefill\n",
        "\n",
        "        self.mse = nn.MSELoss(reduction='sum')\n",
        "        self.cel = nn.CrossEntropyLoss(reduction='sum')\n",
        "\n",
        "    def extra_repr(self):\n",
        "        repr_str = f'classes={self.num_classes}, stride={self.stride}, threshold={self.thresh}, seen={self.seen.item()}\\n'\n",
        "        repr_str += f'coord_scale={self.coord_scale}, object_scale={self.object_scale}, noobject_scale={self.noobject_scale}, class_scale={self.class_scale}\\n'\n",
        "        repr_str += f'anchors='\n",
        "        for a in self.anchors:\n",
        "            repr_str += f'[{a[0]:.5g}, {a[1]:.5g}] '\n",
        "        return repr_str\n",
        "\n",
        "    def forward(self, output, target, seen=None):\n",
        "        \"\"\" Compute Region loss.\n",
        "\n",
        "        Args:\n",
        "            output (torch.autograd.Variable): Output from the network\n",
        "            target (brambox annotation dataframe or torch.Tensor): Brambox annotations or tensor containing the annotation targets (see :class:`lightnet.data.BramboxToTensor`)\n",
        "            seen (int, optional): How many images the network has already been trained on; Default **Add batch_size to previous seen value**\n",
        "\n",
        "        Note:\n",
        "            If using a target tensor, it should have the dimensions `[num_batch, num_anno, 5]` and following format per image:\n",
        "\n",
        "            .. math::\n",
        "\n",
        "                \\\\begin{bmatrix}\n",
        "                    class\\\\_idx & x\\\\_center & y\\\\_center & width & height \\\\\\\\\n",
        "                    class\\\\_idx & x\\\\_center & y\\\\_center & width & height \\\\\\\\\n",
        "                    ... \\\\\\\\\n",
        "                    -1 & 0 & 0 & 0 & 0 \\\\\\\\\n",
        "                    -1 & 0 & 0 & 0 & 0 \\\\\\\\\n",
        "                    ...\n",
        "                \\\\end{bmatrix}\n",
        "\n",
        "            With all coordinates being relative to the image size. |br|\n",
        "            Since the annotations from all images of a batch should be made of the same length, you can pad them with: `[-1, 0, 0, 0, 0]`.\n",
        "\n",
        "        Note:\n",
        "            Besides being easier to work with, brambox dataframes have the added benefit that\n",
        "            this loss function will also consider the ``ignore`` flag of annotations and ignore detections that match with it.\n",
        "            This allows you to have annotations that will not influence the loss in any way,\n",
        "            as opposed to having them removed and counting them as false detections.\n",
        "        \"\"\"\n",
        "        # Parameters\n",
        "        nB = output.data.size(0)\n",
        "        nA = self.num_anchors\n",
        "        nC = self.num_classes\n",
        "        nH = output.data.size(2)\n",
        "        nW = output.data.size(3)\n",
        "        nPixels = nH * nW\n",
        "        device = output.device\n",
        "        if seen is not None:\n",
        "            self.seen = torch.tensor(seen)\n",
        "        elif self.training:\n",
        "            self.seen += nB\n",
        "\n",
        "        # Get x,y,w,h,conf,cls\n",
        "        output = output.view(nB, nA, -1, nPixels)\n",
        "        coord = torch.zeros_like(output[:, :, :4])\n",
        "        coord[:, :, :2] = output[:, :, :2].sigmoid()    # tx,ty\n",
        "        coord[:, :, 2:4] = output[:, :, 2:4]            # tw,th\n",
        "        conf = output[:, :, 4].sigmoid()\n",
        "        if nC > 1:\n",
        "            cls = output[:, :, 5:].contiguous().view(nB*nA, nC, nPixels).transpose(1, 2).contiguous().view(-1, nC)\n",
        "\n",
        "        # Create prediction boxes\n",
        "        pred_boxes = torch.FloatTensor(nB*nA*nPixels, 4)\n",
        "        lin_x = torch.linspace(0, nW-1, nW).repeat(nH, 1).view(nPixels).to(device)\n",
        "        lin_y = torch.linspace(0, nH-1, nH).view(nH, 1).repeat(1, nW).view(nPixels).to(device)\n",
        "        anchor_w = self.anchors[:, 0].contiguous().view(nA, 1).to(device)\n",
        "        anchor_h = self.anchors[:, 1].contiguous().view(nA, 1).to(device)\n",
        "\n",
        "        pred_boxes[:, 0] = (coord[:, :, 0].detach() + lin_x).view(-1)\n",
        "        pred_boxes[:, 1] = (coord[:, :, 1].detach() + lin_y).view(-1)\n",
        "        pred_boxes[:, 2] = (coord[:, :, 2].detach().exp() * anchor_w.float()).view(-1)\n",
        "        pred_boxes[:, 3] = (coord[:, :, 3].detach().exp() * anchor_h.float()).view(-1)\n",
        "        pred_boxes = pred_boxes.cpu()\n",
        "\n",
        "        # Get target values\n",
        "        coord_mask, conf_mask, cls_mask, tcoord, tconf, tcls = self.build_targets(pred_boxes, target, nB, nH, nW)\n",
        "        coord_mask = coord_mask.expand_as(tcoord).to(device).sqrt()\n",
        "        conf_mask = conf_mask.to(device).sqrt()\n",
        "        tcoord = tcoord.to(device)\n",
        "        tconf = tconf.to(device)\n",
        "        if nC > 1:\n",
        "            tcls = tcls[cls_mask].view(-1).long().to(device)\n",
        "            cls_mask = cls_mask.view(-1, 1).repeat(1, nC).to(device)\n",
        "            cls = cls[cls_mask].view(-1, nC)\n",
        "\n",
        "        # Compute losses\n",
        "        self.loss_coord = self.coord_scale * self.mse(coord*coord_mask, tcoord*coord_mask) / (2 * nB)\n",
        "        self.loss_conf = self.mse(conf*conf_mask, tconf*conf_mask) / (2 * nB)\n",
        "        if nC > 1:\n",
        "            if tcls.numel() > 0:\n",
        "                self.loss_cls = self.class_scale * self.cel(cls, tcls) / nB\n",
        "            else:\n",
        "                self.loss_cls = torch.tensor(0.0).to(device)\n",
        "            self.loss_tot = self.loss_coord + self.loss_conf + self.loss_cls\n",
        "        else:\n",
        "            self.loss_cls = torch.tensor(0.0)\n",
        "            self.loss_tot = self.loss_coord + self.loss_conf\n",
        "\n",
        "        return self.loss_tot\n",
        "\n",
        "    def build_targets(self, pred_boxes, ground_truth, nB, nH, nW):\n",
        "        \"\"\" Compare prediction boxes and targets, convert targets to network output tensors \"\"\"\n",
        "        if torch.is_tensor(ground_truth):\n",
        "            return self.__build_targets_tensor(pred_boxes, ground_truth, nB, nH, nW)\n",
        "        elif pd is not None and isinstance(ground_truth, pd.DataFrame):\n",
        "            return self.__build_targets_brambox(pred_boxes, ground_truth, nB, nH, nW)\n",
        "        else:\n",
        "            raise TypeError(f'Unkown ground truth format [{type(ground_truth)}]')\n",
        "\n",
        "    def __build_targets_tensor(self, pred_boxes, ground_truth, nB, nH, nW):\n",
        "        \"\"\" Compare prediction boxes and ground truths, convert ground truths to network output tensors \"\"\"\n",
        "        # Parameters\n",
        "        nT = ground_truth.size(1)\n",
        "        nA = self.num_anchors\n",
        "        nAnchors = nA*nH*nW\n",
        "        nPixels = nH*nW\n",
        "\n",
        "        # Tensors\n",
        "        coord_mask = torch.zeros(nB, nA, nH, nW, requires_grad=False)\n",
        "        conf_mask = torch.ones(nB, nA, nH, nW, requires_grad=False) * self.noobject_scale\n",
        "        if torchversion >= version120:\n",
        "            cls_mask = torch.zeros(nB, nA, nH, nW, dtype=torch.bool, requires_grad=False)\n",
        "        else:\n",
        "            cls_mask = torch.zeros(nB, nA, nH, nW, requires_grad=False).byte()\n",
        "        tcoord = torch.zeros(nB, nA, 4, nH, nW, requires_grad=False)\n",
        "        tconf = torch.zeros(nB, nA, nH, nW, requires_grad=False)\n",
        "        tcls = torch.zeros(nB, nA, nH, nW, requires_grad=False)\n",
        "\n",
        "        if self.training and self.seen < self.coord_prefill:\n",
        "            coord_mask.fill_(math.sqrt(.01 / self.coord_scale))\n",
        "            if self.anchor_step == 4:\n",
        "                tcoord[:, :, 0] = self.anchors[:, 2].contiguous().view(1, nA, 1, 1).repeat(nB, 1, 1, nPixels)\n",
        "                tcoord[:, :, 1] = self.anchors[:, 3].contiguous().view(1, nA, 1, 1).repeat(nB, 1, 1, nPixels)\n",
        "            else:\n",
        "                tcoord[:, :, 0].fill_(0.5)\n",
        "                tcoord[:, :, 1].fill_(0.5)\n",
        "\n",
        "        for b in range(nB):\n",
        "            gt = ground_truth[b][(ground_truth[b, :, 0] >= 0)[:, None].expand_as(ground_truth[b])].view(-1, 5)\n",
        "            if gt.numel() == 0:     # No gt for this image\n",
        "                continue\n",
        "\n",
        "            # Build up tensors\n",
        "            cur_pred_boxes = pred_boxes[b*nAnchors:(b+1)*nAnchors]\n",
        "            if self.anchor_step == 4:\n",
        "                anchors = self.anchors.clone()\n",
        "                anchors[:, :2] = 0\n",
        "            else:\n",
        "                anchors = torch.cat([torch.zeros_like(self.anchors), self.anchors], 1)\n",
        "\n",
        "            gt = gt[:, 1:]\n",
        "            gt[:, ::2] *= nW\n",
        "            gt[:, 1::2] *= nH\n",
        "\n",
        "            # Set confidence mask of matching detections to 0\n",
        "            iou_gt_pred = bbox_ious(gt, cur_pred_boxes)\n",
        "            mask = (iou_gt_pred > self.thresh).sum(0) >= 1\n",
        "            conf_mask[b][mask.view_as(conf_mask[b])] = 0\n",
        "\n",
        "            # Find best anchor for each gt\n",
        "            iou_gt_anchors = bbox_wh_ious(gt, anchors)\n",
        "            _, best_anchors = iou_gt_anchors.max(1)\n",
        "\n",
        "            # Set masks and target values for each gt\n",
        "            nGT = gt.shape[0]\n",
        "            gi = gt[:, 0].clamp(0, nW-1).long()\n",
        "            gj = gt[:, 1].clamp(0, nH-1).long()\n",
        "\n",
        "            conf_mask[b, best_anchors, gj, gi] = self.object_scale\n",
        "            tconf[b, best_anchors, gj, gi] = iou_gt_pred.view(nGT, nA, nH, nW)[torch.arange(nGT), best_anchors, gj, gi]\n",
        "            coord_mask[b, best_anchors, gj, gi] = 2 - (gt[:, 2] * gt[:, 3]) / nPixels\n",
        "            tcoord[b, best_anchors, 0, gj, gi] = gt[:, 0] - gi.float()\n",
        "            tcoord[b, best_anchors, 1, gj, gi] = gt[:, 1] - gj.float()\n",
        "            tcoord[b, best_anchors, 2, gj, gi] = (gt[:, 2] / self.anchors[best_anchors, 0]).log()\n",
        "            tcoord[b, best_anchors, 3, gj, gi] = (gt[:, 3] / self.anchors[best_anchors, 1]).log()\n",
        "            cls_mask[b, best_anchors, gj, gi] = 1\n",
        "            tcls[b, best_anchors, gj, gi] = ground_truth[b, torch.arange(nGT), 0]\n",
        "\n",
        "        return (\n",
        "            coord_mask.view(nB, nA, 1, nPixels),\n",
        "            conf_mask.view(nB, nA, nPixels),\n",
        "            cls_mask.view(nB, nA, nPixels),\n",
        "            tcoord.view(nB, nA, 4, nPixels),\n",
        "            tconf.view(nB, nA, nPixels),\n",
        "            tcls.view(nB, nA, nPixels)\n",
        "        )\n",
        "\n",
        "    def __build_targets_brambox(self, pred_boxes, ground_truth, nB, nH, nW):\n",
        "        \"\"\" Compare prediction boxes and ground truths, convert ground truths to network output tensors \"\"\"\n",
        "        # Parameters\n",
        "        nA = self.num_anchors\n",
        "        nAnchors = nA*nH*nW\n",
        "        nPixels = nH*nW\n",
        "\n",
        "        # Tensors\n",
        "        coord_mask = torch.zeros(nB, nA, nH, nW, requires_grad=False)\n",
        "        conf_mask = torch.ones(nB, nA, nH, nW, requires_grad=False) * self.noobject_scale\n",
        "        if torchversion >= version120:\n",
        "            cls_mask = torch.zeros(nB, nA, nH, nW, dtype=torch.bool, requires_grad=False)\n",
        "        else:\n",
        "            cls_mask = torch.zeros(nB, nA, nH, nW, requires_grad=False).byte()\n",
        "        tcoord = torch.zeros(nB, nA, 4, nH, nW, requires_grad=False)\n",
        "        tconf = torch.zeros(nB, nA, nH, nW, requires_grad=False)\n",
        "        tcls = torch.zeros(nB, nA, nH, nW, requires_grad=False)\n",
        "\n",
        "        if self.training and self.seen < self.coord_prefill:\n",
        "            coord_mask.fill_(math.sqrt(.01 / self.coord_scale))\n",
        "            if self.anchor_step == 4:\n",
        "                tcoord[:, :, 0] = self.anchors[:, 2].contiguous().view(1, nA, 1, 1).repeat(nB, 1, 1, nPixels)\n",
        "                tcoord[:, :, 1] = self.anchors[:, 3].contiguous().view(1, nA, 1, 1).repeat(nB, 1, 1, nPixels)\n",
        "            else:\n",
        "                tcoord[:, :, 0].fill_(0.5)\n",
        "                tcoord[:, :, 1].fill_(0.5)\n",
        "\n",
        "        for b, gt_filtered in ground_truth.groupby('batch_number', sort=False):\n",
        "            cur_pred_boxes = pred_boxes[b*nAnchors:(b+1)*nAnchors]\n",
        "            if self.anchor_step == 4:\n",
        "                anchors = self.anchors.clone()\n",
        "                anchors[:, :2] = 0\n",
        "            else:\n",
        "                anchors = torch.cat([torch.zeros_like(self.anchors), self.anchors], 1)\n",
        "\n",
        "            # Create ground_truth tensor\n",
        "            gt = torch.empty((gt_filtered.shape[0], 4), requires_grad=False)\n",
        "            gt[:, 2] = torch.from_numpy(gt_filtered.width.values) / self.stride\n",
        "            gt[:, 3] = torch.from_numpy(gt_filtered.height.values) / self.stride\n",
        "            gt[:, 0] = torch.from_numpy(gt_filtered.x_top_left.values).float() / self.stride + (gt[:, 2] / 2)\n",
        "            gt[:, 1] = torch.from_numpy(gt_filtered.y_top_left.values).float() / self.stride + (gt[:, 3] / 2)\n",
        "\n",
        "            # Set confidence mask of matching detections to 0\n",
        "            iou_gt_pred = bbox_ious(gt, cur_pred_boxes)\n",
        "            mask = (iou_gt_pred > self.thresh).sum(0) >= 1\n",
        "            conf_mask[b][mask.view_as(conf_mask[b])] = 0\n",
        "\n",
        "            # Find best anchor for each gt\n",
        "            iou_gt_anchors = bbox_wh_ious(gt, anchors)\n",
        "            _, best_anchors = iou_gt_anchors.max(1)\n",
        "\n",
        "            # Set masks and target values for each gt\n",
        "            nGT = gt.shape[0]\n",
        "            gi = gt[:, 0].clamp(0, nW-1).long()\n",
        "            gj = gt[:, 1].clamp(0, nH-1).long()\n",
        "\n",
        "            conf_mask[b, best_anchors, gj, gi] = self.object_scale\n",
        "            tconf[b, best_anchors, gj, gi] = iou_gt_pred.view(nGT, nA, nH, nW)[torch.arange(nGT), best_anchors, gj, gi]\n",
        "            coord_mask[b, best_anchors, gj, gi] = 2 - (gt[:, 2] * gt[:, 3]) / nPixels\n",
        "            tcoord[b, best_anchors, 0, gj, gi] = gt[:, 0] - gi.float()\n",
        "            tcoord[b, best_anchors, 1, gj, gi] = gt[:, 1] - gj.float()\n",
        "            tcoord[b, best_anchors, 2, gj, gi] = (gt[:, 2] / self.anchors[best_anchors, 0].float()).log()\n",
        "            tcoord[b, best_anchors, 3, gj, gi] = (gt[:, 3] / self.anchors[best_anchors, 1].float()).log()\n",
        "            cls_mask[b, best_anchors, gj, gi] = 1\n",
        "            tcls[b, best_anchors, gj, gi] = torch.from_numpy(gt_filtered.class_id.values).float()\n",
        "\n",
        "            # Set masks of ignored to zero\n",
        "            if gt_filtered.ignore.any():\n",
        "                if torchversion >= version120:\n",
        "                    ignore_mask = torch.from_numpy(gt_filtered.ignore.values)\n",
        "                else:\n",
        "                    ignore_mask = torch.from_numpy(gt_filtered.ignore.values.astype(np.uint8))\n",
        "                gi = gi[ignore_mask]\n",
        "                gj = gj[ignore_mask]\n",
        "                best_anchors = best_anchors[ignore_mask]\n",
        "\n",
        "                conf_mask[b, best_anchors, gj, gi] = 0\n",
        "                coord_mask[b, best_anchors, gj, gi] = 0\n",
        "                cls_mask[b, best_anchors, gj, gi] = 0\n",
        "\n",
        "        return (\n",
        "            coord_mask.view(nB, nA, 1, nPixels),\n",
        "            conf_mask.view(nB, nA, nPixels),\n",
        "            cls_mask.view(nB, nA, nPixels),\n",
        "            tcoord.view(nB, nA, 4, nPixels),\n",
        "            tconf.view(nB, nA, nPixels),\n",
        "            tcls.view(nB, nA, nPixels)\n",
        "        )\n",
        "\n",
        "\n",
        "def bbox_ious(boxes1, boxes2):\n",
        "    \"\"\" Compute IOU between all boxes from ``boxes1`` with all boxes from ``boxes2``.\n",
        "\n",
        "    Args:\n",
        "        boxes1 (torch.Tensor): List of bounding boxes\n",
        "        boxes2 (torch.Tensor): List of bounding boxes\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor[len(boxes1) X len(boxes2)]: IOU values\n",
        "\n",
        "    Note:\n",
        "        Tensor format: [[xc, yc, w, h],...]\n",
        "    \"\"\"\n",
        "    b1x1, b1y1 = (boxes1[:, :2] - (boxes1[:, 2:4] / 2)).split(1, 1)\n",
        "    b1x2, b1y2 = (boxes1[:, :2] + (boxes1[:, 2:4] / 2)).split(1, 1)\n",
        "    b2x1, b2y1 = (boxes2[:, :2] - (boxes2[:, 2:4] / 2)).split(1, 1)\n",
        "    b2x2, b2y2 = (boxes2[:, :2] + (boxes2[:, 2:4] / 2)).split(1, 1)\n",
        "\n",
        "    dx = (b1x2.min(b2x2.t()) - b1x1.max(b2x1.t())).clamp(min=0)\n",
        "    dy = (b1y2.min(b2y2.t()) - b1y1.max(b2y1.t())).clamp(min=0)\n",
        "    intersections = dx * dy\n",
        "\n",
        "    areas1 = (b1x2 - b1x1) * (b1y2 - b1y1)\n",
        "    areas2 = (b2x2 - b2x1) * (b2y2 - b2y1)\n",
        "    unions = (areas1 + areas2.t()) - intersections\n",
        "\n",
        "    return intersections / unions\n",
        "\n",
        "\n",
        "def bbox_wh_ious(boxes1, boxes2):\n",
        "    \"\"\" Shorter version of :func:`lightnet.network.loss._regionloss.bbox_ious`\n",
        "    for when we are only interested in W/H of the bounding boxes and not X/Y.\n",
        "\n",
        "    Args:\n",
        "        boxes1 (torch.Tensor): List of bounding boxes\n",
        "        boxes2 (torch.Tensor): List of bounding boxes\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor[len(boxes1) X len(boxes2)]: IOU values when discarding X/Y offsets (aka. as if they were zero)\n",
        "\n",
        "    Note:\n",
        "        Tensor format: [[xc, yc, w, h],...]\n",
        "    \"\"\"\n",
        "    b1w = boxes1[:, 2].unsqueeze(1)\n",
        "    b1h = boxes1[:, 3].unsqueeze(1)\n",
        "    b2w = boxes2[:, 2]\n",
        "    b2h = boxes2[:, 3]\n",
        "\n",
        "    intersections = b1w.min(b2w.type_as(b1w)) * b1h.min(b2h.type_as(b1h))\n",
        "    unions = (b1w * b1h) + (b1w * b1h).type_as(b1w) - intersections\n",
        "\n",
        "    return intersections / unions"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting lightnet/network/loss/_regionloss.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BQhf1uwLjg5L",
        "outputId": "521a840f-80db-4fd4-909c-62f96e159e4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# if starting from weights\n",
        "#!python example/bin/train.py \"data/weights/weights_21000.state.pt\" -n \"example/cfg/yolo.py\" -a \"data/images/valves\" -b \"/content/gdrive/My Drive/dataManagement/lightnet/backup\" --cuda\n",
        "# if starting from scratch\n",
        "!python example/bin/train.py \"/content/gdrive/My Drive/dataManagement/lightnet/backup/darknet53_448.pt\" -n \"example/cfg/yolo.py\" -a \"data/images/valves\" -b \"/content/gdrive/My Drive/dataManagement/lightnet/backup\" --cuda"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[01m\u001b[37mINFO      \u001b[00m Loading weights from file [/content/gdrive/My Drive/dataManagement/lightnet/backup/darknet53_448.pt]\n",
            "\u001b[01m\u001b[33mWARNING   \u001b[00m Modules not matching, performing partial update\n",
            "\u001b[01m\u001b[33mDEPRECATED\u001b[00m This class is deprectated in favor of the new TensorBoard integration in PyTorch\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Start training\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1 Loss:3918.69690 (Coord:1640.62 Conf:2263.71 Cls:14.37)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2 Loss:3920.24933 (Coord:1640.75 Conf:2264.56 Cls:14.94)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3 Loss:3902.72681 (Coord:1628.91 Conf:2260.48 Cls:13.34)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4 Loss:3914.77579 (Coord:1638.11 Conf:2263.19 Cls:13.48)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 5 Loss:3913.73575 (Coord:1636.70 Conf:2262.30 Cls:14.73)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 6 Loss:3914.47775 (Coord:1637.25 Conf:2263.00 Cls:14.22)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 7 Loss:3922.93527 (Coord:1642.91 Conf:2264.68 Cls:15.34)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 8 Loss:3913.64154 (Coord:1637.27 Conf:2261.79 Cls:14.59)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 9 Loss:3914.11435 (Coord:1635.97 Conf:2264.34 Cls:13.81)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 10 Loss:3902.29651 (Coord:1628.65 Conf:2260.89 Cls:12.76)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 11 Loss:3921.01532 (Coord:1641.55 Conf:2264.77 Cls:14.69)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 12 Loss:3904.99588 (Coord:1630.19 Conf:2261.39 Cls:13.41)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 13 Loss:3925.42740 (Coord:1645.61 Conf:2264.96 Cls:14.86)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 14 Loss:3906.14029 (Coord:1630.34 Conf:2262.24 Cls:13.57)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 15 Loss:3912.03357 (Coord:1635.19 Conf:2262.63 Cls:14.21)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 16 Loss:3910.48547 (Coord:1635.11 Conf:2261.07 Cls:14.31)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 17 Loss:3924.54092 (Coord:1645.26 Conf:2264.24 Cls:15.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 18 Loss:3917.07599 (Coord:1638.43 Conf:2263.77 Cls:14.87)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 19 Loss:3908.91690 (Coord:1633.38 Conf:2262.34 Cls:13.19)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 20 Loss:3912.44916 (Coord:1634.73 Conf:2263.32 Cls:14.40)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 21 Loss:3915.43030 (Coord:1638.05 Conf:2263.24 Cls:14.13)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 22 Loss:3916.54025 (Coord:1639.38 Conf:2262.98 Cls:14.19)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 23 Loss:3918.13428 (Coord:1638.37 Conf:2265.17 Cls:14.59)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 24 Loss:3906.02591 (Coord:1632.55 Conf:2260.03 Cls:13.45)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 25 Loss:3913.55658 (Coord:1636.40 Conf:2262.69 Cls:14.47)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 26 Loss:3903.67868 (Coord:1628.53 Conf:2261.25 Cls:13.90)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 27 Loss:3913.84393 (Coord:1637.45 Conf:2262.16 Cls:14.24)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 28 Loss:3918.15234 (Coord:1640.28 Conf:2263.86 Cls:14.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 29 Loss:3919.94714 (Coord:1642.28 Conf:2262.85 Cls:14.81)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 30 Loss:3917.73010 (Coord:1639.59 Conf:2263.81 Cls:14.33)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 31 Loss:3900.34894 (Coord:1626.41 Conf:2260.28 Cls:13.65)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 32 Loss:3925.02747 (Coord:1645.36 Conf:2264.45 Cls:15.22)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 33 Loss:3922.83618 (Coord:1643.94 Conf:2263.96 Cls:14.93)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 34 Loss:3890.94321 (Coord:1618.73 Conf:2259.13 Cls:13.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 35 Loss:3902.88489 (Coord:1628.09 Conf:2261.21 Cls:13.58)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 36 Loss:3916.61749 (Coord:1640.31 Conf:2261.76 Cls:14.55)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 37 Loss:3898.34766 (Coord:1625.60 Conf:2259.33 Cls:13.42)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 38 Loss:3913.82602 (Coord:1635.86 Conf:2263.25 Cls:14.71)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 39 Loss:3919.15234 (Coord:1641.47 Conf:2262.69 Cls:14.99)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 40 Loss:3895.08167 (Coord:1624.07 Conf:2257.52 Cls:13.49)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 41 Loss:3907.20578 (Coord:1631.02 Conf:2261.18 Cls:15.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 42 Loss:3894.64270 (Coord:1624.28 Conf:2257.39 Cls:12.97)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 43 Loss:3898.87607 (Coord:1625.17 Conf:2259.71 Cls:13.99)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 44 Loss:3909.08398 (Coord:1632.57 Conf:2260.57 Cls:15.94)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 45 Loss:3899.98392 (Coord:1627.00 Conf:2258.79 Cls:14.19)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 46 Loss:3887.96017 (Coord:1618.10 Conf:2256.90 Cls:12.96)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 47 Loss:3903.19098 (Coord:1630.51 Conf:2257.47 Cls:15.21)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 48 Loss:3890.33398 (Coord:1618.66 Conf:2256.29 Cls:15.39)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 49 Loss:3888.64987 (Coord:1620.45 Conf:2254.87 Cls:13.33)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 50 Loss:3876.03778 (Coord:1609.94 Conf:2253.05 Cls:13.04)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 51 Loss:3890.43149 (Coord:1620.77 Conf:2254.42 Cls:15.23)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 52 Loss:3878.77664 (Coord:1612.02 Conf:2252.67 Cls:14.09)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 53 Loss:3870.70386 (Coord:1606.22 Conf:2251.09 Cls:13.40)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 54 Loss:3870.98877 (Coord:1607.25 Conf:2249.78 Cls:13.96)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 55 Loss:3863.51260 (Coord:1601.83 Conf:2248.11 Cls:13.56)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 56 Loss:3867.52655 (Coord:1603.68 Conf:2249.01 Cls:14.84)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 57 Loss:3852.34564 (Coord:1592.03 Conf:2246.09 Cls:14.23)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 58 Loss:3859.06152 (Coord:1599.93 Conf:2244.39 Cls:14.73)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 59 Loss:3846.35260 (Coord:1589.44 Conf:2243.22 Cls:13.70)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 60 Loss:3845.73514 (Coord:1589.84 Conf:2241.66 Cls:14.24)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 61 Loss:3827.23166 (Coord:1576.21 Conf:2237.69 Cls:13.32)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 62 Loss:3839.71991 (Coord:1585.30 Conf:2239.78 Cls:14.64)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 63 Loss:3823.48224 (Coord:1573.50 Conf:2235.44 Cls:14.53)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 64 Loss:3813.25314 (Coord:1566.98 Conf:2232.35 Cls:13.92)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 65 Loss:3803.75113 (Coord:1559.09 Conf:2230.13 Cls:14.54)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 66 Loss:3795.38382 (Coord:1555.50 Conf:2225.86 Cls:14.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 67 Loss:3796.57852 (Coord:1555.67 Conf:2226.87 Cls:14.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 68 Loss:3768.54684 (Coord:1536.98 Conf:2218.06 Cls:13.50)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 69 Loss:3786.02115 (Coord:1549.08 Conf:2221.75 Cls:15.19)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 70 Loss:3749.30084 (Coord:1523.99 Conf:2212.25 Cls:13.06)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 71 Loss:3752.97729 (Coord:1525.86 Conf:2212.51 Cls:14.60)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 72 Loss:3735.72067 (Coord:1513.02 Conf:2208.35 Cls:14.35)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 73 Loss:3724.61252 (Coord:1507.46 Conf:2203.64 Cls:13.52)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 74 Loss:3708.63788 (Coord:1495.87 Conf:2198.63 Cls:14.14)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 75 Loss:3708.80600 (Coord:1497.45 Conf:2196.67 Cls:14.69)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 76 Loss:3677.72531 (Coord:1474.06 Conf:2189.70 Cls:13.96)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 77 Loss:3681.42374 (Coord:1479.61 Conf:2187.20 Cls:14.61)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 78 Loss:3661.27924 (Coord:1466.97 Conf:2180.26 Cls:14.05)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 79 Loss:3640.19638 (Coord:1451.73 Conf:2174.52 Cls:13.95)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 80 Loss:3630.92953 (Coord:1446.30 Conf:2170.34 Cls:14.28)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 81 Loss:3612.78754 (Coord:1435.75 Conf:2162.77 Cls:14.27)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 82 Loss:3596.40811 (Coord:1422.36 Conf:2159.33 Cls:14.72)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 83 Loss:3584.68326 (Coord:1418.66 Conf:2151.28 Cls:14.74)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 84 Loss:3554.74924 (Coord:1398.61 Conf:2142.31 Cls:13.83)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 85 Loss:3534.36832 (Coord:1385.15 Conf:2135.85 Cls:13.37)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 86 Loss:3514.18991 (Coord:1373.19 Conf:2127.57 Cls:13.43)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 87 Loss:3505.78052 (Coord:1369.69 Conf:2121.77 Cls:14.32)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 88 Loss:3484.61670 (Coord:1356.09 Conf:2114.54 Cls:13.98)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 89 Loss:3470.10623 (Coord:1348.85 Conf:2106.34 Cls:14.91)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 90 Loss:3431.65701 (Coord:1322.79 Conf:2095.21 Cls:13.66)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 91 Loss:3410.81601 (Coord:1311.61 Conf:2085.86 Cls:13.35)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 92 Loss:3399.63721 (Coord:1306.41 Conf:2078.62 Cls:14.60)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 93 Loss:3370.54251 (Coord:1288.82 Conf:2067.52 Cls:14.21)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 94 Loss:3338.98492 (Coord:1270.98 Conf:2054.61 Cls:13.39)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 95 Loss:3316.17606 (Coord:1257.83 Conf:2044.85 Cls:13.49)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 96 Loss:3305.43402 (Coord:1254.92 Conf:2035.72 Cls:14.80)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 97 Loss:3275.86777 (Coord:1238.33 Conf:2023.79 Cls:13.75)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 98 Loss:3254.41693 (Coord:1227.64 Conf:2012.02 Cls:14.75)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 99 Loss:3205.25638 (Coord:1195.02 Conf:1997.17 Cls:13.06)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 100 Loss:3210.15781 (Coord:1207.13 Conf:1988.58 Cls:14.45)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 101 Loss:3185.10110 (Coord:1194.29 Conf:1975.66 Cls:15.15)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 102 Loss:3130.34958 (Coord:1158.68 Conf:1958.43 Cls:13.24)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 103 Loss:3106.24438 (Coord:1148.27 Conf:1944.50 Cls:13.48)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 104 Loss:3076.90494 (Coord:1133.48 Conf:1930.23 Cls:13.19)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 105 Loss:3057.43005 (Coord:1126.08 Conf:1917.03 Cls:14.32)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 106 Loss:3034.47845 (Coord:1118.09 Conf:1902.20 Cls:14.18)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 107 Loss:2987.36276 (Coord:1090.48 Conf:1884.28 Cls:12.60)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 108 Loss:2963.40381 (Coord:1081.27 Conf:1868.32 Cls:13.81)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 109 Loss:2944.04947 (Coord:1076.32 Conf:1853.41 Cls:14.32)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 110 Loss:2902.85022 (Coord:1053.66 Conf:1835.81 Cls:13.39)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 111 Loss:2875.24402 (Coord:1043.07 Conf:1818.24 Cls:13.94)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 112 Loss:2840.26273 (Coord:1025.59 Conf:1800.33 Cls:14.34)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 113 Loss:2812.43658 (Coord:1017.47 Conf:1781.95 Cls:13.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 114 Loss:2765.38449 (Coord:991.67 Conf:1761.01 Cls:12.71)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 115 Loss:2738.43350 (Coord:982.39 Conf:1742.85 Cls:13.19)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 116 Loss:2711.26111 (Coord:972.63 Conf:1724.25 Cls:14.38)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 117 Loss:2690.74841 (Coord:970.36 Conf:1705.75 Cls:14.64)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 118 Loss:2632.98645 (Coord:937.59 Conf:1682.03 Cls:13.36)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 119 Loss:2602.23624 (Coord:927.25 Conf:1661.31 Cls:13.68)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 120 Loss:2567.44391 (Coord:913.36 Conf:1640.97 Cls:13.11)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 121 Loss:2528.24066 (Coord:896.86 Conf:1618.13 Cls:13.24)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 122 Loss:2503.31711 (Coord:894.18 Conf:1595.83 Cls:13.31)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 123 Loss:2463.59207 (Coord:875.47 Conf:1574.58 Cls:13.54)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 124 Loss:2415.62354 (Coord:852.80 Conf:1549.81 Cls:13.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 125 Loss:2393.82205 (Coord:852.92 Conf:1527.45 Cls:13.45)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 126 Loss:2355.01443 (Coord:837.85 Conf:1503.90 Cls:13.27)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 127 Loss:2305.97421 (Coord:814.45 Conf:1479.05 Cls:12.47)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 128 Loss:2277.24554 (Coord:808.23 Conf:1455.41 Cls:13.60)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 129 Loss:2247.09103 (Coord:801.68 Conf:1431.62 Cls:13.79)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 130 Loss:2195.97638 (Coord:777.20 Conf:1405.30 Cls:13.48)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 131 Loss:2161.14648 (Coord:768.55 Conf:1380.36 Cls:12.23)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 132 Loss:2119.34036 (Coord:752.92 Conf:1353.89 Cls:12.53)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 133 Loss:2078.41980 (Coord:737.65 Conf:1328.53 Cls:12.24)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 134 Loss:1560.83430 (Coord:242.44 Conf:1304.41 Cls:13.98)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 135 Loss:1351.56851 (Coord:60.72 Conf:1278.01 Cls:12.84)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 136 Loss:1330.32594 (Coord:64.35 Conf:1252.42 Cls:13.55)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 137 Loss:1291.11983 (Coord:57.24 Conf:1222.46 Cls:11.42)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 138 Loss:1262.67561 (Coord:55.08 Conf:1195.26 Cls:12.34)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 139 Loss:1240.77481 (Coord:56.82 Conf:1171.01 Cls:12.94)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 140 Loss:1207.92047 (Coord:53.48 Conf:1141.78 Cls:12.66)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 141 Loss:1181.29773 (Coord:55.07 Conf:1114.16 Cls:12.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 142 Loss:1154.09315 (Coord:53.39 Conf:1087.76 Cls:12.95)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 143 Loss:1118.15950 (Coord:46.47 Conf:1059.55 Cls:12.14)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 144 Loss:1100.28549 (Coord:54.38 Conf:1032.81 Cls:13.09)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 145 Loss:1063.32426 (Coord:46.66 Conf:1004.60 Cls:12.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 146 Loss:1033.06418 (Coord:44.39 Conf:976.48 Cls:12.19)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 147 Loss:1008.79115 (Coord:46.37 Conf:950.53 Cls:11.89)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 148 Loss:979.80676 (Coord:44.94 Conf:922.52 Cls:12.35)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 149 Loss:951.86301 (Coord:43.58 Conf:895.91 Cls:12.36)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 150 Loss:922.53452 (Coord:42.20 Conf:868.74 Cls:11.60)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 151 Loss:894.16553 (Coord:40.45 Conf:842.00 Cls:11.71)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 152 Loss:865.55967 (Coord:37.87 Conf:815.86 Cls:11.83)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 153 Loss:845.76315 (Coord:41.37 Conf:792.28 Cls:12.11)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 154 Loss:816.48991 (Coord:39.23 Conf:765.47 Cls:11.80)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 155 Loss:787.75045 (Coord:37.74 Conf:738.42 Cls:11.60)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 156 Loss:767.25873 (Coord:37.29 Conf:717.98 Cls:11.99)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 157 Loss:736.29337 (Coord:34.40 Conf:691.04 Cls:10.86)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 158 Loss:714.57800 (Coord:35.80 Conf:666.79 Cls:11.99)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 159 Loss:692.52135 (Coord:35.18 Conf:645.44 Cls:11.90)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 160 Loss:671.53667 (Coord:35.60 Conf:623.93 Cls:12.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 161 Loss:643.38441 (Coord:31.57 Conf:600.43 Cls:11.38)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 162 Loss:621.12226 (Coord:32.79 Conf:577.39 Cls:10.93)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 163 Loss:600.57440 (Coord:32.84 Conf:556.67 Cls:11.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 164 Loss:582.65761 (Coord:31.81 Conf:539.49 Cls:11.35)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 165 Loss:554.03692 (Coord:28.46 Conf:514.88 Cls:10.70)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 166 Loss:538.92506 (Coord:30.60 Conf:497.70 Cls:10.62)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 167 Loss:517.61884 (Coord:28.81 Conf:477.89 Cls:10.92)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 168 Loss:500.76019 (Coord:28.95 Conf:460.66 Cls:11.15)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 169 Loss:481.13782 (Coord:28.10 Conf:442.34 Cls:10.70)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 170 Loss:468.39112 (Coord:29.99 Conf:427.21 Cls:11.20)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 171 Loss:447.09235 (Coord:27.71 Conf:408.76 Cls:10.63)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 172 Loss:430.50339 (Coord:27.05 Conf:392.93 Cls:10.52)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 173 Loss:415.22015 (Coord:26.50 Conf:378.01 Cls:10.71)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 174 Loss:399.29966 (Coord:25.55 Conf:363.52 Cls:10.23)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 175 Loss:383.92091 (Coord:24.60 Conf:348.80 Cls:10.51)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 176 Loss:369.83355 (Coord:24.24 Conf:335.09 Cls:10.50)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 177 Loss:354.05296 (Coord:22.55 Conf:321.30 Cls:10.21)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 178 Loss:345.01163 (Coord:25.34 Conf:309.66 Cls:10.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 179 Loss:331.16998 (Coord:23.24 Conf:297.80 Cls:10.12)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 180 Loss:317.44297 (Coord:23.47 Conf:283.92 Cls:10.05)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 181 Loss:303.48628 (Coord:20.51 Conf:273.63 Cls:9.35)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 182 Loss:297.84954 (Coord:23.85 Conf:263.17 Cls:10.83)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 183 Loss:285.30048 (Coord:22.28 Conf:252.93 Cls:10.09)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 184 Loss:272.50504 (Coord:20.17 Conf:243.41 Cls:8.93)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 185 Loss:261.36779 (Coord:19.73 Conf:232.69 Cls:8.95)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 186 Loss:254.24533 (Coord:19.80 Conf:224.60 Cls:9.85)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 187 Loss:246.61292 (Coord:21.15 Conf:215.88 Cls:9.58)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 188 Loss:234.56115 (Coord:18.31 Conf:207.08 Cls:9.17)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 189 Loss:227.28861 (Coord:17.96 Conf:199.72 Cls:9.60)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 190 Loss:218.24930 (Coord:18.32 Conf:191.19 Cls:8.74)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 191 Loss:212.23326 (Coord:18.85 Conf:184.09 Cls:9.29)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 192 Loss:204.47271 (Coord:18.00 Conf:177.67 Cls:8.81)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 193 Loss:197.63427 (Coord:17.64 Conf:171.02 Cls:8.97)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 194 Loss:190.73927 (Coord:16.82 Conf:164.52 Cls:9.40)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 195 Loss:181.06837 (Coord:15.54 Conf:157.64 Cls:7.89)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 196 Loss:179.28216 (Coord:17.38 Conf:152.50 Cls:9.40)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 197 Loss:172.30811 (Coord:16.16 Conf:147.06 Cls:9.09)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 198 Loss:165.22633 (Coord:15.73 Conf:141.16 Cls:8.33)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 199 Loss:162.03987 (Coord:15.94 Conf:137.34 Cls:8.76)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 200 Loss:154.34304 (Coord:14.85 Conf:130.93 Cls:8.57)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 201 Loss:152.62026 (Coord:16.37 Conf:127.35 Cls:8.89)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 202 Loss:144.69824 (Coord:13.69 Conf:122.38 Cls:8.63)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 203 Loss:138.38376 (Coord:13.33 Conf:117.49 Cls:7.57)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 204 Loss:136.65697 (Coord:14.52 Conf:113.78 Cls:8.36)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 205 Loss:132.38488 (Coord:13.83 Conf:110.32 Cls:8.24)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 206 Loss:125.88810 (Coord:12.64 Conf:105.67 Cls:7.58)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 207 Loss:122.91676 (Coord:12.15 Conf:102.57 Cls:8.20)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 208 Loss:119.94162 (Coord:12.75 Conf:99.28 Cls:7.91)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 209 Loss:115.52054 (Coord:12.26 Conf:95.60 Cls:7.67)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 210 Loss:112.37372 (Coord:11.86 Conf:93.14 Cls:7.38)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 211 Loss:110.11600 (Coord:12.67 Conf:89.83 Cls:7.62)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 212 Loss:105.25967 (Coord:10.46 Conf:87.08 Cls:7.72)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 213 Loss:102.10494 (Coord:11.05 Conf:83.76 Cls:7.30)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 214 Loss:100.59568 (Coord:11.42 Conf:81.77 Cls:7.41)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 215 Loss:96.41719 (Coord:10.57 Conf:78.52 Cls:7.33)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 216 Loss:94.58276 (Coord:10.70 Conf:76.62 Cls:7.26)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 217 Loss:91.15571 (Coord:10.29 Conf:74.05 Cls:6.82)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 218 Loss:89.81459 (Coord:10.42 Conf:71.96 Cls:7.43)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 219 Loss:87.19625 (Coord:10.02 Conf:69.96 Cls:7.22)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 220 Loss:84.11769 (Coord:9.70 Conf:67.57 Cls:6.85)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 221 Loss:83.04453 (Coord:9.77 Conf:66.15 Cls:7.13)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 222 Loss:79.30667 (Coord:9.15 Conf:63.61 Cls:6.55)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 223 Loss:76.85678 (Coord:8.79 Conf:61.85 Cls:6.22)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 224 Loss:76.30971 (Coord:9.11 Conf:60.48 Cls:6.72)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 225 Loss:74.64710 (Coord:8.97 Conf:58.49 Cls:7.19)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 226 Loss:73.12411 (Coord:9.02 Conf:57.26 Cls:6.84)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 227 Loss:70.87969 (Coord:8.80 Conf:55.61 Cls:6.47)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 228 Loss:67.33857 (Coord:7.74 Conf:53.40 Cls:6.20)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 229 Loss:67.11391 (Coord:8.34 Conf:52.55 Cls:6.22)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 230 Loss:64.40866 (Coord:7.71 Conf:50.45 Cls:6.25)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 231 Loss:64.19761 (Coord:7.91 Conf:49.82 Cls:6.46)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 232 Loss:62.16191 (Coord:7.59 Conf:48.46 Cls:6.11)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 233 Loss:59.84419 (Coord:6.98 Conf:46.94 Cls:5.92)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 234 Loss:59.60094 (Coord:7.72 Conf:45.89 Cls:5.99)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 235 Loss:58.37896 (Coord:7.06 Conf:45.39 Cls:5.93)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 236 Loss:56.50885 (Coord:7.48 Conf:43.41 Cls:5.62)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 237 Loss:54.58901 (Coord:6.63 Conf:41.95 Cls:6.00)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 238 Loss:53.23968 (Coord:6.64 Conf:41.16 Cls:5.43)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 239 Loss:51.94366 (Coord:6.30 Conf:40.40 Cls:5.25)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 240 Loss:52.79994 (Coord:6.84 Conf:39.92 Cls:6.05)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 241 Loss:50.76715 (Coord:6.65 Conf:38.50 Cls:5.62)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 242 Loss:50.69310 (Coord:6.66 Conf:38.29 Cls:5.74)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 243 Loss:48.08980 (Coord:6.04 Conf:36.66 Cls:5.39)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 244 Loss:47.94672 (Coord:6.71 Conf:35.95 Cls:5.29)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 245 Loss:45.85055 (Coord:5.65 Conf:35.12 Cls:5.08)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 246 Loss:46.02366 (Coord:5.93 Conf:34.82 Cls:5.28)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 247 Loss:43.89200 (Coord:5.44 Conf:33.43 Cls:5.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 248 Loss:43.43205 (Coord:5.50 Conf:32.96 Cls:4.97)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 249 Loss:42.69042 (Coord:5.33 Conf:32.44 Cls:4.92)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 250 Loss:42.72350 (Coord:5.80 Conf:31.80 Cls:5.13)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 251 Loss:40.94847 (Coord:5.26 Conf:31.08 Cls:4.61)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 252 Loss:40.94832 (Coord:5.32 Conf:30.73 Cls:4.90)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 253 Loss:39.74701 (Coord:5.42 Conf:29.46 Cls:4.86)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 254 Loss:38.72607 (Coord:5.06 Conf:29.02 Cls:4.64)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 255 Loss:39.69281 (Coord:5.49 Conf:29.15 Cls:5.06)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 256 Loss:36.51926 (Coord:4.61 Conf:27.74 Cls:4.16)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 257 Loss:36.05892 (Coord:4.69 Conf:27.01 Cls:4.36)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 258 Loss:36.36554 (Coord:4.77 Conf:27.17 Cls:4.42)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 259 Loss:36.25951 (Coord:4.93 Conf:26.88 Cls:4.45)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 260 Loss:34.77158 (Coord:4.71 Conf:25.83 Cls:4.23)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 261 Loss:35.00663 (Coord:4.70 Conf:25.77 Cls:4.53)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 262 Loss:33.44085 (Coord:4.52 Conf:24.98 Cls:3.94)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 263 Loss:33.61114 (Coord:4.74 Conf:24.59 Cls:4.28)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 264 Loss:33.02087 (Coord:4.22 Conf:24.64 Cls:4.17)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 265 Loss:32.10552 (Coord:4.39 Conf:23.64 Cls:4.08)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 266 Loss:30.74860 (Coord:4.18 Conf:22.68 Cls:3.89)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 267 Loss:30.83764 (Coord:4.15 Conf:22.89 Cls:3.80)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 268 Loss:31.11712 (Coord:4.37 Conf:22.77 Cls:3.98)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 269 Loss:30.22868 (Coord:4.17 Conf:22.15 Cls:3.91)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 270 Loss:29.93356 (Coord:4.17 Conf:21.98 Cls:3.78)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 271 Loss:28.88111 (Coord:4.15 Conf:20.94 Cls:3.79)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 272 Loss:29.33575 (Coord:4.36 Conf:21.20 Cls:3.78)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 273 Loss:27.34505 (Coord:3.69 Conf:20.34 Cls:3.32)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 274 Loss:27.82594 (Coord:3.97 Conf:20.42 Cls:3.44)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 275 Loss:27.57396 (Coord:3.86 Conf:19.91 Cls:3.81)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 276 Loss:26.79413 (Coord:3.83 Conf:19.55 Cls:3.42)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 277 Loss:26.46796 (Coord:3.84 Conf:19.16 Cls:3.47)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 278 Loss:26.24255 (Coord:3.65 Conf:19.24 Cls:3.36)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 279 Loss:26.78866 (Coord:4.00 Conf:19.22 Cls:3.56)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 280 Loss:25.13682 (Coord:3.69 Conf:18.18 Cls:3.26)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 281 Loss:24.71633 (Coord:3.44 Conf:18.12 Cls:3.15)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 282 Loss:24.10879 (Coord:3.31 Conf:17.72 Cls:3.08)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 283 Loss:24.50239 (Coord:3.58 Conf:17.61 Cls:3.31)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 284 Loss:25.30357 (Coord:3.93 Conf:17.95 Cls:3.42)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 285 Loss:22.83773 (Coord:3.13 Conf:16.87 Cls:2.83)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 286 Loss:23.50090 (Coord:3.48 Conf:16.99 Cls:3.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 287 Loss:23.36206 (Coord:3.49 Conf:16.80 Cls:3.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 288 Loss:22.88213 (Coord:3.28 Conf:16.61 Cls:2.99)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 289 Loss:21.93158 (Coord:3.11 Conf:16.16 Cls:2.67)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 290 Loss:22.33628 (Coord:3.32 Conf:16.17 Cls:2.85)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 291 Loss:22.70404 (Coord:3.41 Conf:16.18 Cls:3.11)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 292 Loss:21.35098 (Coord:3.00 Conf:15.61 Cls:2.75)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 293 Loss:21.69234 (Coord:3.35 Conf:15.57 Cls:2.78)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 294 Loss:21.47386 (Coord:3.13 Conf:15.51 Cls:2.83)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 295 Loss:20.35715 (Coord:3.03 Conf:14.88 Cls:2.45)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 296 Loss:20.85857 (Coord:3.04 Conf:15.08 Cls:2.74)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 297 Loss:20.25598 (Coord:2.97 Conf:14.70 Cls:2.58)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 298 Loss:20.12187 (Coord:2.99 Conf:14.55 Cls:2.58)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 299 Loss:20.15780 (Coord:3.00 Conf:14.60 Cls:2.55)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 300 Loss:19.54326 (Coord:2.87 Conf:14.24 Cls:2.44)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 301 Loss:19.80846 (Coord:2.85 Conf:14.48 Cls:2.48)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 302 Loss:18.91887 (Coord:2.73 Conf:13.83 Cls:2.36)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 303 Loss:19.12061 (Coord:3.00 Conf:13.68 Cls:2.44)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 304 Loss:19.55159 (Coord:2.97 Conf:14.03 Cls:2.56)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 305 Loss:18.23942 (Coord:2.75 Conf:13.25 Cls:2.24)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 306 Loss:18.47522 (Coord:2.68 Conf:13.46 Cls:2.33)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 307 Loss:17.56762 (Coord:2.68 Conf:12.84 Cls:2.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 308 Loss:18.19055 (Coord:2.64 Conf:13.25 Cls:2.30)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 309 Loss:17.75326 (Coord:2.72 Conf:12.89 Cls:2.15)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 310 Loss:17.71855 (Coord:2.63 Conf:12.82 Cls:2.27)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 311 Loss:18.03120 (Coord:2.94 Conf:12.86 Cls:2.23)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 312 Loss:17.11220 (Coord:2.45 Conf:12.50 Cls:2.16)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 313 Loss:17.98128 (Coord:2.91 Conf:12.71 Cls:2.37)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 314 Loss:16.34269 (Coord:2.37 Conf:12.03 Cls:1.95)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 315 Loss:16.77380 (Coord:2.53 Conf:12.24 Cls:2.00)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 316 Loss:16.17428 (Coord:2.54 Conf:11.66 Cls:1.97)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 317 Loss:16.14873 (Coord:2.43 Conf:11.75 Cls:1.97)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 318 Loss:16.67133 (Coord:2.49 Conf:12.13 Cls:2.05)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 319 Loss:16.39817 (Coord:2.74 Conf:11.60 Cls:2.06)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 320 Loss:15.45431 (Coord:2.30 Conf:11.31 Cls:1.84)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 321 Loss:15.50058 (Coord:2.32 Conf:11.33 Cls:1.84)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 322 Loss:16.01174 (Coord:2.47 Conf:11.55 Cls:1.99)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 323 Loss:15.14529 (Coord:2.28 Conf:11.07 Cls:1.79)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 324 Loss:15.50947 (Coord:2.46 Conf:11.18 Cls:1.87)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 325 Loss:15.15728 (Coord:2.40 Conf:10.92 Cls:1.84)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 326 Loss:14.89302 (Coord:2.36 Conf:10.80 Cls:1.74)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 327 Loss:14.48628 (Coord:2.28 Conf:10.43 Cls:1.78)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 328 Loss:14.89304 (Coord:2.28 Conf:10.80 Cls:1.81)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 329 Loss:14.49161 (Coord:2.24 Conf:10.57 Cls:1.68)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 330 Loss:14.49151 (Coord:2.32 Conf:10.37 Cls:1.81)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 331 Loss:14.08566 (Coord:2.19 Conf:10.26 Cls:1.63)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 332 Loss:13.91009 (Coord:2.15 Conf:10.12 Cls:1.64)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 333 Loss:13.96147 (Coord:2.24 Conf:10.08 Cls:1.65)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 334 Loss:13.71233 (Coord:2.14 Conf:9.95 Cls:1.62)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 335 Loss:13.53271 (Coord:2.05 Conf:9.90 Cls:1.58)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 336 Loss:13.42043 (Coord:2.08 Conf:9.79 Cls:1.55)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 337 Loss:13.61115 (Coord:2.19 Conf:9.78 Cls:1.64)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 338 Loss:13.05371 (Coord:2.05 Conf:9.40 Cls:1.61)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 339 Loss:12.45859 (Coord:1.91 Conf:9.07 Cls:1.47)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 340 Loss:13.60867 (Coord:2.20 Conf:9.82 Cls:1.59)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 341 Loss:12.83471 (Coord:2.10 Conf:9.26 Cls:1.48)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 342 Loss:12.25954 (Coord:1.99 Conf:8.80 Cls:1.47)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 343 Loss:12.81136 (Coord:2.08 Conf:9.21 Cls:1.52)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 344 Loss:12.70933 (Coord:1.99 Conf:9.19 Cls:1.53)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 345 Loss:12.32718 (Coord:1.91 Conf:8.99 Cls:1.43)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 346 Loss:11.68078 (Coord:1.96 Conf:8.40 Cls:1.32)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 347 Loss:12.34867 (Coord:2.09 Conf:8.72 Cls:1.54)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 348 Loss:11.69598 (Coord:1.92 Conf:8.43 Cls:1.35)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 349 Loss:11.55517 (Coord:1.82 Conf:8.38 Cls:1.35)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 350 Loss:11.96559 (Coord:1.97 Conf:8.56 Cls:1.43)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 351 Loss:11.33766 (Coord:1.85 Conf:8.06 Cls:1.43)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 352 Loss:11.72339 (Coord:1.96 Conf:8.38 Cls:1.38)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 353 Loss:11.26049 (Coord:1.79 Conf:8.25 Cls:1.23)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 354 Loss:11.12177 (Coord:1.78 Conf:8.03 Cls:1.31)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 355 Loss:10.82031 (Coord:1.74 Conf:7.90 Cls:1.17)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 356 Loss:11.15142 (Coord:1.78 Conf:8.06 Cls:1.32)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 357 Loss:11.05164 (Coord:1.85 Conf:7.86 Cls:1.34)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 358 Loss:10.81496 (Coord:1.71 Conf:7.88 Cls:1.23)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 359 Loss:10.37437 (Coord:1.73 Conf:7.42 Cls:1.23)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 360 Loss:10.15564 (Coord:1.64 Conf:7.36 Cls:1.16)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 361 Loss:10.22440 (Coord:1.66 Conf:7.40 Cls:1.16)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 362 Loss:10.57726 (Coord:1.75 Conf:7.57 Cls:1.25)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 363 Loss:10.25086 (Coord:1.67 Conf:7.35 Cls:1.22)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 364 Loss:9.85302 (Coord:1.53 Conf:7.20 Cls:1.13)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 365 Loss:10.08498 (Coord:1.71 Conf:7.18 Cls:1.19)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 366 Loss:10.20408 (Coord:1.76 Conf:7.26 Cls:1.19)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 367 Loss:10.08067 (Coord:1.66 Conf:7.29 Cls:1.13)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 368 Loss:9.41118 (Coord:1.54 Conf:6.77 Cls:1.10)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 369 Loss:9.52024 (Coord:1.61 Conf:6.80 Cls:1.11)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 370 Loss:9.67652 (Coord:1.62 Conf:6.90 Cls:1.16)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 371 Loss:9.16992 (Coord:1.47 Conf:6.64 Cls:1.06)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 372 Loss:9.38795 (Coord:1.65 Conf:6.66 Cls:1.08)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 373 Loss:9.06638 (Coord:1.51 Conf:6.56 Cls:1.00)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 374 Loss:9.56154 (Coord:1.71 Conf:6.72 Cls:1.13)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 375 Loss:8.62885 (Coord:1.41 Conf:6.23 Cls:0.99)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 376 Loss:9.16845 (Coord:1.50 Conf:6.60 Cls:1.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 377 Loss:8.60560 (Coord:1.50 Conf:6.09 Cls:1.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 378 Loss:8.77840 (Coord:1.53 Conf:6.26 Cls:0.99)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 379 Loss:8.69798 (Coord:1.53 Conf:6.18 Cls:0.99)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 380 Loss:8.57525 (Coord:1.39 Conf:6.19 Cls:1.00)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 381 Loss:8.41648 (Coord:1.54 Conf:5.92 Cls:0.96)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 382 Loss:8.00318 (Coord:1.37 Conf:5.68 Cls:0.95)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 383 Loss:8.16126 (Coord:1.35 Conf:5.90 Cls:0.91)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 384 Loss:8.62396 (Coord:1.55 Conf:6.05 Cls:1.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 385 Loss:8.06577 (Coord:1.35 Conf:5.80 Cls:0.91)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 386 Loss:8.08541 (Coord:1.46 Conf:5.72 Cls:0.91)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 387 Loss:8.08777 (Coord:1.49 Conf:5.66 Cls:0.93)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 388 Loss:7.96295 (Coord:1.35 Conf:5.65 Cls:0.96)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 389 Loss:7.83499 (Coord:1.42 Conf:5.51 Cls:0.91)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 390 Loss:7.63653 (Coord:1.47 Conf:5.26 Cls:0.91)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 391 Loss:7.38539 (Coord:1.34 Conf:5.21 Cls:0.83)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 392 Loss:8.07402 (Coord:1.64 Conf:5.46 Cls:0.97)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 393 Loss:7.75234 (Coord:1.45 Conf:5.40 Cls:0.89)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 394 Loss:6.87937 (Coord:1.24 Conf:4.85 Cls:0.78)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 395 Loss:7.24926 (Coord:1.33 Conf:5.12 Cls:0.80)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 396 Loss:7.27769 (Coord:1.42 Conf:5.01 Cls:0.85)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 397 Loss:7.39672 (Coord:1.42 Conf:5.08 Cls:0.90)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 398 Loss:6.87184 (Coord:1.24 Conf:4.80 Cls:0.83)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 399 Loss:7.53144 (Coord:1.50 Conf:5.14 Cls:0.89)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 400 Loss:6.88464 (Coord:1.36 Conf:4.75 Cls:0.78)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 401 Loss:6.78884 (Coord:1.26 Conf:4.79 Cls:0.74)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 402 Loss:6.61402 (Coord:1.28 Conf:4.53 Cls:0.80)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 403 Loss:6.94018 (Coord:1.45 Conf:4.65 Cls:0.84)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 404 Loss:6.84882 (Coord:1.42 Conf:4.58 Cls:0.85)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 405 Loss:6.70814 (Coord:1.38 Conf:4.56 Cls:0.76)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 406 Loss:6.36176 (Coord:1.25 Conf:4.38 Cls:0.73)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 407 Loss:6.82554 (Coord:1.36 Conf:4.69 Cls:0.77)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 408 Loss:6.25846 (Coord:1.24 Conf:4.31 Cls:0.72)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 409 Loss:6.66337 (Coord:1.48 Conf:4.40 Cls:0.78)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 410 Loss:6.24935 (Coord:1.36 Conf:4.14 Cls:0.75)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 411 Loss:6.48929 (Coord:1.42 Conf:4.29 Cls:0.78)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 412 Loss:6.27039 (Coord:1.40 Conf:4.16 Cls:0.71)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 413 Loss:6.24122 (Coord:1.44 Conf:4.08 Cls:0.72)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 414 Loss:6.04359 (Coord:1.30 Conf:4.04 Cls:0.70)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 415 Loss:6.04889 (Coord:1.32 Conf:4.01 Cls:0.73)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 416 Loss:6.45267 (Coord:1.68 Conf:4.08 Cls:0.70)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 417 Loss:5.94959 (Coord:1.31 Conf:3.92 Cls:0.73)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 418 Loss:5.66126 (Coord:1.35 Conf:3.66 Cls:0.65)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 419 Loss:6.26206 (Coord:1.57 Conf:3.98 Cls:0.71)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 420 Loss:6.05902 (Coord:1.52 Conf:3.89 Cls:0.65)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 421 Loss:6.07778 (Coord:1.66 Conf:3.71 Cls:0.70)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 422 Loss:6.01411 (Coord:1.65 Conf:3.65 Cls:0.71)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 423 Loss:5.40630 (Coord:1.24 Conf:3.53 Cls:0.64)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 424 Loss:5.92875 (Coord:1.56 Conf:3.69 Cls:0.67)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 425 Loss:6.28702 (Coord:1.97 Conf:3.58 Cls:0.74)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 426 Loss:5.61398 (Coord:1.37 Conf:3.57 Cls:0.68)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 427 Loss:5.90440 (Coord:1.69 Conf:3.53 Cls:0.69)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 428 Loss:5.61283 (Coord:1.66 Conf:3.34 Cls:0.61)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 429 Loss:5.68743 (Coord:1.50 Conf:3.54 Cls:0.65)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 430 Loss:5.67722 (Coord:1.54 Conf:3.43 Cls:0.70)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 431 Loss:5.40771 (Coord:1.52 Conf:3.29 Cls:0.60)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 432 Loss:5.51621 (Coord:1.57 Conf:3.27 Cls:0.68)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 433 Loss:5.65657 (Coord:1.66 Conf:3.39 Cls:0.61)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 434 Loss:5.75012 (Coord:1.76 Conf:3.34 Cls:0.65)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 435 Loss:5.02639 (Coord:1.37 Conf:3.05 Cls:0.61)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 436 Loss:5.55088 (Coord:1.60 Conf:3.29 Cls:0.66)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 437 Loss:5.21183 (Coord:1.53 Conf:3.10 Cls:0.58)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 438 Loss:5.63065 (Coord:1.80 Conf:3.18 Cls:0.65)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 439 Loss:5.32581 (Coord:1.57 Conf:3.17 Cls:0.58)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 440 Loss:4.96392 (Coord:1.44 Conf:2.95 Cls:0.58)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 441 Loss:5.60283 (Coord:1.83 Conf:3.15 Cls:0.63)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 442 Loss:5.47392 (Coord:1.69 Conf:3.15 Cls:0.64)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 443 Loss:5.33186 (Coord:1.74 Conf:3.01 Cls:0.59)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 444 Loss:5.42017 (Coord:1.85 Conf:2.98 Cls:0.59)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 445 Loss:5.00955 (Coord:1.56 Conf:2.86 Cls:0.59)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 446 Loss:5.49545 (Coord:1.79 Conf:3.07 Cls:0.63)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 447 Loss:5.36120 (Coord:1.99 Conf:2.79 Cls:0.58)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 448 Loss:5.21026 (Coord:1.69 Conf:2.93 Cls:0.59)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 449 Loss:5.31985 (Coord:1.79 Conf:2.92 Cls:0.61)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 450 Loss:5.08176 (Coord:1.85 Conf:2.67 Cls:0.56)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 451 Loss:5.43084 (Coord:2.15 Conf:2.73 Cls:0.55)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 452 Loss:4.89981 (Coord:1.64 Conf:2.68 Cls:0.58)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 453 Loss:5.92788 (Coord:2.36 Conf:2.92 Cls:0.65)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 454 Loss:5.44546 (Coord:1.98 Conf:2.85 Cls:0.62)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 455 Loss:5.27744 (Coord:2.03 Conf:2.68 Cls:0.57)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 456 Loss:5.14865 (Coord:1.96 Conf:2.64 Cls:0.55)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 457 Loss:4.89714 (Coord:1.78 Conf:2.56 Cls:0.55)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 458 Loss:5.20285 (Coord:1.99 Conf:2.63 Cls:0.58)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 459 Loss:5.44276 (Coord:2.27 Conf:2.62 Cls:0.56)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 460 Loss:5.46573 (Coord:2.13 Conf:2.72 Cls:0.61)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 461 Loss:4.87458 (Coord:1.83 Conf:2.50 Cls:0.54)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 462 Loss:5.21616 (Coord:2.12 Conf:2.53 Cls:0.56)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 463 Loss:5.52620 (Coord:2.45 Conf:2.50 Cls:0.58)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 464 Loss:4.99028 (Coord:1.89 Conf:2.52 Cls:0.59)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 465 Loss:5.49358 (Coord:2.36 Conf:2.55 Cls:0.59)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 466 Loss:5.42524 (Coord:2.43 Conf:2.44 Cls:0.56)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 467 Loss:4.86402 (Coord:1.93 Conf:2.40 Cls:0.53)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 468 Loss:5.68939 (Coord:2.56 Conf:2.50 Cls:0.63)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 469 Loss:5.08106 (Coord:2.16 Conf:2.38 Cls:0.54)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 470 Loss:5.12486 (Coord:2.05 Conf:2.46 Cls:0.62)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 471 Loss:5.47449 (Coord:2.40 Conf:2.49 Cls:0.58)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 472 Loss:5.24907 (Coord:2.35 Conf:2.35 Cls:0.55)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 473 Loss:4.81419 (Coord:1.94 Conf:2.33 Cls:0.55)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 474 Loss:5.23195 (Coord:2.23 Conf:2.41 Cls:0.60)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 475 Loss:5.43138 (Coord:2.53 Conf:2.31 Cls:0.58)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 476 Loss:4.68797 (Coord:1.82 Conf:2.29 Cls:0.58)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 477 Loss:5.12113 (Coord:2.20 Conf:2.35 Cls:0.57)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 478 Loss:5.65545 (Coord:2.87 Conf:2.25 Cls:0.54)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 479 Loss:4.44326 (Coord:1.79 Conf:2.10 Cls:0.56)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 480 Loss:4.89907 (Coord:2.09 Conf:2.25 Cls:0.56)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 481 Loss:5.99190 (Coord:2.94 Conf:2.41 Cls:0.64)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 482 Loss:4.94585 (Coord:2.02 Conf:2.34 Cls:0.58)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 483 Loss:4.89685 (Coord:2.09 Conf:2.21 Cls:0.59)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 484 Loss:4.92081 (Coord:2.26 Conf:2.11 Cls:0.56)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 485 Loss:5.72120 (Coord:3.00 Conf:2.16 Cls:0.57)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 486 Loss:4.71809 (Coord:2.09 Conf:2.08 Cls:0.55)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 487 Loss:5.31164 (Coord:2.45 Conf:2.27 Cls:0.59)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 488 Loss:6.01517 (Coord:3.08 Conf:2.30 Cls:0.63)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 489 Loss:5.02301 (Coord:2.37 Conf:2.08 Cls:0.58)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 490 Loss:6.50147 (Coord:3.62 Conf:2.27 Cls:0.61)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 491 Loss:5.20128 (Coord:2.52 Conf:2.09 Cls:0.59)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 492 Loss:5.56214 (Coord:2.84 Conf:2.11 Cls:0.62)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 493 Loss:5.60725 (Coord:2.84 Conf:2.14 Cls:0.63)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 494 Loss:5.42468 (Coord:2.80 Conf:2.03 Cls:0.59)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 495 Loss:4.94621 (Coord:2.26 Conf:2.09 Cls:0.60)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 496 Loss:5.01224 (Coord:2.20 Conf:2.17 Cls:0.65)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 497 Loss:5.19227 (Coord:2.58 Conf:2.01 Cls:0.60)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 498 Loss:4.93112 (Coord:2.19 Conf:2.16 Cls:0.59)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 499 Loss:5.17211 (Coord:2.44 Conf:2.09 Cls:0.64)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 500 Loss:5.31284 (Coord:2.64 Conf:2.05 Cls:0.62)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Saved backup\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 501 Loss:4.53953 (Coord:1.86 Conf:2.09 Cls:0.60)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 502 Loss:4.59689 (Coord:2.04 Conf:1.98 Cls:0.58)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 503 Loss:5.88681 (Coord:3.18 Conf:2.04 Cls:0.67)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 504 Loss:4.60747 (Coord:2.05 Conf:1.98 Cls:0.58)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 505 Loss:4.74472 (Coord:2.06 Conf:2.07 Cls:0.61)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 506 Loss:5.18017 (Coord:2.66 Conf:1.94 Cls:0.58)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 507 Loss:4.96325 (Coord:2.37 Conf:2.00 Cls:0.59)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 508 Loss:4.75507 (Coord:2.33 Conf:1.88 Cls:0.54)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 509 Loss:5.13767 (Coord:2.51 Conf:2.03 Cls:0.59)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 510 Loss:4.75207 (Coord:2.24 Conf:1.94 Cls:0.57)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 511 Loss:5.29788 (Coord:2.65 Conf:1.99 Cls:0.66)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 512 Loss:5.72558 (Coord:3.11 Conf:2.03 Cls:0.59)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 513 Loss:4.86740 (Coord:2.47 Conf:1.88 Cls:0.52)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 514 Loss:5.11761 (Coord:2.58 Conf:1.95 Cls:0.59)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 515 Loss:5.03744 (Coord:2.58 Conf:1.88 Cls:0.58)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 516 Loss:5.34007 (Coord:2.94 Conf:1.81 Cls:0.59)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 517 Loss:4.87976 (Coord:2.43 Conf:1.87 Cls:0.58)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 518 Loss:5.34409 (Coord:2.89 Conf:1.88 Cls:0.57)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 519 Loss:5.37436 (Coord:2.91 Conf:1.84 Cls:0.62)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 520 Loss:4.67742 (Coord:2.26 Conf:1.85 Cls:0.57)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 521 Loss:5.08826 (Coord:2.67 Conf:1.83 Cls:0.58)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 522 Loss:5.34283 (Coord:2.80 Conf:1.93 Cls:0.61)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 523 Loss:4.49893 (Coord:2.15 Conf:1.80 Cls:0.55)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 524 Loss:5.13003 (Coord:2.71 Conf:1.85 Cls:0.57)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 525 Loss:5.42128 (Coord:3.03 Conf:1.83 Cls:0.56)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 526 Loss:4.90734 (Coord:2.51 Conf:1.79 Cls:0.60)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 527 Loss:4.66596 (Coord:2.29 Conf:1.84 Cls:0.54)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 528 Loss:4.99863 (Coord:2.70 Conf:1.73 Cls:0.57)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 529 Loss:4.74861 (Coord:2.35 Conf:1.81 Cls:0.59)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 530 Loss:5.09404 (Coord:2.73 Conf:1.80 Cls:0.56)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 531 Loss:5.06154 (Coord:2.78 Conf:1.72 Cls:0.56)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 532 Loss:4.88765 (Coord:2.48 Conf:1.84 Cls:0.57)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 533 Loss:4.62393 (Coord:2.31 Conf:1.77 Cls:0.55)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 534 Loss:5.21522 (Coord:2.89 Conf:1.75 Cls:0.58)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 535 Loss:4.81629 (Coord:2.54 Conf:1.72 Cls:0.55)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 536 Loss:4.49835 (Coord:2.24 Conf:1.72 Cls:0.55)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 537 Loss:4.78241 (Coord:2.54 Conf:1.69 Cls:0.55)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 538 Loss:5.60015 (Coord:3.37 Conf:1.68 Cls:0.55)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 539 Loss:4.70369 (Coord:2.34 Conf:1.82 Cls:0.54)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 540 Loss:4.89184 (Coord:2.59 Conf:1.74 Cls:0.57)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 541 Loss:5.38297 (Coord:2.97 Conf:1.81 Cls:0.60)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 542 Loss:4.82862 (Coord:2.46 Conf:1.82 Cls:0.55)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 543 Loss:4.67888 (Coord:2.59 Conf:1.57 Cls:0.52)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 544 Loss:5.43332 (Coord:3.13 Conf:1.70 Cls:0.60)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 545 Loss:4.86613 (Coord:2.58 Conf:1.72 Cls:0.57)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 546 Loss:4.76236 (Coord:2.43 Conf:1.75 Cls:0.59)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 547 Loss:5.33132 (Coord:3.15 Conf:1.62 Cls:0.56)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 548 Loss:4.64739 (Coord:2.40 Conf:1.67 Cls:0.58)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 549 Loss:4.82338 (Coord:2.61 Conf:1.64 Cls:0.58)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 550 Loss:5.15080 (Coord:2.90 Conf:1.66 Cls:0.58)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 551 Loss:4.80552 (Coord:2.42 Conf:1.80 Cls:0.59)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 552 Loss:4.34274 (Coord:2.25 Conf:1.57 Cls:0.52)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 553 Loss:4.76361 (Coord:2.59 Conf:1.60 Cls:0.57)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 554 Loss:4.39680 (Coord:2.14 Conf:1.70 Cls:0.56)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 555 Loss:4.25116 (Coord:2.21 Conf:1.52 Cls:0.52)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 556 Loss:4.64709 (Coord:2.46 Conf:1.65 Cls:0.54)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 557 Loss:3.94215 (Coord:1.91 Conf:1.54 Cls:0.49)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 558 Loss:4.31247 (Coord:2.23 Conf:1.57 Cls:0.52)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 559 Loss:4.02232 (Coord:2.02 Conf:1.51 Cls:0.50)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 560 Loss:4.51612 (Coord:2.39 Conf:1.60 Cls:0.53)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 561 Loss:3.91698 (Coord:1.93 Conf:1.49 Cls:0.50)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 562 Loss:4.32847 (Coord:2.29 Conf:1.55 Cls:0.49)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 563 Loss:4.46103 (Coord:2.38 Conf:1.59 Cls:0.49)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 564 Loss:3.61410 (Coord:1.72 Conf:1.45 Cls:0.44)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 565 Loss:4.94879 (Coord:2.85 Conf:1.56 Cls:0.54)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 566 Loss:3.91656 (Coord:1.95 Conf:1.48 Cls:0.49)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 567 Loss:4.07851 (Coord:2.08 Conf:1.52 Cls:0.48)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 568 Loss:4.60613 (Coord:2.60 Conf:1.51 Cls:0.49)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 569 Loss:4.41337 (Coord:2.46 Conf:1.48 Cls:0.47)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 570 Loss:4.06735 (Coord:2.06 Conf:1.51 Cls:0.49)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 571 Loss:4.30132 (Coord:2.35 Conf:1.48 Cls:0.48)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 572 Loss:4.59376 (Coord:2.56 Conf:1.57 Cls:0.47)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 573 Loss:3.69051 (Coord:1.82 Conf:1.42 Cls:0.44)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 574 Loss:4.58672 (Coord:2.52 Conf:1.57 Cls:0.49)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 575 Loss:4.17956 (Coord:2.33 Conf:1.38 Cls:0.46)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 576 Loss:3.60772 (Coord:1.75 Conf:1.41 Cls:0.45)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 577 Loss:4.49514 (Coord:2.56 Conf:1.47 Cls:0.47)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 578 Loss:4.35457 (Coord:2.55 Conf:1.36 Cls:0.45)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 579 Loss:3.83254 (Coord:1.94 Conf:1.42 Cls:0.47)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 580 Loss:3.83717 (Coord:2.00 Conf:1.42 Cls:0.42)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 581 Loss:4.29476 (Coord:2.48 Conf:1.38 Cls:0.43)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 582 Loss:3.82660 (Coord:2.04 Conf:1.36 Cls:0.43)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 583 Loss:3.69434 (Coord:1.95 Conf:1.34 Cls:0.41)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 584 Loss:4.28482 (Coord:2.43 Conf:1.42 Cls:0.44)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 585 Loss:3.52722 (Coord:1.83 Conf:1.31 Cls:0.38)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 586 Loss:3.47421 (Coord:1.70 Conf:1.35 Cls:0.42)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 587 Loss:4.09316 (Coord:2.27 Conf:1.40 Cls:0.42)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 588 Loss:3.91840 (Coord:2.17 Conf:1.34 Cls:0.41)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 589 Loss:3.94319 (Coord:2.10 Conf:1.41 Cls:0.43)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 590 Loss:3.73887 (Coord:2.08 Conf:1.27 Cls:0.39)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 591 Loss:3.94147 (Coord:2.22 Conf:1.32 Cls:0.40)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 592 Loss:3.66711 (Coord:1.96 Conf:1.29 Cls:0.42)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 593 Loss:3.74646 (Coord:1.98 Conf:1.39 Cls:0.38)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 594 Loss:3.51892 (Coord:1.91 Conf:1.24 Cls:0.36)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 595 Loss:3.44281 (Coord:1.72 Conf:1.33 Cls:0.39)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 596 Loss:3.73119 (Coord:2.02 Conf:1.33 Cls:0.38)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 597 Loss:3.87493 (Coord:2.19 Conf:1.29 Cls:0.39)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 598 Loss:3.51917 (Coord:1.75 Conf:1.36 Cls:0.41)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 599 Loss:3.45979 (Coord:1.79 Conf:1.30 Cls:0.37)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 600 Loss:3.38624 (Coord:1.84 Conf:1.18 Cls:0.36)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 601 Loss:3.15171 (Coord:1.49 Conf:1.27 Cls:0.39)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 602 Loss:3.44179 (Coord:1.94 Conf:1.15 Cls:0.35)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 603 Loss:3.72981 (Coord:2.09 Conf:1.26 Cls:0.39)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 604 Loss:2.98415 (Coord:1.38 Conf:1.25 Cls:0.35)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 605 Loss:3.14680 (Coord:1.61 Conf:1.18 Cls:0.36)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 606 Loss:3.86788 (Coord:2.26 Conf:1.24 Cls:0.37)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 607 Loss:2.73661 (Coord:1.29 Conf:1.12 Cls:0.33)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 608 Loss:3.38856 (Coord:1.84 Conf:1.20 Cls:0.35)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 609 Loss:3.29567 (Coord:1.74 Conf:1.21 Cls:0.34)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 610 Loss:2.95694 (Coord:1.54 Conf:1.10 Cls:0.32)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 611 Loss:3.04959 (Coord:1.62 Conf:1.10 Cls:0.33)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 612 Loss:3.23125 (Coord:1.82 Conf:1.09 Cls:0.32)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 613 Loss:3.50013 (Coord:1.92 Conf:1.23 Cls:0.35)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 614 Loss:3.16929 (Coord:1.72 Conf:1.13 Cls:0.32)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 615 Loss:3.40433 (Coord:1.96 Conf:1.13 Cls:0.31)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 616 Loss:3.05814 (Coord:1.62 Conf:1.13 Cls:0.31)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 617 Loss:3.29669 (Coord:1.86 Conf:1.11 Cls:0.33)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 618 Loss:3.36395 (Coord:1.98 Conf:1.07 Cls:0.32)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 619 Loss:3.31839 (Coord:1.81 Conf:1.17 Cls:0.33)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 620 Loss:3.05411 (Coord:1.56 Conf:1.20 Cls:0.30)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 621 Loss:3.11648 (Coord:1.69 Conf:1.12 Cls:0.30)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 622 Loss:3.30239 (Coord:1.88 Conf:1.10 Cls:0.33)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 623 Loss:2.87759 (Coord:1.51 Conf:1.06 Cls:0.30)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 624 Loss:3.05688 (Coord:1.72 Conf:1.02 Cls:0.31)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 625 Loss:3.37384 (Coord:2.03 Conf:1.05 Cls:0.30)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 626 Loss:2.67905 (Coord:1.32 Conf:1.08 Cls:0.28)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 627 Loss:2.77686 (Coord:1.44 Conf:1.04 Cls:0.30)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 628 Loss:3.47846 (Coord:2.11 Conf:1.06 Cls:0.31)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 629 Loss:2.54011 (Coord:1.22 Conf:1.03 Cls:0.29)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 630 Loss:3.14333 (Coord:1.76 Conf:1.06 Cls:0.32)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 631 Loss:2.85704 (Coord:1.60 Conf:0.98 Cls:0.27)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 632 Loss:2.76382 (Coord:1.41 Conf:1.06 Cls:0.30)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 633 Loss:2.62038 (Coord:1.40 Conf:0.97 Cls:0.25)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 634 Loss:3.05843 (Coord:1.77 Conf:1.00 Cls:0.29)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 635 Loss:2.52416 (Coord:1.30 Conf:0.95 Cls:0.27)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 636 Loss:2.61546 (Coord:1.36 Conf:0.97 Cls:0.28)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 637 Loss:2.77654 (Coord:1.53 Conf:0.98 Cls:0.27)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 638 Loss:2.82291 (Coord:1.65 Conf:0.91 Cls:0.25)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 639 Loss:2.52133 (Coord:1.32 Conf:0.94 Cls:0.26)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 640 Loss:2.86891 (Coord:1.52 Conf:1.06 Cls:0.29)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 641 Loss:2.90643 (Coord:1.70 Conf:0.94 Cls:0.27)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 642 Loss:2.12793 (Coord:1.05 Conf:0.83 Cls:0.24)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 643 Loss:3.39634 (Coord:2.04 Conf:1.08 Cls:0.28)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 644 Loss:3.17749 (Coord:1.90 Conf:1.00 Cls:0.28)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 645 Loss:2.80392 (Coord:1.51 Conf:1.02 Cls:0.28)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 646 Loss:2.67698 (Coord:1.52 Conf:0.91 Cls:0.24)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 647 Loss:3.33040 (Coord:2.05 Conf:1.01 Cls:0.27)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 648 Loss:2.74706 (Coord:1.48 Conf:1.00 Cls:0.26)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 649 Loss:3.09096 (Coord:1.88 Conf:0.95 Cls:0.26)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 650 Loss:2.59210 (Coord:1.43 Conf:0.90 Cls:0.26)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 651 Loss:2.82881 (Coord:1.54 Conf:1.04 Cls:0.25)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 652 Loss:2.64219 (Coord:1.45 Conf:0.94 Cls:0.26)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 653 Loss:2.88448 (Coord:1.67 Conf:0.97 Cls:0.25)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 654 Loss:2.80509 (Coord:1.62 Conf:0.94 Cls:0.25)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 655 Loss:2.63325 (Coord:1.44 Conf:0.95 Cls:0.25)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 656 Loss:2.94309 (Coord:1.70 Conf:0.97 Cls:0.27)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 657 Loss:2.64329 (Coord:1.43 Conf:0.97 Cls:0.24)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 658 Loss:2.87355 (Coord:1.70 Conf:0.93 Cls:0.25)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 659 Loss:2.82727 (Coord:1.74 Conf:0.86 Cls:0.23)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 660 Loss:3.01478 (Coord:1.74 Conf:1.00 Cls:0.27)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 661 Loss:2.90726 (Coord:1.75 Conf:0.93 Cls:0.23)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 662 Loss:2.86658 (Coord:1.74 Conf:0.87 Cls:0.26)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 663 Loss:2.87980 (Coord:1.71 Conf:0.91 Cls:0.26)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 664 Loss:3.28231 (Coord:2.05 Conf:0.98 Cls:0.25)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 665 Loss:3.05839 (Coord:1.90 Conf:0.92 Cls:0.25)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 666 Loss:3.22860 (Coord:1.92 Conf:1.04 Cls:0.27)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 667 Loss:3.54818 (Coord:2.31 Conf:0.98 Cls:0.25)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 668 Loss:3.20483 (Coord:2.02 Conf:0.93 Cls:0.26)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 669 Loss:3.10735 (Coord:1.84 Conf:0.99 Cls:0.28)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 670 Loss:3.70646 (Coord:2.38 Conf:1.06 Cls:0.27)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 671 Loss:3.72964 (Coord:2.49 Conf:0.96 Cls:0.27)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 672 Loss:3.00989 (Coord:1.80 Conf:0.95 Cls:0.26)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 673 Loss:3.62663 (Coord:2.45 Conf:0.92 Cls:0.26)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 674 Loss:3.17886 (Coord:1.98 Conf:0.91 Cls:0.28)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 675 Loss:3.75752 (Coord:2.32 Conf:1.10 Cls:0.34)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 676 Loss:3.39612 (Coord:2.18 Conf:0.94 Cls:0.28)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 677 Loss:3.93366 (Coord:2.60 Conf:1.04 Cls:0.30)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 678 Loss:3.51265 (Coord:2.23 Conf:0.99 Cls:0.30)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 679 Loss:3.35622 (Coord:2.08 Conf:0.97 Cls:0.30)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 680 Loss:4.03823 (Coord:2.76 Conf:0.97 Cls:0.31)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 681 Loss:3.48867 (Coord:2.20 Conf:0.98 Cls:0.30)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 682 Loss:3.09299 (Coord:1.84 Conf:0.96 Cls:0.30)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 683 Loss:4.22366 (Coord:2.89 Conf:1.01 Cls:0.33)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 684 Loss:3.27419 (Coord:2.02 Conf:0.96 Cls:0.29)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 685 Loss:2.91633 (Coord:1.66 Conf:0.94 Cls:0.32)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 686 Loss:3.67623 (Coord:2.36 Conf:0.99 Cls:0.33)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 687 Loss:3.83178 (Coord:2.56 Conf:0.97 Cls:0.31)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 688 Loss:3.47467 (Coord:2.04 Conf:1.10 Cls:0.33)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 689 Loss:3.20915 (Coord:2.01 Conf:0.91 Cls:0.29)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 690 Loss:3.74762 (Coord:2.48 Conf:0.99 Cls:0.29)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 691 Loss:3.39593 (Coord:2.13 Conf:0.97 Cls:0.30)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 692 Loss:2.91075 (Coord:1.67 Conf:0.93 Cls:0.31)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 693 Loss:4.12931 (Coord:2.74 Conf:1.05 Cls:0.33)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 694 Loss:3.26506 (Coord:2.08 Conf:0.90 Cls:0.29)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 695 Loss:2.87516 (Coord:1.56 Conf:1.00 Cls:0.31)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 696 Loss:3.41151 (Coord:2.23 Conf:0.89 Cls:0.30)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 697 Loss:3.20871 (Coord:1.92 Conf:0.99 Cls:0.30)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 698 Loss:2.63374 (Coord:1.42 Conf:0.93 Cls:0.28)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 699 Loss:3.01370 (Coord:1.83 Conf:0.89 Cls:0.30)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 700 Loss:2.76510 (Coord:1.63 Conf:0.86 Cls:0.28)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 701 Loss:2.62212 (Coord:1.55 Conf:0.80 Cls:0.27)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 702 Loss:2.79003 (Coord:1.60 Conf:0.91 Cls:0.28)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 703 Loss:2.38148 (Coord:1.30 Conf:0.83 Cls:0.25)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 704 Loss:2.60756 (Coord:1.48 Conf:0.88 Cls:0.25)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 705 Loss:2.48416 (Coord:1.42 Conf:0.81 Cls:0.25)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 706 Loss:2.37926 (Coord:1.31 Conf:0.82 Cls:0.25)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 707 Loss:2.26756 (Coord:1.17 Conf:0.86 Cls:0.23)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 708 Loss:2.52662 (Coord:1.43 Conf:0.85 Cls:0.25)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 709 Loss:2.30749 (Coord:1.29 Conf:0.79 Cls:0.23)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 710 Loss:2.07566 (Coord:1.06 Conf:0.78 Cls:0.23)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 711 Loss:2.29706 (Coord:1.31 Conf:0.77 Cls:0.22)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 712 Loss:2.50165 (Coord:1.53 Conf:0.75 Cls:0.22)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 713 Loss:2.24696 (Coord:1.27 Conf:0.77 Cls:0.21)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 714 Loss:2.25184 (Coord:1.30 Conf:0.74 Cls:0.21)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 715 Loss:2.62232 (Coord:1.64 Conf:0.77 Cls:0.21)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 716 Loss:2.09813 (Coord:1.21 Conf:0.71 Cls:0.18)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 717 Loss:2.32185 (Coord:1.36 Conf:0.76 Cls:0.20)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 718 Loss:2.50747 (Coord:1.58 Conf:0.72 Cls:0.20)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 719 Loss:2.24858 (Coord:1.31 Conf:0.74 Cls:0.19)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 720 Loss:2.25132 (Coord:1.26 Conf:0.80 Cls:0.19)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 721 Loss:2.45099 (Coord:1.56 Conf:0.72 Cls:0.18)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 722 Loss:2.30338 (Coord:1.39 Conf:0.74 Cls:0.18)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 723 Loss:1.90109 (Coord:1.01 Conf:0.74 Cls:0.16)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 724 Loss:2.20361 (Coord:1.25 Conf:0.77 Cls:0.18)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 725 Loss:2.35874 (Coord:1.43 Conf:0.75 Cls:0.18)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 726 Loss:1.77919 (Coord:0.88 Conf:0.72 Cls:0.18)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 727 Loss:1.89229 (Coord:1.07 Conf:0.66 Cls:0.16)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 728 Loss:2.22376 (Coord:1.36 Conf:0.69 Cls:0.17)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 729 Loss:1.68919 (Coord:0.87 Conf:0.66 Cls:0.16)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 730 Loss:1.81816 (Coord:0.98 Conf:0.69 Cls:0.16)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 731 Loss:1.86719 (Coord:1.03 Conf:0.67 Cls:0.16)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 732 Loss:1.70944 (Coord:0.87 Conf:0.68 Cls:0.16)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 733 Loss:1.58807 (Coord:0.78 Conf:0.66 Cls:0.14)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 734 Loss:1.73912 (Coord:0.95 Conf:0.64 Cls:0.15)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 735 Loss:1.66537 (Coord:0.85 Conf:0.69 Cls:0.13)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 736 Loss:1.57487 (Coord:0.76 Conf:0.66 Cls:0.15)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 737 Loss:1.77643 (Coord:1.00 Conf:0.64 Cls:0.13)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 738 Loss:1.60439 (Coord:0.85 Conf:0.63 Cls:0.13)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 739 Loss:1.62624 (Coord:0.83 Conf:0.66 Cls:0.14)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 740 Loss:1.68083 (Coord:0.92 Conf:0.64 Cls:0.12)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 741 Loss:1.59930 (Coord:0.83 Conf:0.64 Cls:0.13)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 742 Loss:1.47157 (Coord:0.72 Conf:0.62 Cls:0.13)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 743 Loss:1.66957 (Coord:0.96 Conf:0.60 Cls:0.11)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 744 Loss:1.43751 (Coord:0.76 Conf:0.56 Cls:0.11)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 745 Loss:1.52582 (Coord:0.76 Conf:0.64 Cls:0.13)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 746 Loss:1.47307 (Coord:0.77 Conf:0.59 Cls:0.11)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 747 Loss:1.67623 (Coord:0.90 Conf:0.68 Cls:0.10)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 748 Loss:1.36267 (Coord:0.69 Conf:0.56 Cls:0.11)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 749 Loss:1.50213 (Coord:0.76 Conf:0.63 Cls:0.11)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 750 Loss:1.45729 (Coord:0.80 Conf:0.55 Cls:0.10)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 751 Loss:1.36695 (Coord:0.68 Conf:0.58 Cls:0.11)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 752 Loss:1.43199 (Coord:0.74 Conf:0.59 Cls:0.10)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 753 Loss:1.41878 (Coord:0.75 Conf:0.57 Cls:0.10)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 754 Loss:1.28918 (Coord:0.62 Conf:0.57 Cls:0.10)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 755 Loss:1.28680 (Coord:0.65 Conf:0.53 Cls:0.11)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 756 Loss:1.40209 (Coord:0.75 Conf:0.56 Cls:0.10)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 757 Loss:1.33788 (Coord:0.69 Conf:0.55 Cls:0.10)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 758 Loss:1.19898 (Coord:0.59 Conf:0.52 Cls:0.09)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 759 Loss:1.38283 (Coord:0.77 Conf:0.52 Cls:0.09)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 760 Loss:1.19343 (Coord:0.61 Conf:0.49 Cls:0.09)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 761 Loss:1.18030 (Coord:0.60 Conf:0.49 Cls:0.09)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 762 Loss:1.28207 (Coord:0.69 Conf:0.50 Cls:0.09)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 763 Loss:1.17646 (Coord:0.58 Conf:0.49 Cls:0.10)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 764 Loss:1.25016 (Coord:0.65 Conf:0.52 Cls:0.08)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 765 Loss:1.16957 (Coord:0.62 Conf:0.47 Cls:0.09)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 766 Loss:1.37728 (Coord:0.75 Conf:0.54 Cls:0.08)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 767 Loss:1.13836 (Coord:0.57 Conf:0.48 Cls:0.09)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 768 Loss:1.21440 (Coord:0.68 Conf:0.45 Cls:0.08)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 769 Loss:1.25303 (Coord:0.65 Conf:0.52 Cls:0.08)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 770 Loss:1.18693 (Coord:0.62 Conf:0.48 Cls:0.09)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 771 Loss:1.07445 (Coord:0.55 Conf:0.45 Cls:0.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 772 Loss:1.23498 (Coord:0.64 Conf:0.52 Cls:0.08)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 773 Loss:1.11832 (Coord:0.56 Conf:0.48 Cls:0.08)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 774 Loss:1.15777 (Coord:0.65 Conf:0.44 Cls:0.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 775 Loss:1.12297 (Coord:0.59 Conf:0.46 Cls:0.08)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 776 Loss:1.12482 (Coord:0.58 Conf:0.47 Cls:0.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 777 Loss:1.06124 (Coord:0.54 Conf:0.44 Cls:0.08)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 778 Loss:1.07177 (Coord:0.56 Conf:0.44 Cls:0.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 779 Loss:1.01168 (Coord:0.53 Conf:0.40 Cls:0.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 780 Loss:1.18472 (Coord:0.68 Conf:0.43 Cls:0.08)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 781 Loss:1.04697 (Coord:0.53 Conf:0.45 Cls:0.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 782 Loss:1.05039 (Coord:0.56 Conf:0.42 Cls:0.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 783 Loss:1.33918 (Coord:0.82 Conf:0.44 Cls:0.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 784 Loss:1.04191 (Coord:0.51 Conf:0.46 Cls:0.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 785 Loss:1.27431 (Coord:0.74 Conf:0.47 Cls:0.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 786 Loss:1.27004 (Coord:0.78 Conf:0.42 Cls:0.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 787 Loss:1.16658 (Coord:0.63 Conf:0.47 Cls:0.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 788 Loss:1.19552 (Coord:0.71 Conf:0.42 Cls:0.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 789 Loss:1.39339 (Coord:0.87 Conf:0.45 Cls:0.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 790 Loss:1.32835 (Coord:0.80 Conf:0.46 Cls:0.07)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 791 Loss:1.30316 (Coord:0.77 Conf:0.46 Cls:0.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 792 Loss:1.73451 (Coord:1.23 Conf:0.43 Cls:0.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 793 Loss:1.36892 (Coord:0.81 Conf:0.49 Cls:0.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 794 Loss:1.26127 (Coord:0.75 Conf:0.44 Cls:0.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 795 Loss:1.97709 (Coord:1.45 Conf:0.45 Cls:0.08)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 796 Loss:1.60770 (Coord:1.04 Conf:0.49 Cls:0.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 797 Loss:1.54744 (Coord:0.96 Conf:0.51 Cls:0.08)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 798 Loss:1.74762 (Coord:1.26 Conf:0.41 Cls:0.08)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 799 Loss:1.76656 (Coord:1.17 Conf:0.51 Cls:0.08)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 800 Loss:1.40322 (Coord:0.83 Conf:0.50 Cls:0.08)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 801 Loss:1.69483 (Coord:1.17 Conf:0.45 Cls:0.08)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 802 Loss:1.96596 (Coord:1.36 Conf:0.51 Cls:0.09)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 803 Loss:1.61124 (Coord:0.97 Conf:0.55 Cls:0.09)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 804 Loss:1.73136 (Coord:1.21 Conf:0.44 Cls:0.08)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 805 Loss:2.66680 (Coord:2.09 Conf:0.49 Cls:0.09)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 806 Loss:1.51415 (Coord:0.84 Conf:0.58 Cls:0.10)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 807 Loss:1.79186 (Coord:1.15 Conf:0.54 Cls:0.10)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 808 Loss:2.41009 (Coord:1.85 Conf:0.46 Cls:0.10)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 809 Loss:1.76776 (Coord:1.15 Conf:0.53 Cls:0.09)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 810 Loss:1.61363 (Coord:0.99 Conf:0.53 Cls:0.09)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 811 Loss:2.54247 (Coord:1.92 Conf:0.51 Cls:0.11)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 812 Loss:1.70001 (Coord:1.09 Conf:0.51 Cls:0.10)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 813 Loss:1.58089 (Coord:0.88 Conf:0.60 Cls:0.10)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 814 Loss:1.96855 (Coord:1.37 Conf:0.50 Cls:0.10)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 815 Loss:2.47874 (Coord:1.78 Conf:0.59 Cls:0.11)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 816 Loss:1.32391 (Coord:0.67 Conf:0.55 Cls:0.10)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 817 Loss:2.02566 (Coord:1.43 Conf:0.49 Cls:0.10)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 818 Loss:1.89431 (Coord:1.30 Conf:0.48 Cls:0.11)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 819 Loss:1.78156 (Coord:1.06 Conf:0.62 Cls:0.10)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 820 Loss:1.63216 (Coord:0.94 Conf:0.58 Cls:0.11)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 821 Loss:2.03230 (Coord:1.32 Conf:0.60 Cls:0.11)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 822 Loss:1.83590 (Coord:1.21 Conf:0.53 Cls:0.09)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 823 Loss:1.15897 (Coord:0.55 Conf:0.51 Cls:0.10)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 824 Loss:1.82737 (Coord:1.12 Conf:0.60 Cls:0.11)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 825 Loss:1.73024 (Coord:1.06 Conf:0.56 Cls:0.10)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 826 Loss:1.17703 (Coord:0.62 Conf:0.47 Cls:0.09)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 827 Loss:1.26655 (Coord:0.67 Conf:0.50 Cls:0.10)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 828 Loss:1.57245 (Coord:0.90 Conf:0.57 Cls:0.10)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 829 Loss:1.46192 (Coord:0.82 Conf:0.55 Cls:0.09)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 830 Loss:1.19128 (Coord:0.59 Conf:0.51 Cls:0.10)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 831 Loss:1.18262 (Coord:0.64 Conf:0.46 Cls:0.08)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 832 Loss:1.27892 (Coord:0.71 Conf:0.49 Cls:0.09)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 833 Loss:1.14428 (Coord:0.56 Conf:0.50 Cls:0.08)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 834 Loss:1.27620 (Coord:0.68 Conf:0.50 Cls:0.09)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 835 Loss:1.10146 (Coord:0.55 Conf:0.47 Cls:0.09)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 836 Loss:1.04726 (Coord:0.55 Conf:0.42 Cls:0.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 837 Loss:1.07370 (Coord:0.55 Conf:0.44 Cls:0.08)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 838 Loss:1.13131 (Coord:0.62 Conf:0.43 Cls:0.08)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 839 Loss:1.03563 (Coord:0.57 Conf:0.39 Cls:0.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 840 Loss:1.05281 (Coord:0.56 Conf:0.43 Cls:0.07)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 841 Loss:1.16332 (Coord:0.59 Conf:0.50 Cls:0.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 842 Loss:0.96882 (Coord:0.48 Conf:0.42 Cls:0.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 843 Loss:0.94696 (Coord:0.50 Conf:0.39 Cls:0.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 844 Loss:0.94223 (Coord:0.47 Conf:0.41 Cls:0.07)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 845 Loss:1.05988 (Coord:0.57 Conf:0.43 Cls:0.06)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 846 Loss:1.11341 (Coord:0.64 Conf:0.41 Cls:0.06)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 847 Loss:1.05760 (Coord:0.54 Conf:0.46 Cls:0.06)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 848 Loss:0.92055 (Coord:0.45 Conf:0.41 Cls:0.06)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 849 Loss:1.02607 (Coord:0.52 Conf:0.44 Cls:0.06)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 850 Loss:1.13152 (Coord:0.60 Conf:0.47 Cls:0.06)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 851 Loss:1.00225 (Coord:0.49 Conf:0.45 Cls:0.06)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 852 Loss:0.95259 (Coord:0.48 Conf:0.41 Cls:0.06)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 853 Loss:0.91717 (Coord:0.49 Conf:0.38 Cls:0.05)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 854 Loss:0.88267 (Coord:0.45 Conf:0.38 Cls:0.05)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 855 Loss:0.86251 (Coord:0.41 Conf:0.40 Cls:0.05)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 856 Loss:1.10153 (Coord:0.60 Conf:0.44 Cls:0.06)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 857 Loss:1.16836 (Coord:0.61 Conf:0.51 Cls:0.05)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 858 Loss:0.97534 (Coord:0.49 Conf:0.43 Cls:0.06)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 859 Loss:1.06910 (Coord:0.55 Conf:0.47 Cls:0.05)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 860 Loss:0.85118 (Coord:0.42 Conf:0.39 Cls:0.05)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 861 Loss:0.95844 (Coord:0.51 Conf:0.40 Cls:0.05)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 862 Loss:1.17390 (Coord:0.65 Conf:0.48 Cls:0.05)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 863 Loss:0.89837 (Coord:0.45 Conf:0.40 Cls:0.05)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 864 Loss:0.84975 (Coord:0.43 Conf:0.37 Cls:0.05)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 865 Loss:0.85597 (Coord:0.43 Conf:0.38 Cls:0.05)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 866 Loss:0.81093 (Coord:0.41 Conf:0.35 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 867 Loss:0.74642 (Coord:0.36 Conf:0.34 Cls:0.05)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 868 Loss:0.85683 (Coord:0.42 Conf:0.38 Cls:0.05)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 869 Loss:0.83662 (Coord:0.42 Conf:0.36 Cls:0.05)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 870 Loss:0.75124 (Coord:0.36 Conf:0.35 Cls:0.05)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 871 Loss:0.82862 (Coord:0.45 Conf:0.34 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 872 Loss:0.75896 (Coord:0.35 Conf:0.36 Cls:0.05)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 873 Loss:0.72966 (Coord:0.36 Conf:0.33 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 874 Loss:0.75466 (Coord:0.38 Conf:0.33 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 875 Loss:0.67651 (Coord:0.31 Conf:0.32 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 876 Loss:0.70773 (Coord:0.35 Conf:0.32 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 877 Loss:0.75500 (Coord:0.38 Conf:0.33 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 878 Loss:0.72341 (Coord:0.35 Conf:0.33 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 879 Loss:0.77862 (Coord:0.42 Conf:0.32 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 880 Loss:0.64281 (Coord:0.29 Conf:0.31 Cls:0.04)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 881 Loss:0.77688 (Coord:0.41 Conf:0.33 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 882 Loss:0.74975 (Coord:0.40 Conf:0.31 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 883 Loss:0.69759 (Coord:0.36 Conf:0.29 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 884 Loss:0.85142 (Coord:0.48 Conf:0.34 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 885 Loss:0.81223 (Coord:0.44 Conf:0.33 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 886 Loss:0.65565 (Coord:0.33 Conf:0.29 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 887 Loss:0.78074 (Coord:0.42 Conf:0.32 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 888 Loss:0.89081 (Coord:0.50 Conf:0.35 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 889 Loss:0.67886 (Coord:0.35 Conf:0.29 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 890 Loss:0.82572 (Coord:0.48 Conf:0.31 Cls:0.04)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 891 Loss:0.79943 (Coord:0.44 Conf:0.32 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 892 Loss:0.75120 (Coord:0.39 Conf:0.33 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 893 Loss:0.79841 (Coord:0.44 Conf:0.33 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 894 Loss:0.73975 (Coord:0.37 Conf:0.33 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 895 Loss:0.75971 (Coord:0.43 Conf:0.30 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 896 Loss:0.81458 (Coord:0.45 Conf:0.33 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 897 Loss:0.66999 (Coord:0.33 Conf:0.30 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 898 Loss:0.65595 (Coord:0.37 Conf:0.26 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 899 Loss:0.73856 (Coord:0.38 Conf:0.33 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 900 Loss:0.82792 (Coord:0.40 Conf:0.39 Cls:0.04)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 901 Loss:0.70598 (Coord:0.38 Conf:0.29 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 902 Loss:0.71007 (Coord:0.37 Conf:0.30 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 903 Loss:0.74027 (Coord:0.37 Conf:0.33 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 904 Loss:0.68648 (Coord:0.36 Conf:0.30 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 905 Loss:0.64563 (Coord:0.35 Conf:0.26 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 906 Loss:0.63797 (Coord:0.32 Conf:0.28 Cls:0.04)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 907 Loss:0.69336 (Coord:0.37 Conf:0.29 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 908 Loss:0.65840 (Coord:0.34 Conf:0.29 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 909 Loss:0.73381 (Coord:0.39 Conf:0.31 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 910 Loss:0.73768 (Coord:0.40 Conf:0.31 Cls:0.03)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 911 Loss:0.69961 (Coord:0.39 Conf:0.27 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 912 Loss:0.80207 (Coord:0.42 Conf:0.35 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 913 Loss:0.63266 (Coord:0.31 Conf:0.29 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 914 Loss:0.76455 (Coord:0.45 Conf:0.28 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 915 Loss:0.73906 (Coord:0.37 Conf:0.33 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 916 Loss:0.89849 (Coord:0.48 Conf:0.39 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 917 Loss:0.74863 (Coord:0.44 Conf:0.28 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 918 Loss:0.73570 (Coord:0.36 Conf:0.34 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 919 Loss:0.63615 (Coord:0.35 Conf:0.26 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 920 Loss:0.73677 (Coord:0.44 Conf:0.26 Cls:0.03)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 921 Loss:0.70311 (Coord:0.37 Conf:0.31 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 922 Loss:0.63366 (Coord:0.32 Conf:0.29 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 923 Loss:0.81661 (Coord:0.51 Conf:0.28 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 924 Loss:0.73706 (Coord:0.37 Conf:0.33 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 925 Loss:0.80863 (Coord:0.47 Conf:0.30 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 926 Loss:0.83089 (Coord:0.49 Conf:0.31 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 927 Loss:0.63067 (Coord:0.29 Conf:0.31 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 928 Loss:0.77341 (Coord:0.42 Conf:0.32 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 929 Loss:0.81969 (Coord:0.47 Conf:0.32 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 930 Loss:0.62373 (Coord:0.31 Conf:0.28 Cls:0.03)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 931 Loss:0.75666 (Coord:0.39 Conf:0.33 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 932 Loss:0.88625 (Coord:0.54 Conf:0.32 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 933 Loss:0.64929 (Coord:0.32 Conf:0.30 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 934 Loss:0.71234 (Coord:0.33 Conf:0.35 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 935 Loss:0.72868 (Coord:0.42 Conf:0.28 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 936 Loss:0.59225 (Coord:0.27 Conf:0.29 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 937 Loss:0.72270 (Coord:0.37 Conf:0.33 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 938 Loss:0.83747 (Coord:0.47 Conf:0.34 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 939 Loss:0.55237 (Coord:0.26 Conf:0.26 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 940 Loss:0.73792 (Coord:0.38 Conf:0.32 Cls:0.03)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 941 Loss:0.71329 (Coord:0.38 Conf:0.30 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 942 Loss:0.58435 (Coord:0.29 Conf:0.26 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 943 Loss:0.66445 (Coord:0.33 Conf:0.30 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 944 Loss:0.78766 (Coord:0.45 Conf:0.31 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 945 Loss:0.68423 (Coord:0.36 Conf:0.30 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 946 Loss:0.60242 (Coord:0.28 Conf:0.29 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 947 Loss:0.74711 (Coord:0.41 Conf:0.31 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 948 Loss:0.67290 (Coord:0.39 Conf:0.25 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 949 Loss:0.64206 (Coord:0.31 Conf:0.30 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 950 Loss:0.74361 (Coord:0.35 Conf:0.37 Cls:0.03)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 951 Loss:0.62607 (Coord:0.34 Conf:0.26 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 952 Loss:0.69887 (Coord:0.36 Conf:0.31 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 953 Loss:0.77995 (Coord:0.41 Conf:0.34 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 954 Loss:0.62470 (Coord:0.35 Conf:0.24 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 955 Loss:0.58984 (Coord:0.26 Conf:0.30 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 956 Loss:0.66418 (Coord:0.34 Conf:0.30 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 957 Loss:0.67785 (Coord:0.35 Conf:0.29 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 958 Loss:0.61282 (Coord:0.31 Conf:0.28 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 959 Loss:0.65940 (Coord:0.35 Conf:0.28 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 960 Loss:0.58758 (Coord:0.30 Conf:0.26 Cls:0.03)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 961 Loss:0.50924 (Coord:0.25 Conf:0.23 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 962 Loss:0.67113 (Coord:0.35 Conf:0.29 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 963 Loss:0.65893 (Coord:0.36 Conf:0.28 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 964 Loss:0.59460 (Coord:0.31 Conf:0.26 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 965 Loss:0.58757 (Coord:0.31 Conf:0.25 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 966 Loss:0.59758 (Coord:0.31 Conf:0.26 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 967 Loss:0.54397 (Coord:0.26 Conf:0.26 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 968 Loss:0.63039 (Coord:0.32 Conf:0.29 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 969 Loss:0.94191 (Coord:0.51 Conf:0.41 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 970 Loss:0.66167 (Coord:0.33 Conf:0.31 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 971 Loss:0.64959 (Coord:0.28 Conf:0.35 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 972 Loss:0.72265 (Coord:0.35 Conf:0.35 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 973 Loss:0.62985 (Coord:0.31 Conf:0.29 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 974 Loss:0.64886 (Coord:0.32 Conf:0.31 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 975 Loss:0.67305 (Coord:0.35 Conf:0.30 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 976 Loss:0.56474 (Coord:0.25 Conf:0.29 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 977 Loss:0.65218 (Coord:0.34 Conf:0.29 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 978 Loss:0.66773 (Coord:0.35 Conf:0.29 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 979 Loss:0.62386 (Coord:0.29 Conf:0.31 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 980 Loss:0.62837 (Coord:0.34 Conf:0.27 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 981 Loss:0.65147 (Coord:0.32 Conf:0.31 Cls:0.03)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 982 Loss:0.50376 (Coord:0.24 Conf:0.24 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 983 Loss:0.53465 (Coord:0.27 Conf:0.24 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 984 Loss:0.72799 (Coord:0.39 Conf:0.32 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 985 Loss:0.57939 (Coord:0.32 Conf:0.24 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 986 Loss:0.56519 (Coord:0.24 Conf:0.30 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 987 Loss:0.59969 (Coord:0.29 Conf:0.29 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 988 Loss:0.55385 (Coord:0.28 Conf:0.25 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 989 Loss:0.53267 (Coord:0.26 Conf:0.25 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 990 Loss:0.52392 (Coord:0.25 Conf:0.26 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 991 Loss:0.59942 (Coord:0.30 Conf:0.27 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 992 Loss:0.58091 (Coord:0.31 Conf:0.25 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 993 Loss:0.61022 (Coord:0.30 Conf:0.29 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 994 Loss:0.54497 (Coord:0.29 Conf:0.24 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 995 Loss:0.54781 (Coord:0.28 Conf:0.25 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 996 Loss:0.75925 (Coord:0.42 Conf:0.31 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 997 Loss:0.89559 (Coord:0.50 Conf:0.37 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 998 Loss:0.78174 (Coord:0.48 Conf:0.28 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 999 Loss:0.85377 (Coord:0.43 Conf:0.40 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1000 Loss:0.69926 (Coord:0.30 Conf:0.38 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Saved backup\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1001 Loss:0.58953 (Coord:0.31 Conf:0.25 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1002 Loss:0.71496 (Coord:0.39 Conf:0.31 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1003 Loss:0.62907 (Coord:0.33 Conf:0.28 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1004 Loss:0.62991 (Coord:0.33 Conf:0.28 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1005 Loss:0.57271 (Coord:0.30 Conf:0.25 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1006 Loss:0.56481 (Coord:0.30 Conf:0.25 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1007 Loss:0.57497 (Coord:0.29 Conf:0.27 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1008 Loss:0.50796 (Coord:0.25 Conf:0.23 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1009 Loss:0.48018 (Coord:0.24 Conf:0.22 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1010 Loss:0.49107 (Coord:0.24 Conf:0.23 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1011 Loss:0.45498 (Coord:0.20 Conf:0.23 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1012 Loss:0.47971 (Coord:0.22 Conf:0.24 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1013 Loss:0.41579 (Coord:0.19 Conf:0.21 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1014 Loss:0.45104 (Coord:0.20 Conf:0.23 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1015 Loss:0.45819 (Coord:0.20 Conf:0.23 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1016 Loss:0.43700 (Coord:0.19 Conf:0.23 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1017 Loss:0.42044 (Coord:0.18 Conf:0.22 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1018 Loss:0.43585 (Coord:0.19 Conf:0.22 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1019 Loss:0.41080 (Coord:0.17 Conf:0.22 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1020 Loss:0.44128 (Coord:0.19 Conf:0.23 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1021 Loss:0.39688 (Coord:0.16 Conf:0.21 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1022 Loss:0.40085 (Coord:0.17 Conf:0.21 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1023 Loss:0.39164 (Coord:0.16 Conf:0.21 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1024 Loss:0.38941 (Coord:0.16 Conf:0.21 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1025 Loss:0.39549 (Coord:0.16 Conf:0.21 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1026 Loss:0.37585 (Coord:0.15 Conf:0.20 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1027 Loss:0.38892 (Coord:0.17 Conf:0.19 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1028 Loss:0.36442 (Coord:0.15 Conf:0.20 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1029 Loss:0.38288 (Coord:0.15 Conf:0.21 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1030 Loss:0.36082 (Coord:0.15 Conf:0.19 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1031 Loss:0.33964 (Coord:0.14 Conf:0.18 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1032 Loss:0.36415 (Coord:0.15 Conf:0.20 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1033 Loss:0.36575 (Coord:0.15 Conf:0.20 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1034 Loss:0.35190 (Coord:0.14 Conf:0.19 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1035 Loss:0.33760 (Coord:0.14 Conf:0.18 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1036 Loss:0.34998 (Coord:0.14 Conf:0.19 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1037 Loss:0.35846 (Coord:0.15 Conf:0.19 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1038 Loss:0.34348 (Coord:0.14 Conf:0.18 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1039 Loss:0.34411 (Coord:0.13 Conf:0.19 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1040 Loss:0.31463 (Coord:0.12 Conf:0.17 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1041 Loss:0.33249 (Coord:0.13 Conf:0.18 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1042 Loss:0.32031 (Coord:0.12 Conf:0.18 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1043 Loss:0.31747 (Coord:0.12 Conf:0.17 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1044 Loss:0.33321 (Coord:0.13 Conf:0.19 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1045 Loss:0.32229 (Coord:0.12 Conf:0.18 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1046 Loss:0.29458 (Coord:0.11 Conf:0.16 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1047 Loss:0.30598 (Coord:0.12 Conf:0.17 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1048 Loss:0.33275 (Coord:0.13 Conf:0.18 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1049 Loss:0.29935 (Coord:0.12 Conf:0.16 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1050 Loss:0.29338 (Coord:0.10 Conf:0.17 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1051 Loss:0.29326 (Coord:0.11 Conf:0.16 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1052 Loss:0.28686 (Coord:0.11 Conf:0.16 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1053 Loss:0.31790 (Coord:0.12 Conf:0.18 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1054 Loss:0.29710 (Coord:0.12 Conf:0.16 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1055 Loss:0.28899 (Coord:0.11 Conf:0.16 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1056 Loss:0.29104 (Coord:0.10 Conf:0.17 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1057 Loss:0.29357 (Coord:0.11 Conf:0.17 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1058 Loss:0.28659 (Coord:0.10 Conf:0.16 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1059 Loss:0.30024 (Coord:0.11 Conf:0.17 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1060 Loss:0.27289 (Coord:0.11 Conf:0.15 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1061 Loss:0.28981 (Coord:0.11 Conf:0.16 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1062 Loss:0.28142 (Coord:0.10 Conf:0.16 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1063 Loss:0.28488 (Coord:0.10 Conf:0.16 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1064 Loss:0.27592 (Coord:0.10 Conf:0.16 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1065 Loss:0.27274 (Coord:0.10 Conf:0.16 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1066 Loss:0.26381 (Coord:0.09 Conf:0.15 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1067 Loss:0.26831 (Coord:0.10 Conf:0.15 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1068 Loss:0.29063 (Coord:0.10 Conf:0.17 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1069 Loss:0.26029 (Coord:0.09 Conf:0.15 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1070 Loss:0.27130 (Coord:0.10 Conf:0.15 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1071 Loss:0.26199 (Coord:0.09 Conf:0.15 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1072 Loss:0.27426 (Coord:0.09 Conf:0.16 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1073 Loss:0.26953 (Coord:0.10 Conf:0.15 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1074 Loss:0.27023 (Coord:0.09 Conf:0.16 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1075 Loss:0.26856 (Coord:0.09 Conf:0.16 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1076 Loss:0.25948 (Coord:0.09 Conf:0.15 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1077 Loss:0.25982 (Coord:0.09 Conf:0.15 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1078 Loss:0.26919 (Coord:0.10 Conf:0.15 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1079 Loss:0.26912 (Coord:0.09 Conf:0.16 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1080 Loss:0.24344 (Coord:0.09 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1081 Loss:0.24822 (Coord:0.09 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1082 Loss:0.25835 (Coord:0.09 Conf:0.15 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1083 Loss:0.24218 (Coord:0.08 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1084 Loss:0.25018 (Coord:0.09 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1085 Loss:0.28484 (Coord:0.10 Conf:0.17 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1086 Loss:0.24920 (Coord:0.08 Conf:0.15 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1087 Loss:0.24154 (Coord:0.08 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1088 Loss:0.24513 (Coord:0.09 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1089 Loss:0.24934 (Coord:0.08 Conf:0.15 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1090 Loss:0.23928 (Coord:0.08 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1091 Loss:0.25061 (Coord:0.08 Conf:0.15 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1092 Loss:0.23602 (Coord:0.08 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1093 Loss:0.26965 (Coord:0.09 Conf:0.16 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1094 Loss:0.24837 (Coord:0.08 Conf:0.15 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1095 Loss:0.24362 (Coord:0.08 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1096 Loss:0.24294 (Coord:0.07 Conf:0.15 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1097 Loss:0.23667 (Coord:0.08 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1098 Loss:0.24256 (Coord:0.08 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1099 Loss:0.22500 (Coord:0.07 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1100 Loss:0.25469 (Coord:0.08 Conf:0.15 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1101 Loss:0.23552 (Coord:0.08 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1102 Loss:0.24113 (Coord:0.08 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1103 Loss:0.23179 (Coord:0.07 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1104 Loss:0.23067 (Coord:0.07 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1105 Loss:0.24384 (Coord:0.08 Conf:0.15 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1106 Loss:0.23364 (Coord:0.08 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1107 Loss:0.22912 (Coord:0.07 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1108 Loss:0.22576 (Coord:0.07 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1109 Loss:0.23412 (Coord:0.08 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1110 Loss:0.22823 (Coord:0.07 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1111 Loss:0.21832 (Coord:0.07 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1112 Loss:0.24205 (Coord:0.07 Conf:0.15 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1113 Loss:0.23420 (Coord:0.07 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1114 Loss:0.22106 (Coord:0.07 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1115 Loss:0.21503 (Coord:0.07 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1116 Loss:0.23695 (Coord:0.07 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1117 Loss:0.21269 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1118 Loss:0.23677 (Coord:0.07 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1119 Loss:0.24181 (Coord:0.08 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1120 Loss:0.23532 (Coord:0.07 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1121 Loss:0.20773 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1122 Loss:0.22015 (Coord:0.07 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1123 Loss:0.22916 (Coord:0.07 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1124 Loss:0.20954 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1125 Loss:0.22191 (Coord:0.07 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1126 Loss:0.23862 (Coord:0.07 Conf:0.15 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1127 Loss:0.20756 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1128 Loss:0.21100 (Coord:0.07 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1129 Loss:0.21048 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1130 Loss:0.21783 (Coord:0.07 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1131 Loss:0.22538 (Coord:0.07 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1132 Loss:0.22081 (Coord:0.07 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1133 Loss:0.21143 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1134 Loss:0.22000 (Coord:0.06 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1135 Loss:0.21227 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1136 Loss:0.21805 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1137 Loss:0.21580 (Coord:0.07 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1138 Loss:0.20548 (Coord:0.06 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1139 Loss:0.21588 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1140 Loss:0.21210 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1141 Loss:0.20564 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1142 Loss:0.20701 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1143 Loss:0.22089 (Coord:0.07 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1144 Loss:0.20862 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1145 Loss:0.20927 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1146 Loss:0.22130 (Coord:0.07 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1147 Loss:0.20230 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1148 Loss:0.21656 (Coord:0.06 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1149 Loss:0.19934 (Coord:0.06 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1150 Loss:0.20396 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1151 Loss:0.19881 (Coord:0.06 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1152 Loss:0.21740 (Coord:0.06 Conf:0.14 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1153 Loss:0.20064 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1154 Loss:0.20396 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1155 Loss:0.20851 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1156 Loss:0.19819 (Coord:0.06 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1157 Loss:0.20148 (Coord:0.05 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1158 Loss:0.20747 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1159 Loss:0.19793 (Coord:0.06 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1160 Loss:0.20541 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1161 Loss:0.20323 (Coord:0.06 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1162 Loss:0.19158 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1163 Loss:0.21623 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1164 Loss:0.19614 (Coord:0.06 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1165 Loss:0.18870 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1166 Loss:0.19800 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1167 Loss:0.21086 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1168 Loss:0.19841 (Coord:0.05 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1169 Loss:0.19182 (Coord:0.06 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1170 Loss:0.20202 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1171 Loss:0.20423 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1172 Loss:0.20137 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1173 Loss:0.20214 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1174 Loss:0.19401 (Coord:0.06 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1175 Loss:0.19283 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1176 Loss:0.19825 (Coord:0.05 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1177 Loss:0.20910 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1178 Loss:0.18785 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1179 Loss:0.19403 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1180 Loss:0.18417 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1181 Loss:0.20169 (Coord:0.05 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1182 Loss:0.20234 (Coord:0.05 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1183 Loss:0.19293 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1184 Loss:0.18875 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1185 Loss:0.18750 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1186 Loss:0.19317 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1187 Loss:0.19533 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1188 Loss:0.18395 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1189 Loss:0.18779 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1190 Loss:0.20455 (Coord:0.06 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1191 Loss:0.19737 (Coord:0.05 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1192 Loss:0.19054 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1193 Loss:0.18711 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1194 Loss:0.19237 (Coord:0.06 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1195 Loss:0.19416 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1196 Loss:0.18868 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1197 Loss:0.19212 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1198 Loss:0.19768 (Coord:0.05 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1199 Loss:0.19033 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1200 Loss:0.18409 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1201 Loss:0.17732 (Coord:0.05 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1202 Loss:0.19907 (Coord:0.05 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1203 Loss:0.18383 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1204 Loss:0.18667 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1205 Loss:0.18548 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1206 Loss:0.18268 (Coord:0.05 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1207 Loss:0.19011 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1208 Loss:0.18572 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1209 Loss:0.18199 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1210 Loss:0.19294 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1211 Loss:0.18158 (Coord:0.04 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1212 Loss:0.18793 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1213 Loss:0.18365 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1214 Loss:0.18714 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1215 Loss:0.18715 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1216 Loss:0.17562 (Coord:0.05 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1217 Loss:0.18240 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1218 Loss:0.19211 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1219 Loss:0.18277 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1220 Loss:0.18816 (Coord:0.04 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1221 Loss:0.18739 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1222 Loss:0.18467 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1223 Loss:0.17660 (Coord:0.04 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1224 Loss:0.16931 (Coord:0.05 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1225 Loss:0.19714 (Coord:0.05 Conf:0.13 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1226 Loss:0.18179 (Coord:0.04 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1227 Loss:0.17597 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1228 Loss:0.18381 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1229 Loss:0.19132 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1230 Loss:0.17216 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1231 Loss:0.17284 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1232 Loss:0.18610 (Coord:0.04 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1233 Loss:0.17288 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1234 Loss:0.17695 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1235 Loss:0.18405 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1236 Loss:0.17424 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1237 Loss:0.18373 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1238 Loss:0.16594 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1239 Loss:0.17712 (Coord:0.05 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1240 Loss:0.18627 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1241 Loss:0.16824 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1242 Loss:0.18424 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1243 Loss:0.18449 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1244 Loss:0.17106 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1245 Loss:0.19126 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1246 Loss:0.17236 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1247 Loss:0.17031 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1248 Loss:0.18227 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1249 Loss:0.17811 (Coord:0.04 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1250 Loss:0.17385 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1251 Loss:0.17325 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1252 Loss:0.16296 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1253 Loss:0.17631 (Coord:0.04 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1254 Loss:0.17626 (Coord:0.04 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1255 Loss:0.17742 (Coord:0.04 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1256 Loss:0.17527 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1257 Loss:0.18156 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1258 Loss:0.16819 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1259 Loss:0.16849 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1260 Loss:0.18725 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1261 Loss:0.17422 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1262 Loss:0.16726 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1263 Loss:0.16764 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1264 Loss:0.17809 (Coord:0.04 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1265 Loss:0.17771 (Coord:0.04 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1266 Loss:0.18466 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1267 Loss:0.17345 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1268 Loss:0.17628 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1269 Loss:0.16071 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1270 Loss:0.18203 (Coord:0.04 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1271 Loss:0.17077 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1272 Loss:0.16082 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1273 Loss:0.16397 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1274 Loss:0.17223 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1275 Loss:0.18237 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1276 Loss:0.17975 (Coord:0.04 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1277 Loss:0.16235 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1278 Loss:0.16416 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1279 Loss:0.16895 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1280 Loss:0.17627 (Coord:0.04 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1281 Loss:0.16577 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1282 Loss:0.16132 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1283 Loss:0.18234 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1284 Loss:0.16955 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1285 Loss:0.17242 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1286 Loss:0.16457 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1287 Loss:0.16565 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1288 Loss:0.16499 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1289 Loss:0.17363 (Coord:0.04 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1290 Loss:0.16746 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1291 Loss:0.16983 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1292 Loss:0.17878 (Coord:0.04 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1293 Loss:0.16609 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1294 Loss:0.14961 (Coord:0.04 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1295 Loss:0.17485 (Coord:0.04 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1296 Loss:0.16844 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1297 Loss:0.17858 (Coord:0.04 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1298 Loss:0.17194 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1299 Loss:0.15714 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1300 Loss:0.15668 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1301 Loss:0.15551 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1302 Loss:0.18569 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1303 Loss:0.17019 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1304 Loss:0.16524 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1305 Loss:0.16741 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1306 Loss:0.15986 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1307 Loss:0.16192 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1308 Loss:0.16471 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1309 Loss:0.16457 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1310 Loss:0.16652 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1311 Loss:0.16319 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1312 Loss:0.15643 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1313 Loss:0.16617 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1314 Loss:0.15965 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1315 Loss:0.16831 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1316 Loss:0.16749 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1317 Loss:0.15775 (Coord:0.03 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1318 Loss:0.17315 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1319 Loss:0.16813 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1320 Loss:0.17280 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1321 Loss:0.16231 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1322 Loss:0.15993 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1323 Loss:0.17336 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1324 Loss:0.14975 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1325 Loss:0.16034 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1326 Loss:0.16369 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1327 Loss:0.15375 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1328 Loss:0.15890 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1329 Loss:0.16660 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1330 Loss:0.17304 (Coord:0.04 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1331 Loss:0.14887 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1332 Loss:0.17538 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1333 Loss:0.15074 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1334 Loss:0.16767 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1335 Loss:0.15766 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1336 Loss:0.16782 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1337 Loss:0.15210 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1338 Loss:0.16813 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1339 Loss:0.15204 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1340 Loss:0.15878 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1341 Loss:0.15972 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1342 Loss:0.15463 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1343 Loss:0.18206 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1344 Loss:0.14537 (Coord:0.03 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1345 Loss:0.15220 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1346 Loss:0.17363 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1347 Loss:0.15467 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1348 Loss:0.16698 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1349 Loss:0.15293 (Coord:0.04 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1350 Loss:0.15786 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1351 Loss:0.15110 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1352 Loss:0.15340 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1353 Loss:0.18198 (Coord:0.05 Conf:0.12 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1354 Loss:0.15387 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1355 Loss:0.16294 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1356 Loss:0.16093 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1357 Loss:0.15231 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1358 Loss:0.15518 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1359 Loss:0.15939 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1360 Loss:0.15120 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1361 Loss:0.15795 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1362 Loss:0.15800 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1363 Loss:0.16211 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1364 Loss:0.15878 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1365 Loss:0.15850 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1366 Loss:0.16977 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1367 Loss:0.14460 (Coord:0.03 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1368 Loss:0.17481 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1369 Loss:0.14454 (Coord:0.03 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1370 Loss:0.15627 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1371 Loss:0.15852 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1372 Loss:0.14941 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1373 Loss:0.15891 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1374 Loss:0.15971 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1375 Loss:0.15216 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1376 Loss:0.15540 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1377 Loss:0.15449 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1378 Loss:0.15991 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1379 Loss:0.15494 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1380 Loss:0.15170 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1381 Loss:0.14685 (Coord:0.03 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1382 Loss:0.16003 (Coord:0.03 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1383 Loss:0.15824 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1384 Loss:0.15524 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1385 Loss:0.14481 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1386 Loss:0.16186 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1387 Loss:0.15728 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1388 Loss:0.14971 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1389 Loss:0.14716 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1390 Loss:0.15718 (Coord:0.03 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1391 Loss:0.16265 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1392 Loss:0.14150 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1393 Loss:0.15483 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1394 Loss:0.15927 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1395 Loss:0.14603 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1396 Loss:0.15008 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1397 Loss:0.15128 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1398 Loss:0.16120 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1399 Loss:0.14385 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1400 Loss:0.15536 (Coord:0.03 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1401 Loss:0.15070 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1402 Loss:0.15793 (Coord:0.03 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1403 Loss:0.14854 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1404 Loss:0.13988 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1405 Loss:0.16336 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1406 Loss:0.15272 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1407 Loss:0.14147 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1408 Loss:0.16378 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1409 Loss:0.15424 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1410 Loss:0.15881 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1411 Loss:0.15648 (Coord:0.03 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1412 Loss:0.15013 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1413 Loss:0.13249 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1414 Loss:0.16281 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1415 Loss:0.14614 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1416 Loss:0.14420 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1417 Loss:0.14207 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1418 Loss:0.15667 (Coord:0.03 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1419 Loss:0.15777 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1420 Loss:0.14770 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1421 Loss:0.14994 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1422 Loss:0.15203 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1423 Loss:0.16769 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1424 Loss:0.13980 (Coord:0.03 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1425 Loss:0.15162 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1426 Loss:0.14302 (Coord:0.03 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1427 Loss:0.15330 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1428 Loss:0.14801 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1429 Loss:0.15209 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1430 Loss:0.14718 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1431 Loss:0.14276 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1432 Loss:0.15815 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1433 Loss:0.14926 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1434 Loss:0.14553 (Coord:0.03 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1435 Loss:0.14450 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1436 Loss:0.14736 (Coord:0.03 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1437 Loss:0.15299 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1438 Loss:0.14888 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1439 Loss:0.15431 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1440 Loss:0.14426 (Coord:0.03 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1441 Loss:0.15014 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1442 Loss:0.14931 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1443 Loss:0.15302 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1444 Loss:0.15510 (Coord:0.03 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1445 Loss:0.14088 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1446 Loss:0.14206 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1447 Loss:0.14963 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1448 Loss:0.15654 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1449 Loss:0.14030 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1450 Loss:0.14787 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1451 Loss:0.15483 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1452 Loss:0.15046 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1453 Loss:0.14327 (Coord:0.03 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1454 Loss:0.13941 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1455 Loss:0.14580 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1456 Loss:0.16043 (Coord:0.04 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1457 Loss:0.14291 (Coord:0.03 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1458 Loss:0.14665 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1459 Loss:0.14769 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1460 Loss:0.15385 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1461 Loss:0.14009 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1462 Loss:0.13838 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1463 Loss:0.14592 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1464 Loss:0.13602 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1465 Loss:0.14118 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1466 Loss:0.15395 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1467 Loss:0.14627 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1468 Loss:0.15015 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1469 Loss:0.13176 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1470 Loss:0.15339 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1471 Loss:0.14406 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1472 Loss:0.13703 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1473 Loss:0.14471 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1474 Loss:0.14943 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1475 Loss:0.14471 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1476 Loss:0.14752 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1477 Loss:0.14541 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1478 Loss:0.14099 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1479 Loss:0.14446 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1480 Loss:0.15239 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1481 Loss:0.13820 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1482 Loss:0.13688 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1483 Loss:0.13758 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1484 Loss:0.15953 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1485 Loss:0.14009 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1486 Loss:0.14170 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1487 Loss:0.14280 (Coord:0.03 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1488 Loss:0.14080 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1489 Loss:0.14230 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1490 Loss:0.14963 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1491 Loss:0.13731 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1492 Loss:0.14688 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1493 Loss:0.14813 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1494 Loss:0.13739 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1495 Loss:0.14926 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1496 Loss:0.14081 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1497 Loss:0.14501 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1498 Loss:0.13852 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1499 Loss:0.14098 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1500 Loss:0.14850 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Saved backup\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1501 Loss:0.14002 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1502 Loss:0.14001 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1503 Loss:0.14276 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1504 Loss:0.12667 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1505 Loss:0.14975 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1506 Loss:0.14324 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1507 Loss:0.15633 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1508 Loss:0.13916 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1509 Loss:0.14522 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1510 Loss:0.14747 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1511 Loss:0.15257 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1512 Loss:0.12630 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1513 Loss:0.14089 (Coord:0.03 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1514 Loss:0.14060 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1515 Loss:0.13911 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1516 Loss:0.13864 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1517 Loss:0.14441 (Coord:0.03 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1518 Loss:0.14132 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1519 Loss:0.15197 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1520 Loss:0.13841 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1521 Loss:0.14410 (Coord:0.03 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1522 Loss:0.13899 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1523 Loss:0.13961 (Coord:0.03 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1524 Loss:0.14308 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1525 Loss:0.14071 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1526 Loss:0.13438 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1527 Loss:0.13744 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1528 Loss:0.14313 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1529 Loss:0.14798 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1530 Loss:0.13299 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1531 Loss:0.15481 (Coord:0.03 Conf:0.11 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1532 Loss:0.14450 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1533 Loss:0.13816 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1534 Loss:0.14421 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1535 Loss:0.14345 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1536 Loss:0.12858 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1537 Loss:0.14184 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1538 Loss:0.15520 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1539 Loss:0.13489 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1540 Loss:0.14055 (Coord:0.03 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1541 Loss:0.14736 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1542 Loss:0.14148 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1543 Loss:0.14669 (Coord:0.03 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1544 Loss:0.13221 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1545 Loss:0.13826 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1546 Loss:0.13890 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1547 Loss:0.14152 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1548 Loss:0.14160 (Coord:0.03 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1549 Loss:0.14507 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1550 Loss:0.13792 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1551 Loss:0.14247 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1552 Loss:0.14135 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1553 Loss:0.12600 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1554 Loss:0.14060 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1555 Loss:0.14038 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1556 Loss:0.12722 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1557 Loss:0.14386 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1558 Loss:0.13743 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1559 Loss:0.15058 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1560 Loss:0.13901 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1561 Loss:0.14562 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1562 Loss:0.14344 (Coord:0.03 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1563 Loss:0.13765 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1564 Loss:0.13355 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1565 Loss:0.13936 (Coord:0.03 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1566 Loss:0.13223 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1567 Loss:0.13411 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1568 Loss:0.13546 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1569 Loss:0.13477 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1570 Loss:0.13142 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1571 Loss:0.14136 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1572 Loss:0.14564 (Coord:0.03 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1573 Loss:0.14190 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1574 Loss:0.13038 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1575 Loss:0.14069 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1576 Loss:0.14062 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1577 Loss:0.13266 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1578 Loss:0.12999 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1579 Loss:0.14735 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1580 Loss:0.13339 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1581 Loss:0.14067 (Coord:0.03 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1582 Loss:0.13992 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1583 Loss:0.14224 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1584 Loss:0.13564 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1585 Loss:0.13385 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1586 Loss:0.12273 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1587 Loss:0.14459 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1588 Loss:0.13696 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1589 Loss:0.13990 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1590 Loss:0.13743 (Coord:0.03 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1591 Loss:0.13042 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1592 Loss:0.12736 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1593 Loss:0.13752 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1594 Loss:0.14636 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1595 Loss:0.13937 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1596 Loss:0.13143 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1597 Loss:0.14325 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1598 Loss:0.13879 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1599 Loss:0.13083 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1600 Loss:0.14845 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1601 Loss:0.13390 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1602 Loss:0.13167 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1603 Loss:0.13920 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1604 Loss:0.13199 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1605 Loss:0.12704 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1606 Loss:0.13761 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1607 Loss:0.13358 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1608 Loss:0.12316 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1609 Loss:0.14188 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1610 Loss:0.13307 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1611 Loss:0.12846 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1612 Loss:0.13608 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1613 Loss:0.13266 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1614 Loss:0.12895 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1615 Loss:0.14039 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1616 Loss:0.12555 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1617 Loss:0.13345 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1618 Loss:0.13422 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1619 Loss:0.13017 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1620 Loss:0.13964 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1621 Loss:0.12760 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1622 Loss:0.13429 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1623 Loss:0.12557 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1624 Loss:0.13420 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1625 Loss:0.13217 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1626 Loss:0.13331 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1627 Loss:0.14095 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1628 Loss:0.12418 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1629 Loss:0.12342 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1630 Loss:0.14261 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1631 Loss:0.13405 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1632 Loss:0.13276 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1633 Loss:0.13706 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1634 Loss:0.12562 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1635 Loss:0.13442 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1636 Loss:0.13507 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1637 Loss:0.13136 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1638 Loss:0.14266 (Coord:0.04 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1639 Loss:0.12789 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1640 Loss:0.12834 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1641 Loss:0.13052 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1642 Loss:0.13846 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1643 Loss:0.13317 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1644 Loss:0.12054 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1645 Loss:0.13454 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1646 Loss:0.14042 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1647 Loss:0.13012 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1648 Loss:0.13439 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1649 Loss:0.13486 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1650 Loss:0.12943 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1651 Loss:0.13726 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1652 Loss:0.12665 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1653 Loss:0.13223 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1654 Loss:0.12724 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1655 Loss:0.15277 (Coord:0.04 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1656 Loss:0.12223 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1657 Loss:0.12522 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1658 Loss:0.14071 (Coord:0.03 Conf:0.10 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1659 Loss:0.12441 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1660 Loss:0.13664 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1661 Loss:0.12741 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1662 Loss:0.13984 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1663 Loss:0.14212 (Coord:0.03 Conf:0.10 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1664 Loss:0.12641 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1665 Loss:0.12706 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1666 Loss:0.12872 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1667 Loss:0.14363 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1668 Loss:0.12802 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1669 Loss:0.13353 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1670 Loss:0.13064 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1671 Loss:0.13472 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1672 Loss:0.12486 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1673 Loss:0.12891 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1674 Loss:0.12425 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1675 Loss:0.13209 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1676 Loss:0.12680 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1677 Loss:0.13293 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1678 Loss:0.12451 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1679 Loss:0.13125 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1680 Loss:0.13094 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1681 Loss:0.12066 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1682 Loss:0.13307 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1683 Loss:0.13539 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1684 Loss:0.12467 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1685 Loss:0.12041 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1686 Loss:0.12987 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1687 Loss:0.13330 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1688 Loss:0.13731 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1689 Loss:0.13009 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1690 Loss:0.12964 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1691 Loss:0.12865 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1692 Loss:0.13115 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1693 Loss:0.12909 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1694 Loss:0.13702 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1695 Loss:0.13210 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1696 Loss:0.12350 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1697 Loss:0.11994 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1698 Loss:0.13109 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1699 Loss:0.12649 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1700 Loss:0.13629 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1701 Loss:0.13521 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1702 Loss:0.12478 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1703 Loss:0.13643 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1704 Loss:0.12304 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1705 Loss:0.13487 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1706 Loss:0.13126 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1707 Loss:0.13226 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1708 Loss:0.12319 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1709 Loss:0.12358 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1710 Loss:0.12141 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1711 Loss:0.13107 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1712 Loss:0.13943 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1713 Loss:0.12567 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1714 Loss:0.13780 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1715 Loss:0.12445 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1716 Loss:0.12311 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1717 Loss:0.12395 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1718 Loss:0.12805 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1719 Loss:0.12596 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1720 Loss:0.12627 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1721 Loss:0.12727 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1722 Loss:0.13172 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1723 Loss:0.12923 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1724 Loss:0.12039 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1725 Loss:0.12615 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1726 Loss:0.12611 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1727 Loss:0.12176 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1728 Loss:0.12951 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1729 Loss:0.13172 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1730 Loss:0.12548 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1731 Loss:0.12434 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1732 Loss:0.12844 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1733 Loss:0.11126 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1734 Loss:0.13299 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1735 Loss:0.14207 (Coord:0.04 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1736 Loss:0.12244 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1737 Loss:0.12615 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1738 Loss:0.12312 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1739 Loss:0.13186 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1740 Loss:0.12257 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1741 Loss:0.12153 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1742 Loss:0.13011 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1743 Loss:0.12726 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1744 Loss:0.13597 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1745 Loss:0.13056 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1746 Loss:0.12673 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1747 Loss:0.11590 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1748 Loss:0.12447 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1749 Loss:0.12652 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1750 Loss:0.12888 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1751 Loss:0.11965 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1752 Loss:0.13056 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1753 Loss:0.12982 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1754 Loss:0.11281 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1755 Loss:0.12853 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1756 Loss:0.14060 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1757 Loss:0.12827 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1758 Loss:0.12697 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1759 Loss:0.12224 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1760 Loss:0.12356 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1761 Loss:0.12503 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1762 Loss:0.12643 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1763 Loss:0.12379 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1764 Loss:0.12618 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1765 Loss:0.14090 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1766 Loss:0.13076 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1767 Loss:0.11796 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1768 Loss:0.12367 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1769 Loss:0.12368 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1770 Loss:0.12294 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1771 Loss:0.13703 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1772 Loss:0.12533 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1773 Loss:0.12071 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1774 Loss:0.13994 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1775 Loss:0.12323 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1776 Loss:0.11832 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1777 Loss:0.13020 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1778 Loss:0.11947 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1779 Loss:0.13199 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1780 Loss:0.11907 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1781 Loss:0.12741 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1782 Loss:0.12217 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1783 Loss:0.11938 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1784 Loss:0.13424 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1785 Loss:0.12405 (Coord:0.02 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1786 Loss:0.12913 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1787 Loss:0.12758 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1788 Loss:0.11842 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1789 Loss:0.13957 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1790 Loss:0.11514 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1791 Loss:0.11795 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1792 Loss:0.12016 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1793 Loss:0.12385 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1794 Loss:0.14009 (Coord:0.03 Conf:0.09 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1795 Loss:0.12374 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1796 Loss:0.12350 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1797 Loss:0.12841 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1798 Loss:0.12390 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1799 Loss:0.12411 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1800 Loss:0.12251 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1801 Loss:0.11788 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1802 Loss:0.13297 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1803 Loss:0.12226 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1804 Loss:0.11675 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1805 Loss:0.12377 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1806 Loss:0.12329 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1807 Loss:0.11552 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1808 Loss:0.11592 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1809 Loss:0.12716 (Coord:0.03 Conf:0.08 Cls:0.02)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1810 Loss:0.12748 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1811 Loss:0.11374 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1812 Loss:0.12241 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1813 Loss:0.12657 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1814 Loss:0.11634 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1815 Loss:0.12740 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1816 Loss:0.13176 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1817 Loss:0.11641 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1818 Loss:0.12432 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1819 Loss:0.11883 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1820 Loss:0.12628 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1821 Loss:0.11976 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1822 Loss:0.11823 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1823 Loss:0.12209 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1824 Loss:0.12523 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1825 Loss:0.12200 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1826 Loss:0.12702 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1827 Loss:0.13304 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1828 Loss:0.11264 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1829 Loss:0.11818 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1830 Loss:0.13768 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1831 Loss:0.12076 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1832 Loss:0.12445 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1833 Loss:0.11491 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1834 Loss:0.12247 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1835 Loss:0.12044 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1836 Loss:0.11848 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1837 Loss:0.11982 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1838 Loss:0.12763 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1839 Loss:0.11679 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1840 Loss:0.11709 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1841 Loss:0.11903 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1842 Loss:0.12374 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1843 Loss:0.11912 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1844 Loss:0.11231 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1845 Loss:0.12028 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1846 Loss:0.13658 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1847 Loss:0.11733 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1848 Loss:0.12237 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1849 Loss:0.10924 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1850 Loss:0.13317 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1851 Loss:0.12303 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1852 Loss:0.11206 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1853 Loss:0.12709 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1854 Loss:0.11661 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1855 Loss:0.12589 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1856 Loss:0.12070 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1857 Loss:0.12062 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1858 Loss:0.12610 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1859 Loss:0.11108 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1860 Loss:0.14130 (Coord:0.04 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1861 Loss:0.11628 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1862 Loss:0.11480 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1863 Loss:0.11394 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1864 Loss:0.12038 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1865 Loss:0.12755 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1866 Loss:0.11350 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1867 Loss:0.11288 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1868 Loss:0.12271 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1869 Loss:0.12205 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1870 Loss:0.12165 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1871 Loss:0.11625 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1872 Loss:0.13406 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1873 Loss:0.11786 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1874 Loss:0.11644 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1875 Loss:0.11955 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1876 Loss:0.11874 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1877 Loss:0.12454 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1878 Loss:0.11972 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1879 Loss:0.11826 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1880 Loss:0.12786 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1881 Loss:0.11957 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1882 Loss:0.12721 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1883 Loss:0.11186 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1884 Loss:0.11858 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1885 Loss:0.12233 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1886 Loss:0.11670 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1887 Loss:0.12203 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1888 Loss:0.13317 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1889 Loss:0.11792 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1890 Loss:0.11822 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1891 Loss:0.11672 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1892 Loss:0.11165 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1893 Loss:0.11419 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1894 Loss:0.12643 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1895 Loss:0.11652 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1896 Loss:0.12195 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1897 Loss:0.11631 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1898 Loss:0.11651 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1899 Loss:0.11544 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1900 Loss:0.12611 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1901 Loss:0.11878 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1902 Loss:0.11182 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1903 Loss:0.13586 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1904 Loss:0.12234 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1905 Loss:0.11760 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1906 Loss:0.12088 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1907 Loss:0.12235 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1908 Loss:0.12679 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1909 Loss:0.11600 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1910 Loss:0.11547 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1911 Loss:0.11527 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1912 Loss:0.11944 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1913 Loss:0.11208 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1914 Loss:0.11231 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1915 Loss:0.12370 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1916 Loss:0.11439 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1917 Loss:0.11713 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1918 Loss:0.12286 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1919 Loss:0.11531 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1920 Loss:0.11718 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1921 Loss:0.11569 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1922 Loss:0.12030 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1923 Loss:0.11690 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1924 Loss:0.13051 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1925 Loss:0.11422 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1926 Loss:0.11046 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1927 Loss:0.13301 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1928 Loss:0.11716 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1929 Loss:0.11070 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1930 Loss:0.13925 (Coord:0.04 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1931 Loss:0.12016 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1932 Loss:0.12044 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1933 Loss:0.11592 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1934 Loss:0.11449 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1935 Loss:0.11699 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1936 Loss:0.11535 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1937 Loss:0.11590 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1938 Loss:0.11609 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1939 Loss:0.11596 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1940 Loss:0.11602 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1941 Loss:0.11353 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1942 Loss:0.12929 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1943 Loss:0.11743 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1944 Loss:0.12382 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1945 Loss:0.10828 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1946 Loss:0.10848 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1947 Loss:0.11783 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1948 Loss:0.12840 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1949 Loss:0.10656 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1950 Loss:0.11638 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1951 Loss:0.12961 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1952 Loss:0.10567 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1953 Loss:0.11624 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1954 Loss:0.11961 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1955 Loss:0.11583 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1956 Loss:0.12156 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1957 Loss:0.11797 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1958 Loss:0.11527 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1959 Loss:0.12496 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1960 Loss:0.11395 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1961 Loss:0.11685 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1962 Loss:0.11675 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1963 Loss:0.11907 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1964 Loss:0.11478 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1965 Loss:0.11597 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1966 Loss:0.11458 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1967 Loss:0.12777 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1968 Loss:0.11479 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1969 Loss:0.11336 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1970 Loss:0.13671 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1971 Loss:0.11140 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1972 Loss:0.11684 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1973 Loss:0.11730 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1974 Loss:0.11063 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1975 Loss:0.11914 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1976 Loss:0.11733 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1977 Loss:0.11577 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1978 Loss:0.11275 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1979 Loss:0.12797 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1980 Loss:0.12242 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1981 Loss:0.11279 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1982 Loss:0.10894 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1983 Loss:0.11192 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1984 Loss:0.11955 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1985 Loss:0.12653 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1986 Loss:0.13028 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1987 Loss:0.10544 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1988 Loss:0.11594 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1989 Loss:0.11326 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1990 Loss:0.11648 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1991 Loss:0.11006 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1992 Loss:0.11514 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1993 Loss:0.11210 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1994 Loss:0.11485 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1995 Loss:0.11444 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1996 Loss:0.11412 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1997 Loss:0.11858 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1998 Loss:0.11432 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 1999 Loss:0.11257 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2000 Loss:0.11438 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Saved backup\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2001 Loss:0.11492 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2002 Loss:0.11579 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2003 Loss:0.11279 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2004 Loss:0.11655 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2005 Loss:0.11143 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2006 Loss:0.12040 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2007 Loss:0.11859 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2008 Loss:0.11751 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2009 Loss:0.11330 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2010 Loss:0.10766 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2011 Loss:0.11564 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2012 Loss:0.10952 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2013 Loss:0.12327 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2014 Loss:0.11175 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2015 Loss:0.12086 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2016 Loss:0.12410 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2017 Loss:0.10510 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2018 Loss:0.11723 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2019 Loss:0.11233 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2020 Loss:0.12241 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2021 Loss:0.11163 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2022 Loss:0.10941 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2023 Loss:0.11594 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2024 Loss:0.11811 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2025 Loss:0.11578 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2026 Loss:0.11792 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2027 Loss:0.11857 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2028 Loss:0.10894 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2029 Loss:0.11964 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2030 Loss:0.11347 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2031 Loss:0.11149 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2032 Loss:0.11503 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2033 Loss:0.11626 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2034 Loss:0.11330 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2035 Loss:0.10799 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2036 Loss:0.11601 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2037 Loss:0.12045 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2038 Loss:0.10938 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2039 Loss:0.10971 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2040 Loss:0.11504 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2041 Loss:0.11274 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2042 Loss:0.11153 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2043 Loss:0.10754 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2044 Loss:0.11896 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2045 Loss:0.11054 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2046 Loss:0.11004 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2047 Loss:0.11191 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2048 Loss:0.11346 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2049 Loss:0.10703 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2050 Loss:0.11787 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2051 Loss:0.10737 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2052 Loss:0.12095 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2053 Loss:0.11158 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2054 Loss:0.10790 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2055 Loss:0.12093 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2056 Loss:0.10998 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2057 Loss:0.10850 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2058 Loss:0.11861 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2059 Loss:0.10971 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2060 Loss:0.10809 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2061 Loss:0.10990 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2062 Loss:0.12841 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2063 Loss:0.10832 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2064 Loss:0.11762 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2065 Loss:0.11208 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2066 Loss:0.11391 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2067 Loss:0.11629 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2068 Loss:0.10948 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2069 Loss:0.11946 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2070 Loss:0.11506 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2071 Loss:0.10878 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2072 Loss:0.11389 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2073 Loss:0.11793 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2074 Loss:0.11289 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2075 Loss:0.11213 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2076 Loss:0.11159 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2077 Loss:0.11268 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2078 Loss:0.10717 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2079 Loss:0.11300 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2080 Loss:0.11219 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2081 Loss:0.11294 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2082 Loss:0.10858 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2083 Loss:0.11811 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2084 Loss:0.11245 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2085 Loss:0.12274 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2086 Loss:0.11038 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2087 Loss:0.10669 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2088 Loss:0.11251 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2089 Loss:0.10573 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2090 Loss:0.12558 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2091 Loss:0.10422 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2092 Loss:0.11013 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2093 Loss:0.11336 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2094 Loss:0.10662 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2095 Loss:0.11106 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2096 Loss:0.11563 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2097 Loss:0.11147 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2098 Loss:0.12195 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2099 Loss:0.10199 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2100 Loss:0.11467 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2101 Loss:0.11623 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2102 Loss:0.10915 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2103 Loss:0.10933 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2104 Loss:0.10097 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2105 Loss:0.10660 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2106 Loss:0.11923 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2107 Loss:0.09979 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2108 Loss:0.11015 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2109 Loss:0.12809 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2110 Loss:0.11079 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2111 Loss:0.11523 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2112 Loss:0.11682 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2113 Loss:0.11422 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2114 Loss:0.11478 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2115 Loss:0.11388 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2116 Loss:0.10563 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2117 Loss:0.11303 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2118 Loss:0.10664 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2119 Loss:0.11085 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2120 Loss:0.10852 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2121 Loss:0.10919 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2122 Loss:0.10793 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2123 Loss:0.10313 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2124 Loss:0.11170 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2125 Loss:0.11038 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2126 Loss:0.11469 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2127 Loss:0.11103 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2128 Loss:0.10016 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2129 Loss:0.10984 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2130 Loss:0.11311 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2131 Loss:0.10656 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2132 Loss:0.11155 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2133 Loss:0.12905 (Coord:0.03 Conf:0.09 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2134 Loss:0.10065 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2135 Loss:0.10286 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2136 Loss:0.11489 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2137 Loss:0.11095 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2138 Loss:0.10609 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2139 Loss:0.11391 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2140 Loss:0.11594 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2141 Loss:0.10368 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2142 Loss:0.10402 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2143 Loss:0.11057 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2144 Loss:0.11779 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2145 Loss:0.11223 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2146 Loss:0.11718 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2147 Loss:0.10429 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2148 Loss:0.10892 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2149 Loss:0.11211 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2150 Loss:0.10528 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2151 Loss:0.11264 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2152 Loss:0.10784 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2153 Loss:0.12329 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2154 Loss:0.11165 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2155 Loss:0.10882 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2156 Loss:0.10821 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2157 Loss:0.10716 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2158 Loss:0.10502 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2159 Loss:0.11016 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2160 Loss:0.10792 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2161 Loss:0.11322 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2162 Loss:0.10550 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2163 Loss:0.11517 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2164 Loss:0.10113 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2165 Loss:0.11224 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2166 Loss:0.11118 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2167 Loss:0.11774 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2168 Loss:0.10205 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2169 Loss:0.10635 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2170 Loss:0.10736 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2171 Loss:0.10022 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2172 Loss:0.12598 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2173 Loss:0.11187 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2174 Loss:0.11123 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2175 Loss:0.10179 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2176 Loss:0.10902 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2177 Loss:0.10674 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2178 Loss:0.10844 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2179 Loss:0.11040 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2180 Loss:0.11694 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2181 Loss:0.10085 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2182 Loss:0.10377 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2183 Loss:0.11184 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2184 Loss:0.10657 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2185 Loss:0.10082 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2186 Loss:0.12079 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2187 Loss:0.10606 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2188 Loss:0.10794 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2189 Loss:0.10815 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2190 Loss:0.10189 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2191 Loss:0.10554 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2192 Loss:0.10738 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2193 Loss:0.10312 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2194 Loss:0.10438 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2195 Loss:0.11023 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2196 Loss:0.11366 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2197 Loss:0.10434 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2198 Loss:0.10173 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2199 Loss:0.11080 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2200 Loss:0.10623 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2201 Loss:0.11167 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2202 Loss:0.10928 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2203 Loss:0.11526 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2204 Loss:0.10903 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2205 Loss:0.10585 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2206 Loss:0.10468 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2207 Loss:0.11144 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2208 Loss:0.11958 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2209 Loss:0.10104 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2210 Loss:0.10399 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2211 Loss:0.11344 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2212 Loss:0.10466 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2213 Loss:0.10683 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2214 Loss:0.10185 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2215 Loss:0.11081 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2216 Loss:0.10596 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2217 Loss:0.12460 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2218 Loss:0.11063 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2219 Loss:0.10046 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2220 Loss:0.11796 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2221 Loss:0.10067 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2222 Loss:0.11514 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2223 Loss:0.11182 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2224 Loss:0.10283 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2225 Loss:0.11421 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2226 Loss:0.10661 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2227 Loss:0.11237 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2228 Loss:0.10434 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2229 Loss:0.10582 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2230 Loss:0.10772 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2231 Loss:0.10101 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2232 Loss:0.11269 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2233 Loss:0.10746 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2234 Loss:0.10288 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2235 Loss:0.10883 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2236 Loss:0.10102 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2237 Loss:0.10793 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2238 Loss:0.10000 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2239 Loss:0.10776 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2240 Loss:0.10409 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2241 Loss:0.11258 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2242 Loss:0.09980 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2243 Loss:0.10828 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2244 Loss:0.11179 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2245 Loss:0.10852 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2246 Loss:0.10489 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2247 Loss:0.10741 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2248 Loss:0.10344 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2249 Loss:0.10432 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2250 Loss:0.12453 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2251 Loss:0.09755 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2252 Loss:0.10575 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2253 Loss:0.11518 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2254 Loss:0.10020 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2255 Loss:0.11488 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2256 Loss:0.10886 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2257 Loss:0.10164 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2258 Loss:0.11042 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2259 Loss:0.11154 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2260 Loss:0.09945 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2261 Loss:0.10875 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2262 Loss:0.11392 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2263 Loss:0.10668 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2264 Loss:0.10003 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2265 Loss:0.10108 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2266 Loss:0.11612 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2267 Loss:0.10179 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2268 Loss:0.11486 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2269 Loss:0.10327 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2270 Loss:0.12892 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2271 Loss:0.10631 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2272 Loss:0.09811 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2273 Loss:0.10325 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2274 Loss:0.10555 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2275 Loss:0.10610 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2276 Loss:0.09980 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2277 Loss:0.10329 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2278 Loss:0.12191 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2279 Loss:0.10537 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2280 Loss:0.09982 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2281 Loss:0.10820 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2282 Loss:0.10643 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2283 Loss:0.09415 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2284 Loss:0.11277 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2285 Loss:0.10487 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2286 Loss:0.11676 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2287 Loss:0.10014 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2288 Loss:0.10404 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2289 Loss:0.11063 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2290 Loss:0.11220 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2291 Loss:0.10233 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2292 Loss:0.10610 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2293 Loss:0.10339 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2294 Loss:0.09716 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2295 Loss:0.10516 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2296 Loss:0.10618 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2297 Loss:0.11331 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2298 Loss:0.10369 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2299 Loss:0.10548 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2300 Loss:0.11937 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2301 Loss:0.10476 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2302 Loss:0.10627 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2303 Loss:0.10863 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2304 Loss:0.10312 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2305 Loss:0.10852 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2306 Loss:0.10067 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2307 Loss:0.10141 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2308 Loss:0.11158 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2309 Loss:0.10717 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2310 Loss:0.09861 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2311 Loss:0.10406 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2312 Loss:0.10790 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2313 Loss:0.09773 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2314 Loss:0.10767 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2315 Loss:0.10674 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2316 Loss:0.10191 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2317 Loss:0.10569 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2318 Loss:0.09988 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2319 Loss:0.10216 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2320 Loss:0.11197 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2321 Loss:0.10823 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2322 Loss:0.10337 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2323 Loss:0.10084 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2324 Loss:0.10587 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2325 Loss:0.10974 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2326 Loss:0.09887 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2327 Loss:0.11067 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2328 Loss:0.10195 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2329 Loss:0.10016 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2330 Loss:0.10187 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2331 Loss:0.11410 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2332 Loss:0.10289 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2333 Loss:0.10704 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2334 Loss:0.11117 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2335 Loss:0.10592 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2336 Loss:0.10870 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2337 Loss:0.09765 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2338 Loss:0.10824 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2339 Loss:0.10318 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2340 Loss:0.11045 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2341 Loss:0.10008 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2342 Loss:0.11036 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2343 Loss:0.10162 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2344 Loss:0.10955 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2345 Loss:0.10107 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2346 Loss:0.11107 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2347 Loss:0.10303 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2348 Loss:0.10320 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2349 Loss:0.10110 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2350 Loss:0.10890 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2351 Loss:0.09658 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2352 Loss:0.11254 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2353 Loss:0.10121 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2354 Loss:0.09916 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2355 Loss:0.11016 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2356 Loss:0.10279 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2357 Loss:0.11166 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2358 Loss:0.10067 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2359 Loss:0.10433 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2360 Loss:0.10652 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2361 Loss:0.10330 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2362 Loss:0.10648 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2363 Loss:0.09900 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2364 Loss:0.10802 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2365 Loss:0.10148 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2366 Loss:0.10316 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2367 Loss:0.10266 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2368 Loss:0.09787 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2369 Loss:0.10744 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2370 Loss:0.09724 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2371 Loss:0.11292 (Coord:0.02 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2372 Loss:0.11207 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2373 Loss:0.10284 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2374 Loss:0.09931 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2375 Loss:0.10332 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2376 Loss:0.09983 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2377 Loss:0.11163 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2378 Loss:0.09934 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2379 Loss:0.10085 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2380 Loss:0.10708 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2381 Loss:0.09626 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2382 Loss:0.10284 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2383 Loss:0.10825 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2384 Loss:0.10480 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2385 Loss:0.09741 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2386 Loss:0.09710 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2387 Loss:0.10765 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2388 Loss:0.09937 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2389 Loss:0.10255 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2390 Loss:0.10530 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2391 Loss:0.10204 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2392 Loss:0.10208 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2393 Loss:0.10536 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2394 Loss:0.10359 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2395 Loss:0.10462 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2396 Loss:0.10444 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2397 Loss:0.09910 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2398 Loss:0.09646 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2399 Loss:0.10708 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2400 Loss:0.10418 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2401 Loss:0.10391 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2402 Loss:0.11342 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2403 Loss:0.09785 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2404 Loss:0.11655 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2405 Loss:0.09930 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2406 Loss:0.10080 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2407 Loss:0.09954 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2408 Loss:0.10434 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2409 Loss:0.10556 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2410 Loss:0.10131 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2411 Loss:0.10127 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2412 Loss:0.09770 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2413 Loss:0.09992 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2414 Loss:0.11449 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2415 Loss:0.09921 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2416 Loss:0.10148 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2417 Loss:0.10949 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2418 Loss:0.09590 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2419 Loss:0.10263 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2420 Loss:0.09908 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2421 Loss:0.09755 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2422 Loss:0.10281 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2423 Loss:0.10806 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2424 Loss:0.09862 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2425 Loss:0.09763 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2426 Loss:0.10625 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2427 Loss:0.10451 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2428 Loss:0.09610 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2429 Loss:0.09766 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2430 Loss:0.09949 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2431 Loss:0.09945 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2432 Loss:0.10212 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2433 Loss:0.10136 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2434 Loss:0.10100 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2435 Loss:0.10585 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2436 Loss:0.09872 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2437 Loss:0.10374 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2438 Loss:0.10503 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2439 Loss:0.09978 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2440 Loss:0.09444 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2441 Loss:0.11090 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2442 Loss:0.09463 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2443 Loss:0.10456 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2444 Loss:0.10389 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2445 Loss:0.09471 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2446 Loss:0.10365 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2447 Loss:0.09978 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2448 Loss:0.10910 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2449 Loss:0.10318 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2450 Loss:0.09581 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2451 Loss:0.10189 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2452 Loss:0.09792 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2453 Loss:0.10507 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2454 Loss:0.10310 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2455 Loss:0.10876 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2456 Loss:0.09935 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2457 Loss:0.09832 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2458 Loss:0.10716 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2459 Loss:0.09534 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2460 Loss:0.09565 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2461 Loss:0.10190 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2462 Loss:0.11743 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2463 Loss:0.10020 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2464 Loss:0.09719 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2465 Loss:0.10034 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2466 Loss:0.10028 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2467 Loss:0.09936 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2468 Loss:0.10018 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2469 Loss:0.09653 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2470 Loss:0.09915 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2471 Loss:0.10445 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2472 Loss:0.10327 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2473 Loss:0.09802 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2474 Loss:0.10215 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2475 Loss:0.10129 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2476 Loss:0.10127 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2477 Loss:0.09632 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2478 Loss:0.10433 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2479 Loss:0.10101 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2480 Loss:0.09863 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2481 Loss:0.09689 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2482 Loss:0.10012 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2483 Loss:0.10028 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2484 Loss:0.10760 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2485 Loss:0.09590 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2486 Loss:0.09532 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2487 Loss:0.11414 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2488 Loss:0.09441 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2489 Loss:0.10744 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2490 Loss:0.09760 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2491 Loss:0.09434 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2492 Loss:0.10523 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2493 Loss:0.10213 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2494 Loss:0.10887 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2495 Loss:0.09577 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2496 Loss:0.10037 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2497 Loss:0.09617 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2498 Loss:0.10150 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2499 Loss:0.10072 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2500 Loss:0.09643 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Saved backup\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2501 Loss:0.09812 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2502 Loss:0.10022 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2503 Loss:0.10773 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2504 Loss:0.09580 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2505 Loss:0.11421 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2506 Loss:0.09067 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2507 Loss:0.09680 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2508 Loss:0.10101 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2509 Loss:0.09450 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2510 Loss:0.11790 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2511 Loss:0.10761 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2512 Loss:0.09190 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2513 Loss:0.10403 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2514 Loss:0.09616 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2515 Loss:0.11694 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2516 Loss:0.09176 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2517 Loss:0.10676 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2518 Loss:0.09383 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2519 Loss:0.09789 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2520 Loss:0.09178 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2521 Loss:0.10782 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2522 Loss:0.09645 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2523 Loss:0.10091 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2524 Loss:0.10797 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2525 Loss:0.09428 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2526 Loss:0.09532 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2527 Loss:0.10250 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2528 Loss:0.09923 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2529 Loss:0.10243 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2530 Loss:0.09642 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2531 Loss:0.09904 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2532 Loss:0.09469 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2533 Loss:0.10124 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2534 Loss:0.09524 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2535 Loss:0.10158 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2536 Loss:0.09757 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2537 Loss:0.09542 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2538 Loss:0.09937 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2539 Loss:0.09584 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2540 Loss:0.10272 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2541 Loss:0.09300 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2542 Loss:0.09725 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2543 Loss:0.09821 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2544 Loss:0.10501 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2545 Loss:0.09595 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2546 Loss:0.09875 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2547 Loss:0.11281 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2548 Loss:0.09573 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2549 Loss:0.09685 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2550 Loss:0.09802 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2551 Loss:0.10100 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2552 Loss:0.10565 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2553 Loss:0.09985 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2554 Loss:0.09078 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2555 Loss:0.09485 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2556 Loss:0.10876 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2557 Loss:0.10441 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2558 Loss:0.11141 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2559 Loss:0.09948 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2560 Loss:0.09292 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2561 Loss:0.09566 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2562 Loss:0.09892 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2563 Loss:0.09175 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2564 Loss:0.10305 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2565 Loss:0.10377 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2566 Loss:0.10151 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2567 Loss:0.09839 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2568 Loss:0.10118 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2569 Loss:0.09722 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2570 Loss:0.09454 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2571 Loss:0.09891 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2572 Loss:0.11494 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2573 Loss:0.09875 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2574 Loss:0.09923 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2575 Loss:0.09819 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2576 Loss:0.09626 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2577 Loss:0.10377 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2578 Loss:0.09201 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2579 Loss:0.09322 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2580 Loss:0.10273 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2581 Loss:0.09484 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2582 Loss:0.09237 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2583 Loss:0.09981 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2584 Loss:0.09758 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2585 Loss:0.09665 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2586 Loss:0.09661 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2587 Loss:0.10667 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2588 Loss:0.09547 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2589 Loss:0.09579 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2590 Loss:0.10600 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2591 Loss:0.09679 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2592 Loss:0.09602 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2593 Loss:0.09733 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2594 Loss:0.09444 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2595 Loss:0.09879 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2596 Loss:0.10009 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2597 Loss:0.09875 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2598 Loss:0.09910 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2599 Loss:0.09598 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2600 Loss:0.09296 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2601 Loss:0.10361 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2602 Loss:0.09782 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2603 Loss:0.09404 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2604 Loss:0.09700 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2605 Loss:0.09603 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2606 Loss:0.09948 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2607 Loss:0.09233 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2608 Loss:0.10630 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2609 Loss:0.10065 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2610 Loss:0.09715 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2611 Loss:0.10071 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2612 Loss:0.09778 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2613 Loss:0.08996 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2614 Loss:0.09560 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2615 Loss:0.09298 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2616 Loss:0.10239 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2617 Loss:0.09444 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2618 Loss:0.10319 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2619 Loss:0.09579 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2620 Loss:0.10044 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2621 Loss:0.09257 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2622 Loss:0.09918 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2623 Loss:0.10324 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2624 Loss:0.09521 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2625 Loss:0.09972 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2626 Loss:0.09489 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2627 Loss:0.09793 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2628 Loss:0.09759 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2629 Loss:0.09847 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2630 Loss:0.09248 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2631 Loss:0.10004 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2632 Loss:0.09055 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2633 Loss:0.09591 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2634 Loss:0.09758 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2635 Loss:0.10133 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2636 Loss:0.09180 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2637 Loss:0.09538 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2638 Loss:0.11321 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2639 Loss:0.09350 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2640 Loss:0.09874 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2641 Loss:0.08911 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2642 Loss:0.09940 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2643 Loss:0.10696 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2644 Loss:0.09867 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2645 Loss:0.09075 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2646 Loss:0.09613 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2647 Loss:0.09894 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2648 Loss:0.09629 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2649 Loss:0.09838 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2650 Loss:0.09256 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2651 Loss:0.09350 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2652 Loss:0.09642 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2653 Loss:0.10910 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2654 Loss:0.09208 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2655 Loss:0.10102 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2656 Loss:0.09811 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2657 Loss:0.09448 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2658 Loss:0.09605 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2659 Loss:0.10001 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2660 Loss:0.09161 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2661 Loss:0.10105 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2662 Loss:0.09702 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2663 Loss:0.09527 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2664 Loss:0.09119 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2665 Loss:0.10090 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2666 Loss:0.09650 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2667 Loss:0.09719 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2668 Loss:0.09131 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2669 Loss:0.09221 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2670 Loss:0.09291 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2671 Loss:0.10404 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2672 Loss:0.09363 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2673 Loss:0.10025 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2674 Loss:0.09732 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2675 Loss:0.09781 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2676 Loss:0.09576 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2677 Loss:0.09441 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2678 Loss:0.10212 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2679 Loss:0.09236 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2680 Loss:0.09976 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2681 Loss:0.09416 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2682 Loss:0.09319 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2683 Loss:0.09403 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2684 Loss:0.09385 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2685 Loss:0.09339 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2686 Loss:0.08809 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2687 Loss:0.10514 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2688 Loss:0.10228 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2689 Loss:0.09600 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2690 Loss:0.09517 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2691 Loss:0.09756 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2692 Loss:0.10900 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2693 Loss:0.09743 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2694 Loss:0.08438 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2695 Loss:0.09765 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2696 Loss:0.10996 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2697 Loss:0.08912 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2698 Loss:0.09775 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2699 Loss:0.09037 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2700 Loss:0.10884 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2701 Loss:0.09708 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2702 Loss:0.08976 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2703 Loss:0.10092 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2704 Loss:0.08970 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2705 Loss:0.09579 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2706 Loss:0.09251 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2707 Loss:0.09796 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2708 Loss:0.08478 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2709 Loss:0.11221 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2710 Loss:0.09256 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2711 Loss:0.10562 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2712 Loss:0.08926 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2713 Loss:0.09712 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2714 Loss:0.09745 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2715 Loss:0.08892 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2716 Loss:0.09805 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2717 Loss:0.10045 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2718 Loss:0.09139 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2719 Loss:0.09942 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2720 Loss:0.09028 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2721 Loss:0.09955 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2722 Loss:0.09247 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2723 Loss:0.09511 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2724 Loss:0.09323 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2725 Loss:0.09634 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2726 Loss:0.09817 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2727 Loss:0.09278 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2728 Loss:0.10130 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2729 Loss:0.09859 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2730 Loss:0.09243 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2731 Loss:0.09970 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2732 Loss:0.09217 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2733 Loss:0.10280 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2734 Loss:0.08772 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2735 Loss:0.09064 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2736 Loss:0.08930 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2737 Loss:0.09620 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2738 Loss:0.09306 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2739 Loss:0.09610 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2740 Loss:0.09737 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2741 Loss:0.08896 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2742 Loss:0.08938 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2743 Loss:0.09855 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2744 Loss:0.09635 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2745 Loss:0.10426 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2746 Loss:0.09512 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2747 Loss:0.09431 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2748 Loss:0.09133 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2749 Loss:0.09753 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2750 Loss:0.09521 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2751 Loss:0.09169 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2752 Loss:0.09990 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2753 Loss:0.09161 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2754 Loss:0.08462 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2755 Loss:0.08984 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2756 Loss:0.09686 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2757 Loss:0.09100 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2758 Loss:0.09131 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2759 Loss:0.09691 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2760 Loss:0.09264 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2761 Loss:0.09757 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2762 Loss:0.09340 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2763 Loss:0.09639 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2764 Loss:0.10315 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2765 Loss:0.09690 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2766 Loss:0.08934 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2767 Loss:0.09458 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2768 Loss:0.09971 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2769 Loss:0.11785 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2770 Loss:0.09513 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2771 Loss:0.09174 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2772 Loss:0.09205 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2773 Loss:0.08872 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2774 Loss:0.10428 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2775 Loss:0.09115 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2776 Loss:0.09267 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2777 Loss:0.10129 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2778 Loss:0.08850 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2779 Loss:0.09670 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2780 Loss:0.09094 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2781 Loss:0.10162 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2782 Loss:0.09012 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2783 Loss:0.09330 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2784 Loss:0.08760 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2785 Loss:0.09514 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2786 Loss:0.08657 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2787 Loss:0.09130 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2788 Loss:0.10588 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2789 Loss:0.09780 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2790 Loss:0.09554 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2791 Loss:0.08845 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2792 Loss:0.09285 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2793 Loss:0.09277 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2794 Loss:0.09004 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2795 Loss:0.08639 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2796 Loss:0.09595 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2797 Loss:0.09560 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2798 Loss:0.09438 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2799 Loss:0.09088 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2800 Loss:0.09703 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2801 Loss:0.09251 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2802 Loss:0.10073 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2803 Loss:0.09426 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2804 Loss:0.08733 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2805 Loss:0.08925 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2806 Loss:0.11573 (Coord:0.03 Conf:0.08 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2807 Loss:0.08966 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2808 Loss:0.09217 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2809 Loss:0.08993 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2810 Loss:0.09545 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2811 Loss:0.09777 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2812 Loss:0.10545 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2813 Loss:0.09406 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2814 Loss:0.09087 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2815 Loss:0.09135 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2816 Loss:0.08945 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2817 Loss:0.09067 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2818 Loss:0.09524 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2819 Loss:0.09105 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2820 Loss:0.08644 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2821 Loss:0.09468 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2822 Loss:0.09353 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2823 Loss:0.09651 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2824 Loss:0.09267 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2825 Loss:0.08910 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2826 Loss:0.09172 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2827 Loss:0.09110 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2828 Loss:0.09979 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2829 Loss:0.09047 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2830 Loss:0.09686 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2831 Loss:0.09170 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2832 Loss:0.09429 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2833 Loss:0.10511 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2834 Loss:0.09150 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2835 Loss:0.08932 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2836 Loss:0.08613 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2837 Loss:0.09549 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2838 Loss:0.09439 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2839 Loss:0.09872 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2840 Loss:0.08971 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2841 Loss:0.09306 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2842 Loss:0.09563 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2843 Loss:0.08839 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2844 Loss:0.09281 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2845 Loss:0.09273 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2846 Loss:0.09150 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2847 Loss:0.08767 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2848 Loss:0.10313 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2849 Loss:0.08803 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2850 Loss:0.09251 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2851 Loss:0.09205 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2852 Loss:0.08969 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2853 Loss:0.09114 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2854 Loss:0.08864 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2855 Loss:0.09562 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2856 Loss:0.09056 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2857 Loss:0.09118 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2858 Loss:0.08830 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2859 Loss:0.09977 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2860 Loss:0.09307 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2861 Loss:0.09198 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2862 Loss:0.09149 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2863 Loss:0.09527 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2864 Loss:0.08158 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2865 Loss:0.09586 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2866 Loss:0.10443 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2867 Loss:0.09401 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2868 Loss:0.08923 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2869 Loss:0.10040 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2870 Loss:0.11203 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2871 Loss:0.10135 (Coord:0.03 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2872 Loss:0.09281 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2873 Loss:0.09278 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2874 Loss:0.09529 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2875 Loss:0.09022 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2876 Loss:0.09699 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2877 Loss:0.09103 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2878 Loss:0.09152 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2879 Loss:0.08641 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2880 Loss:0.08464 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2881 Loss:0.10261 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2882 Loss:0.09906 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2883 Loss:0.09029 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2884 Loss:0.08622 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2885 Loss:0.10168 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2886 Loss:0.09243 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2887 Loss:0.08622 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2888 Loss:0.08909 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2889 Loss:0.09349 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2890 Loss:0.09485 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2891 Loss:0.08733 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2892 Loss:0.09395 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2893 Loss:0.09397 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2894 Loss:0.08533 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2895 Loss:0.09767 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2896 Loss:0.08594 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2897 Loss:0.09099 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2898 Loss:0.08916 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2899 Loss:0.10040 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2900 Loss:0.09388 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2901 Loss:0.08789 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2902 Loss:0.09365 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2903 Loss:0.09041 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2904 Loss:0.08341 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2905 Loss:0.10118 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2906 Loss:0.08751 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2907 Loss:0.09698 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2908 Loss:0.08845 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2909 Loss:0.09237 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2910 Loss:0.08853 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2911 Loss:0.09082 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2912 Loss:0.09286 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2913 Loss:0.08999 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2914 Loss:0.09003 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2915 Loss:0.09189 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2916 Loss:0.09644 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2917 Loss:0.09000 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2918 Loss:0.09282 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2919 Loss:0.10503 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2920 Loss:0.09090 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2921 Loss:0.08375 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2922 Loss:0.09065 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2923 Loss:0.08606 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2924 Loss:0.09689 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2925 Loss:0.09248 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2926 Loss:0.09393 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2927 Loss:0.08660 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2928 Loss:0.09436 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2929 Loss:0.09031 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2930 Loss:0.08765 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2931 Loss:0.09029 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2932 Loss:0.08792 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2933 Loss:0.09568 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2934 Loss:0.09280 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2935 Loss:0.08717 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2936 Loss:0.08839 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2937 Loss:0.09635 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2938 Loss:0.09177 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2939 Loss:0.09221 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2940 Loss:0.08481 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2941 Loss:0.08729 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2942 Loss:0.09675 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2943 Loss:0.08757 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2944 Loss:0.09426 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2945 Loss:0.09136 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2946 Loss:0.09169 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2947 Loss:0.08933 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2948 Loss:0.10104 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2949 Loss:0.09444 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2950 Loss:0.08951 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2951 Loss:0.09054 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2952 Loss:0.09585 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2953 Loss:0.08906 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2954 Loss:0.08422 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2955 Loss:0.08690 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2956 Loss:0.09254 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2957 Loss:0.08268 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2958 Loss:0.09237 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2959 Loss:0.09685 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2960 Loss:0.09467 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2961 Loss:0.08604 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2962 Loss:0.09181 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2963 Loss:0.08641 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2964 Loss:0.08464 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2965 Loss:0.08847 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2966 Loss:0.10249 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2967 Loss:0.08632 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2968 Loss:0.10261 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2969 Loss:0.08537 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2970 Loss:0.09146 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2971 Loss:0.09393 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2972 Loss:0.08943 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2973 Loss:0.08786 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2974 Loss:0.08869 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2975 Loss:0.09145 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2976 Loss:0.09373 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2977 Loss:0.08784 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2978 Loss:0.09180 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2979 Loss:0.10381 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2980 Loss:0.08949 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2981 Loss:0.08249 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2982 Loss:0.08705 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2983 Loss:0.08644 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2984 Loss:0.10791 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2985 Loss:0.09198 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2986 Loss:0.09573 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2987 Loss:0.08947 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2988 Loss:0.08880 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2989 Loss:0.09911 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2990 Loss:0.08564 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2991 Loss:0.09788 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2992 Loss:0.08736 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2993 Loss:0.08667 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2994 Loss:0.08526 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2995 Loss:0.08963 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2996 Loss:0.09066 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2997 Loss:0.09052 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2998 Loss:0.09962 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 2999 Loss:0.08150 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3000 Loss:0.09637 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Saved backup\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3001 Loss:0.09609 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3002 Loss:0.08461 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3003 Loss:0.09954 (Coord:0.03 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3004 Loss:0.09006 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3005 Loss:0.09542 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3006 Loss:0.08556 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3007 Loss:0.09313 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3008 Loss:0.08344 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3009 Loss:0.09580 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3010 Loss:0.08459 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3011 Loss:0.09579 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3012 Loss:0.09539 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3013 Loss:0.08601 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3014 Loss:0.08442 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3015 Loss:0.08324 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3016 Loss:0.09706 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3017 Loss:0.09073 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3018 Loss:0.09069 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3019 Loss:0.08960 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3020 Loss:0.09164 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3021 Loss:0.08716 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3022 Loss:0.08815 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3023 Loss:0.08945 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3024 Loss:0.08948 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3025 Loss:0.08694 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3026 Loss:0.08740 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3027 Loss:0.08810 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3028 Loss:0.09650 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3029 Loss:0.08987 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3030 Loss:0.09106 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3031 Loss:0.08912 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3032 Loss:0.09404 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3033 Loss:0.09076 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3034 Loss:0.08178 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3035 Loss:0.08653 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3036 Loss:0.08661 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3037 Loss:0.08898 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3038 Loss:0.09548 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3039 Loss:0.08338 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3040 Loss:0.10039 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3041 Loss:0.08934 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3042 Loss:0.08760 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3043 Loss:0.08542 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3044 Loss:0.09115 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3045 Loss:0.08713 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3046 Loss:0.09021 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3047 Loss:0.08714 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3048 Loss:0.09224 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3049 Loss:0.09055 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3050 Loss:0.08427 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3051 Loss:0.09822 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3052 Loss:0.09121 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3053 Loss:0.08381 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3054 Loss:0.09872 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3055 Loss:0.09221 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3056 Loss:0.08637 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3057 Loss:0.08418 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3058 Loss:0.08855 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3059 Loss:0.08386 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3060 Loss:0.09072 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3061 Loss:0.09196 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3062 Loss:0.08220 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3063 Loss:0.09505 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3064 Loss:0.09365 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3065 Loss:0.08593 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3066 Loss:0.08877 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3067 Loss:0.08695 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3068 Loss:0.08552 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3069 Loss:0.08880 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3070 Loss:0.10239 (Coord:0.03 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3071 Loss:0.08934 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3072 Loss:0.08946 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3073 Loss:0.09274 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3074 Loss:0.08864 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3075 Loss:0.08356 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3076 Loss:0.09221 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3077 Loss:0.08792 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3078 Loss:0.08528 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3079 Loss:0.08859 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3080 Loss:0.09410 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3081 Loss:0.08432 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3082 Loss:0.08830 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3083 Loss:0.09931 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3084 Loss:0.09053 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3085 Loss:0.08668 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3086 Loss:0.08895 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3087 Loss:0.09350 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3088 Loss:0.08757 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3089 Loss:0.08154 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3090 Loss:0.09507 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3091 Loss:0.09233 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3092 Loss:0.09189 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3093 Loss:0.08963 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3094 Loss:0.09249 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3095 Loss:0.08655 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3096 Loss:0.08615 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3097 Loss:0.09031 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3098 Loss:0.08716 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3099 Loss:0.08931 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3100 Loss:0.09125 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3101 Loss:0.08656 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3102 Loss:0.08613 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3103 Loss:0.08853 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3104 Loss:0.08815 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3105 Loss:0.08866 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3106 Loss:0.08182 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3107 Loss:0.09331 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3108 Loss:0.08677 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3109 Loss:0.08520 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3110 Loss:0.08852 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3111 Loss:0.08701 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3112 Loss:0.09011 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3113 Loss:0.08905 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3114 Loss:0.08724 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3115 Loss:0.09044 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3116 Loss:0.08180 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3117 Loss:0.10447 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3118 Loss:0.08418 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3119 Loss:0.08854 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3120 Loss:0.08694 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3121 Loss:0.08830 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3122 Loss:0.08805 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3123 Loss:0.08799 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3124 Loss:0.07932 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3125 Loss:0.09861 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3126 Loss:0.08067 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3127 Loss:0.09273 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3128 Loss:0.08777 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3129 Loss:0.10097 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3130 Loss:0.08499 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3131 Loss:0.08919 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3132 Loss:0.08725 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3133 Loss:0.08264 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3134 Loss:0.09033 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3135 Loss:0.08711 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3136 Loss:0.08080 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3137 Loss:0.08951 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3138 Loss:0.09056 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3139 Loss:0.08801 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3140 Loss:0.08677 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3141 Loss:0.08888 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3142 Loss:0.09273 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3143 Loss:0.08926 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3144 Loss:0.08636 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3145 Loss:0.08826 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3146 Loss:0.08633 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3147 Loss:0.08596 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3148 Loss:0.08386 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3149 Loss:0.09680 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3150 Loss:0.08408 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3151 Loss:0.09628 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3152 Loss:0.09644 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3153 Loss:0.08123 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3154 Loss:0.08160 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3155 Loss:0.09445 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3156 Loss:0.08992 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3157 Loss:0.09858 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3158 Loss:0.08821 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3159 Loss:0.07990 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3160 Loss:0.09357 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3161 Loss:0.08567 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3162 Loss:0.08862 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3163 Loss:0.08614 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3164 Loss:0.08853 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3165 Loss:0.08417 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3166 Loss:0.09170 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3167 Loss:0.07948 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3168 Loss:0.08616 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3169 Loss:0.09288 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3170 Loss:0.08547 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3171 Loss:0.09061 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3172 Loss:0.08445 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3173 Loss:0.08292 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3174 Loss:0.08260 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3175 Loss:0.09173 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3176 Loss:0.09848 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3177 Loss:0.08170 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3178 Loss:0.08290 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3179 Loss:0.08698 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3180 Loss:0.09045 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3181 Loss:0.08376 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3182 Loss:0.08379 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3183 Loss:0.09002 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3184 Loss:0.08209 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3185 Loss:0.08439 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3186 Loss:0.08088 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3187 Loss:0.10297 (Coord:0.02 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3188 Loss:0.09479 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3189 Loss:0.08945 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3190 Loss:0.08415 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3191 Loss:0.08580 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3192 Loss:0.09232 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3193 Loss:0.08991 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3194 Loss:0.08521 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3195 Loss:0.08820 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3196 Loss:0.08680 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3197 Loss:0.09025 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3198 Loss:0.08931 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3199 Loss:0.08534 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3200 Loss:0.08388 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3201 Loss:0.09771 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3202 Loss:0.08316 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3203 Loss:0.08333 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3204 Loss:0.09131 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3205 Loss:0.08566 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3206 Loss:0.08525 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3207 Loss:0.09185 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3208 Loss:0.08174 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3209 Loss:0.09022 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3210 Loss:0.09118 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3211 Loss:0.08970 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3212 Loss:0.07728 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3213 Loss:0.08712 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3214 Loss:0.08225 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3215 Loss:0.09530 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3216 Loss:0.08058 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3217 Loss:0.08547 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3218 Loss:0.08526 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3219 Loss:0.09038 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3220 Loss:0.08890 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3221 Loss:0.08510 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3222 Loss:0.09361 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3223 Loss:0.08359 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3224 Loss:0.09104 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3225 Loss:0.08016 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3226 Loss:0.07923 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3227 Loss:0.09102 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3228 Loss:0.10477 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3229 Loss:0.09797 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3230 Loss:0.08239 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3231 Loss:0.08336 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3232 Loss:0.09204 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3233 Loss:0.08698 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3234 Loss:0.08699 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3235 Loss:0.08293 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3236 Loss:0.09191 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3237 Loss:0.08479 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3238 Loss:0.08213 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3239 Loss:0.08106 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3240 Loss:0.08895 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3241 Loss:0.09561 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3242 Loss:0.08626 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3243 Loss:0.08414 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3244 Loss:0.08726 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3245 Loss:0.08482 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3246 Loss:0.08261 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3247 Loss:0.08166 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3248 Loss:0.08500 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3249 Loss:0.09024 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3250 Loss:0.08046 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3251 Loss:0.08682 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3252 Loss:0.08133 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3253 Loss:0.09362 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3254 Loss:0.09274 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3255 Loss:0.07882 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3256 Loss:0.08883 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3257 Loss:0.08436 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3258 Loss:0.08390 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3259 Loss:0.09415 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3260 Loss:0.07644 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3261 Loss:0.09099 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3262 Loss:0.08724 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3263 Loss:0.09538 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3264 Loss:0.08304 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3265 Loss:0.08681 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3266 Loss:0.08856 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3267 Loss:0.08259 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3268 Loss:0.08175 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3269 Loss:0.08861 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3270 Loss:0.08407 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3271 Loss:0.08456 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3272 Loss:0.08061 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3273 Loss:0.08634 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3274 Loss:0.08394 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3275 Loss:0.08853 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3276 Loss:0.08962 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3277 Loss:0.08296 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3278 Loss:0.08505 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3279 Loss:0.09195 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3280 Loss:0.09271 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3281 Loss:0.07874 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3282 Loss:0.07639 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3283 Loss:0.08864 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3284 Loss:0.08035 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3285 Loss:0.09424 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3286 Loss:0.08441 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3287 Loss:0.09860 (Coord:0.03 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3288 Loss:0.08262 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3289 Loss:0.07910 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3290 Loss:0.08487 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3291 Loss:0.09233 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3292 Loss:0.10163 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3293 Loss:0.08149 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3294 Loss:0.08393 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3295 Loss:0.08728 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3296 Loss:0.08122 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3297 Loss:0.08496 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3298 Loss:0.07821 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3299 Loss:0.09062 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3300 Loss:0.08555 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3301 Loss:0.08440 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3302 Loss:0.08571 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3303 Loss:0.08536 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3304 Loss:0.08525 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3305 Loss:0.08681 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3306 Loss:0.08451 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3307 Loss:0.08876 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3308 Loss:0.08260 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3309 Loss:0.09037 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3310 Loss:0.11432 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3311 Loss:0.08626 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3312 Loss:0.08097 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3313 Loss:0.08150 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3314 Loss:0.09136 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3315 Loss:0.07989 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3316 Loss:0.08089 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3317 Loss:0.08240 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3318 Loss:0.08723 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3319 Loss:0.09821 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3320 Loss:0.08069 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3321 Loss:0.08764 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3322 Loss:0.08504 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3323 Loss:0.08435 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3324 Loss:0.08622 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3325 Loss:0.08411 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3326 Loss:0.07970 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3327 Loss:0.08979 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3328 Loss:0.08157 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3329 Loss:0.09589 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3330 Loss:0.08145 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3331 Loss:0.08389 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3332 Loss:0.08107 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3333 Loss:0.07903 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3334 Loss:0.08478 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3335 Loss:0.08883 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3336 Loss:0.08539 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3337 Loss:0.08711 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3338 Loss:0.07820 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3339 Loss:0.08541 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3340 Loss:0.08739 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3341 Loss:0.07908 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3342 Loss:0.08475 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3343 Loss:0.08686 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3344 Loss:0.08471 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3345 Loss:0.08106 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3346 Loss:0.08692 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3347 Loss:0.08854 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3348 Loss:0.08226 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3349 Loss:0.08415 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3350 Loss:0.08450 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3351 Loss:0.08317 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3352 Loss:0.08453 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3353 Loss:0.09487 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3354 Loss:0.08204 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3355 Loss:0.09147 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3356 Loss:0.08223 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3357 Loss:0.08070 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3358 Loss:0.09194 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3359 Loss:0.08104 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3360 Loss:0.07869 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3361 Loss:0.08857 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3362 Loss:0.09368 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3363 Loss:0.08399 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3364 Loss:0.08428 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3365 Loss:0.08566 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3366 Loss:0.08116 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3367 Loss:0.08551 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3368 Loss:0.08511 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3369 Loss:0.09091 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3370 Loss:0.08046 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3371 Loss:0.08546 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3372 Loss:0.08560 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3373 Loss:0.08363 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3374 Loss:0.08283 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3375 Loss:0.09661 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3376 Loss:0.07922 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3377 Loss:0.07851 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3378 Loss:0.10933 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3379 Loss:0.08408 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3380 Loss:0.08915 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3381 Loss:0.08142 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3382 Loss:0.08458 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3383 Loss:0.08645 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3384 Loss:0.07950 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3385 Loss:0.08713 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3386 Loss:0.08534 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3387 Loss:0.08457 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3388 Loss:0.08245 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3389 Loss:0.07959 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3390 Loss:0.08837 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3391 Loss:0.08145 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3392 Loss:0.08458 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3393 Loss:0.08007 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3394 Loss:0.09479 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3395 Loss:0.09127 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3396 Loss:0.08636 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3397 Loss:0.08102 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3398 Loss:0.07647 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3399 Loss:0.09095 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3400 Loss:0.08614 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3401 Loss:0.08074 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3402 Loss:0.08806 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3403 Loss:0.08886 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3404 Loss:0.08728 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3405 Loss:0.07884 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3406 Loss:0.09189 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3407 Loss:0.09209 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3408 Loss:0.08304 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3409 Loss:0.08445 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3410 Loss:0.08542 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3411 Loss:0.09333 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3412 Loss:0.07917 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3413 Loss:0.07625 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3414 Loss:0.09130 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3415 Loss:0.08719 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3416 Loss:0.08379 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3417 Loss:0.08812 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3418 Loss:0.08095 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3419 Loss:0.09191 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3420 Loss:0.08400 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3421 Loss:0.08427 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3422 Loss:0.08999 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3423 Loss:0.08327 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3424 Loss:0.08654 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3425 Loss:0.08534 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3426 Loss:0.08546 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3427 Loss:0.07781 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3428 Loss:0.08403 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3429 Loss:0.10134 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3430 Loss:0.07721 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3431 Loss:0.09351 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3432 Loss:0.07855 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3433 Loss:0.07804 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3434 Loss:0.08946 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3435 Loss:0.08424 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3436 Loss:0.07664 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3437 Loss:0.08343 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3438 Loss:0.08349 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3439 Loss:0.08908 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3440 Loss:0.08746 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3441 Loss:0.07933 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3442 Loss:0.09106 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3443 Loss:0.08410 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3444 Loss:0.07807 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3445 Loss:0.08147 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3446 Loss:0.08547 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3447 Loss:0.08286 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3448 Loss:0.08198 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3449 Loss:0.08225 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3450 Loss:0.08446 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3451 Loss:0.08527 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3452 Loss:0.08920 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3453 Loss:0.07819 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3454 Loss:0.08931 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3455 Loss:0.08177 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3456 Loss:0.07597 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3457 Loss:0.11410 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3458 Loss:0.08057 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3459 Loss:0.08520 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3460 Loss:0.09456 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3461 Loss:0.07670 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3462 Loss:0.08293 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3463 Loss:0.07896 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3464 Loss:0.08443 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3465 Loss:0.08305 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3466 Loss:0.07527 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3467 Loss:0.08303 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3468 Loss:0.07962 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3469 Loss:0.08622 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3470 Loss:0.09407 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3471 Loss:0.07765 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3472 Loss:0.07522 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3473 Loss:0.08651 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3474 Loss:0.08349 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3475 Loss:0.08352 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3476 Loss:0.08211 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3477 Loss:0.07508 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3478 Loss:0.09320 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3479 Loss:0.08570 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3480 Loss:0.08403 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3481 Loss:0.07895 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3482 Loss:0.08156 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3483 Loss:0.08378 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3484 Loss:0.08275 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3485 Loss:0.09097 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3486 Loss:0.08061 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3487 Loss:0.08578 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3488 Loss:0.09009 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3489 Loss:0.08074 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3490 Loss:0.07962 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3491 Loss:0.08039 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3492 Loss:0.08647 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3493 Loss:0.07579 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3494 Loss:0.08555 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3495 Loss:0.08678 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3496 Loss:0.09025 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3497 Loss:0.07916 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3498 Loss:0.07539 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3499 Loss:0.08351 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3500 Loss:0.08579 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Saved backup\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3501 Loss:0.08205 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3502 Loss:0.09310 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3503 Loss:0.07855 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3504 Loss:0.08229 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3505 Loss:0.07904 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3506 Loss:0.08280 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3507 Loss:0.08231 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3508 Loss:0.08382 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3509 Loss:0.08505 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3510 Loss:0.07657 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3511 Loss:0.08420 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3512 Loss:0.08603 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3513 Loss:0.08351 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3514 Loss:0.08157 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3515 Loss:0.07992 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3516 Loss:0.08364 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3517 Loss:0.08403 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3518 Loss:0.09270 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3519 Loss:0.07588 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3520 Loss:0.07765 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3521 Loss:0.08299 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3522 Loss:0.08683 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3523 Loss:0.08441 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3524 Loss:0.08183 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3525 Loss:0.08203 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3526 Loss:0.07542 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3527 Loss:0.09467 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3528 Loss:0.08849 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3529 Loss:0.08345 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3530 Loss:0.08209 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3531 Loss:0.08029 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3532 Loss:0.08431 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3533 Loss:0.08726 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3534 Loss:0.07881 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3535 Loss:0.08051 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3536 Loss:0.08175 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3537 Loss:0.08153 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3538 Loss:0.08115 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3539 Loss:0.08160 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3540 Loss:0.08050 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3541 Loss:0.08410 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3542 Loss:0.08427 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3543 Loss:0.07824 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3544 Loss:0.08493 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3545 Loss:0.08873 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3546 Loss:0.07715 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3547 Loss:0.08495 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3548 Loss:0.07996 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3549 Loss:0.08199 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3550 Loss:0.08045 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3551 Loss:0.08315 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3552 Loss:0.07987 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3553 Loss:0.08418 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3554 Loss:0.08223 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3555 Loss:0.10557 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3556 Loss:0.07463 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3557 Loss:0.07920 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3558 Loss:0.07986 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3559 Loss:0.08649 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3560 Loss:0.08786 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3561 Loss:0.08825 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3562 Loss:0.07460 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3563 Loss:0.09214 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3564 Loss:0.07991 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3565 Loss:0.08481 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3566 Loss:0.07582 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3567 Loss:0.08132 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3568 Loss:0.08216 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3569 Loss:0.08583 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3570 Loss:0.07563 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3571 Loss:0.08113 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3572 Loss:0.08439 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3573 Loss:0.08403 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3574 Loss:0.08117 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3575 Loss:0.08404 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3576 Loss:0.07980 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3577 Loss:0.08155 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3578 Loss:0.08620 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3579 Loss:0.08212 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3580 Loss:0.07964 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3581 Loss:0.07846 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3582 Loss:0.08745 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3583 Loss:0.08703 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3584 Loss:0.08240 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3585 Loss:0.07798 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3586 Loss:0.07783 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3587 Loss:0.08555 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3588 Loss:0.07633 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3589 Loss:0.08273 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3590 Loss:0.07934 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3591 Loss:0.10001 (Coord:0.03 Conf:0.07 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3592 Loss:0.07619 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3593 Loss:0.07971 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3594 Loss:0.09090 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3595 Loss:0.07944 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3596 Loss:0.07953 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3597 Loss:0.07880 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3598 Loss:0.08668 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3599 Loss:0.08118 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3600 Loss:0.08337 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3601 Loss:0.07726 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3602 Loss:0.09304 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3603 Loss:0.07784 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3604 Loss:0.08634 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3605 Loss:0.07309 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3606 Loss:0.08446 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3607 Loss:0.07794 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3608 Loss:0.08446 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3609 Loss:0.07889 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3610 Loss:0.07856 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3611 Loss:0.07741 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3612 Loss:0.08350 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3613 Loss:0.07701 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3614 Loss:0.07784 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3615 Loss:0.08615 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3616 Loss:0.08114 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3617 Loss:0.08998 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3618 Loss:0.07580 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3619 Loss:0.07917 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3620 Loss:0.07689 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3621 Loss:0.08621 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3622 Loss:0.08590 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3623 Loss:0.08587 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3624 Loss:0.09482 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3625 Loss:0.07312 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3626 Loss:0.07926 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3627 Loss:0.08726 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3628 Loss:0.07864 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3629 Loss:0.07824 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3630 Loss:0.08041 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3631 Loss:0.08463 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3632 Loss:0.07581 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3633 Loss:0.08022 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3634 Loss:0.07599 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3635 Loss:0.07640 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3636 Loss:0.09598 (Coord:0.03 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3637 Loss:0.07778 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3638 Loss:0.07656 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3639 Loss:0.08323 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3640 Loss:0.08339 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3641 Loss:0.07710 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3642 Loss:0.08082 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3643 Loss:0.08029 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3644 Loss:0.07776 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3645 Loss:0.07635 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3646 Loss:0.08197 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3647 Loss:0.07812 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3648 Loss:0.07963 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3649 Loss:0.07801 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3650 Loss:0.09090 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3651 Loss:0.09353 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3652 Loss:0.07939 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3653 Loss:0.07963 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3654 Loss:0.08417 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3655 Loss:0.07904 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3656 Loss:0.08149 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3657 Loss:0.07323 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3658 Loss:0.07739 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3659 Loss:0.09243 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3660 Loss:0.07758 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3661 Loss:0.07934 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3662 Loss:0.08238 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3663 Loss:0.08303 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3664 Loss:0.08398 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3665 Loss:0.08128 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3666 Loss:0.08744 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3667 Loss:0.08190 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3668 Loss:0.07543 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3669 Loss:0.07600 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3670 Loss:0.07945 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3671 Loss:0.07517 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3672 Loss:0.08703 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3673 Loss:0.08296 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3674 Loss:0.07739 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3675 Loss:0.07990 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3676 Loss:0.08232 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3677 Loss:0.07913 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3678 Loss:0.07580 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3679 Loss:0.07678 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3680 Loss:0.07826 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3681 Loss:0.09076 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3682 Loss:0.08062 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3683 Loss:0.08638 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3684 Loss:0.07682 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3685 Loss:0.07688 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3686 Loss:0.07945 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3687 Loss:0.08584 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3688 Loss:0.08344 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3689 Loss:0.07982 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3690 Loss:0.08926 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3691 Loss:0.07783 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3692 Loss:0.08060 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3693 Loss:0.07848 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3694 Loss:0.07910 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3695 Loss:0.07737 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3696 Loss:0.08262 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3697 Loss:0.08264 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3698 Loss:0.07425 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3699 Loss:0.09531 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3700 Loss:0.08003 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3701 Loss:0.07908 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3702 Loss:0.08589 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3703 Loss:0.07702 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3704 Loss:0.07197 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3705 Loss:0.09132 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3706 Loss:0.08358 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3707 Loss:0.07496 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3708 Loss:0.08084 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3709 Loss:0.09005 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3710 Loss:0.08148 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3711 Loss:0.07297 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3712 Loss:0.09252 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3713 Loss:0.07586 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3714 Loss:0.08616 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3715 Loss:0.08209 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3716 Loss:0.07856 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3717 Loss:0.08186 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3718 Loss:0.08406 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3719 Loss:0.08434 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3720 Loss:0.08107 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3721 Loss:0.08203 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3722 Loss:0.07922 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3723 Loss:0.08231 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3724 Loss:0.07447 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3725 Loss:0.08316 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3726 Loss:0.08056 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3727 Loss:0.08037 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3728 Loss:0.08231 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3729 Loss:0.08349 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3730 Loss:0.07512 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3731 Loss:0.08220 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3732 Loss:0.08631 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3733 Loss:0.07720 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3734 Loss:0.08031 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3735 Loss:0.09075 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3736 Loss:0.08206 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3737 Loss:0.07693 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3738 Loss:0.09060 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3739 Loss:0.07945 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3740 Loss:0.07811 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3741 Loss:0.08551 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3742 Loss:0.07661 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3743 Loss:0.07859 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3744 Loss:0.08078 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3745 Loss:0.08161 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3746 Loss:0.08328 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3747 Loss:0.07849 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3748 Loss:0.07881 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3749 Loss:0.07637 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3750 Loss:0.07957 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3751 Loss:0.08570 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3752 Loss:0.08144 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3753 Loss:0.07946 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3754 Loss:0.07419 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3755 Loss:0.07888 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3756 Loss:0.07832 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3757 Loss:0.07657 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3758 Loss:0.07957 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3759 Loss:0.08553 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3760 Loss:0.07891 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3761 Loss:0.07443 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3762 Loss:0.08789 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3763 Loss:0.08468 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3764 Loss:0.07470 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3765 Loss:0.08796 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3766 Loss:0.07392 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3767 Loss:0.08230 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3768 Loss:0.07727 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3769 Loss:0.07793 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3770 Loss:0.08085 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3771 Loss:0.07403 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3772 Loss:0.08329 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3773 Loss:0.07668 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3774 Loss:0.08578 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3775 Loss:0.07757 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3776 Loss:0.08178 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3777 Loss:0.07891 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3778 Loss:0.07702 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3779 Loss:0.08603 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3780 Loss:0.08022 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3781 Loss:0.07971 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3782 Loss:0.07754 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3783 Loss:0.08010 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3784 Loss:0.07897 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3785 Loss:0.08311 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3786 Loss:0.08121 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3787 Loss:0.07482 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3788 Loss:0.07922 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3789 Loss:0.07541 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3790 Loss:0.08662 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3791 Loss:0.08836 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3792 Loss:0.08011 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3793 Loss:0.07798 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3794 Loss:0.07984 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3795 Loss:0.07780 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3796 Loss:0.07937 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3797 Loss:0.08217 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3798 Loss:0.08511 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3799 Loss:0.08092 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3800 Loss:0.07240 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3801 Loss:0.08090 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3802 Loss:0.08460 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3803 Loss:0.07787 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3804 Loss:0.07852 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3805 Loss:0.08663 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3806 Loss:0.07948 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3807 Loss:0.07367 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3808 Loss:0.09262 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3809 Loss:0.07444 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3810 Loss:0.07545 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3811 Loss:0.08566 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3812 Loss:0.08450 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3813 Loss:0.07293 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3814 Loss:0.07892 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3815 Loss:0.08374 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3816 Loss:0.08351 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3817 Loss:0.07236 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3818 Loss:0.07721 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3819 Loss:0.09254 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3820 Loss:0.07968 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3821 Loss:0.08297 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3822 Loss:0.07713 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3823 Loss:0.08320 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3824 Loss:0.08068 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3825 Loss:0.07439 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3826 Loss:0.07197 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3827 Loss:0.08995 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3828 Loss:0.07558 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3829 Loss:0.08520 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3830 Loss:0.07323 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3831 Loss:0.07599 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3832 Loss:0.09388 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3833 Loss:0.07935 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3834 Loss:0.07260 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3835 Loss:0.07291 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3836 Loss:0.08144 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3837 Loss:0.07658 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3838 Loss:0.08238 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3839 Loss:0.08367 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3840 Loss:0.07003 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3841 Loss:0.08386 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3842 Loss:0.07548 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3843 Loss:0.09962 (Coord:0.03 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3844 Loss:0.07416 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3845 Loss:0.07725 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3846 Loss:0.07539 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3847 Loss:0.08602 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3848 Loss:0.07532 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3849 Loss:0.07518 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3850 Loss:0.08057 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3851 Loss:0.07694 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3852 Loss:0.08049 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3853 Loss:0.07338 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3854 Loss:0.09213 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3855 Loss:0.07143 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3856 Loss:0.07718 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3857 Loss:0.08003 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3858 Loss:0.08476 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3859 Loss:0.08008 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3860 Loss:0.08098 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3861 Loss:0.08082 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3862 Loss:0.07692 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3863 Loss:0.08198 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3864 Loss:0.07630 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3865 Loss:0.07948 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3866 Loss:0.07733 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3867 Loss:0.07501 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3868 Loss:0.08169 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3869 Loss:0.07916 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3870 Loss:0.07824 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3871 Loss:0.07632 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3872 Loss:0.08330 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3873 Loss:0.07932 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3874 Loss:0.07911 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3875 Loss:0.07498 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3876 Loss:0.07723 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3877 Loss:0.07982 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3878 Loss:0.07487 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3879 Loss:0.07136 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3880 Loss:0.08881 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3881 Loss:0.07313 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3882 Loss:0.07643 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3883 Loss:0.08426 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3884 Loss:0.07513 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3885 Loss:0.07208 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3886 Loss:0.08106 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3887 Loss:0.07921 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3888 Loss:0.07400 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3889 Loss:0.07786 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3890 Loss:0.08081 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (608, 608)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3891 Loss:0.07529 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3892 Loss:0.08448 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3893 Loss:0.07733 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3894 Loss:0.07418 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3895 Loss:0.08210 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3896 Loss:0.07904 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3897 Loss:0.07984 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3898 Loss:0.07567 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3899 Loss:0.08110 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3900 Loss:0.08005 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3901 Loss:0.07745 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3902 Loss:0.07566 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3903 Loss:0.07747 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3904 Loss:0.07389 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3905 Loss:0.07815 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3906 Loss:0.08108 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3907 Loss:0.07271 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3908 Loss:0.08154 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3909 Loss:0.07811 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3910 Loss:0.07665 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3911 Loss:0.07448 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3912 Loss:0.08431 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3913 Loss:0.07840 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3914 Loss:0.07652 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3915 Loss:0.07913 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3916 Loss:0.07839 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3917 Loss:0.09039 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3918 Loss:0.07541 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3919 Loss:0.07480 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3920 Loss:0.07981 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3921 Loss:0.07723 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3922 Loss:0.07668 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3923 Loss:0.07554 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3924 Loss:0.08121 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3925 Loss:0.08497 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3926 Loss:0.07260 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3927 Loss:0.07845 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3928 Loss:0.07955 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3929 Loss:0.07262 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3930 Loss:0.08000 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3931 Loss:0.07538 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3932 Loss:0.07638 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3933 Loss:0.07906 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3934 Loss:0.07256 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3935 Loss:0.07951 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3936 Loss:0.07701 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3937 Loss:0.08945 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3938 Loss:0.07897 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3939 Loss:0.07470 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3940 Loss:0.07794 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3941 Loss:0.07947 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3942 Loss:0.07422 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3943 Loss:0.07930 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3944 Loss:0.08197 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3945 Loss:0.08312 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3946 Loss:0.07509 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3947 Loss:0.08084 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3948 Loss:0.07451 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3949 Loss:0.07515 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3950 Loss:0.08415 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3951 Loss:0.07828 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3952 Loss:0.07077 (Coord:0.01 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3953 Loss:0.08080 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3954 Loss:0.08177 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3955 Loss:0.07983 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3956 Loss:0.07271 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3957 Loss:0.07679 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3958 Loss:0.07420 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3959 Loss:0.07983 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3960 Loss:0.07907 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3961 Loss:0.08025 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3962 Loss:0.07094 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3963 Loss:0.07128 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3964 Loss:0.08794 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3965 Loss:0.07813 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3966 Loss:0.07470 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3967 Loss:0.08567 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3968 Loss:0.07938 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3969 Loss:0.07217 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3970 Loss:0.07622 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3971 Loss:0.08149 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3972 Loss:0.07604 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3973 Loss:0.07740 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3974 Loss:0.07577 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3975 Loss:0.08191 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3976 Loss:0.08187 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3977 Loss:0.07296 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3978 Loss:0.08457 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3979 Loss:0.08105 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3980 Loss:0.08825 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3981 Loss:0.07676 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3982 Loss:0.08073 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3983 Loss:0.07411 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3984 Loss:0.07760 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3985 Loss:0.07224 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3986 Loss:0.08481 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3987 Loss:0.07550 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3988 Loss:0.07383 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3989 Loss:0.08070 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3990 Loss:0.07262 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3991 Loss:0.08940 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3992 Loss:0.08867 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3993 Loss:0.07447 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3994 Loss:0.07185 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3995 Loss:0.07473 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3996 Loss:0.07779 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3997 Loss:0.07754 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3998 Loss:0.08321 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 3999 Loss:0.08060 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4000 Loss:0.07482 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Saved backup\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4001 Loss:0.07957 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4002 Loss:0.07328 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4003 Loss:0.08497 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4004 Loss:0.07417 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4005 Loss:0.08412 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4006 Loss:0.07957 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4007 Loss:0.08133 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4008 Loss:0.07260 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4009 Loss:0.07741 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4010 Loss:0.08442 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4011 Loss:0.07474 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4012 Loss:0.07687 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4013 Loss:0.08686 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4014 Loss:0.07742 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4015 Loss:0.07842 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4016 Loss:0.07123 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4017 Loss:0.07655 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4018 Loss:0.07835 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4019 Loss:0.07759 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4020 Loss:0.07546 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4021 Loss:0.07298 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4022 Loss:0.07591 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4023 Loss:0.07298 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4024 Loss:0.09734 (Coord:0.03 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4025 Loss:0.07420 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4026 Loss:0.07769 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4027 Loss:0.07746 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4028 Loss:0.07223 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4029 Loss:0.07930 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4030 Loss:0.07652 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (576, 576)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4031 Loss:0.07742 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4032 Loss:0.08089 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4033 Loss:0.08402 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4034 Loss:0.06969 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4035 Loss:0.07446 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4036 Loss:0.09043 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4037 Loss:0.07054 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4038 Loss:0.07926 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4039 Loss:0.07430 (Coord:0.01 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4040 Loss:0.08258 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4041 Loss:0.07556 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4042 Loss:0.08160 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4043 Loss:0.07844 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4044 Loss:0.08458 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4045 Loss:0.07312 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4046 Loss:0.07625 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4047 Loss:0.07567 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4048 Loss:0.07994 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4049 Loss:0.07729 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4050 Loss:0.07569 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4051 Loss:0.07433 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4052 Loss:0.07922 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4053 Loss:0.07364 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4054 Loss:0.07776 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4055 Loss:0.08189 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4056 Loss:0.07852 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4057 Loss:0.07839 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4058 Loss:0.08180 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4059 Loss:0.07903 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4060 Loss:0.08386 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4061 Loss:0.08044 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4062 Loss:0.07029 (Coord:0.01 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4063 Loss:0.07519 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4064 Loss:0.08289 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4065 Loss:0.06831 (Coord:0.01 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4066 Loss:0.07990 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4067 Loss:0.09552 (Coord:0.03 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4068 Loss:0.07343 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4069 Loss:0.07569 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4070 Loss:0.07842 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4071 Loss:0.07358 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4072 Loss:0.07701 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4073 Loss:0.07512 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4074 Loss:0.07289 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4075 Loss:0.08407 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4076 Loss:0.07686 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4077 Loss:0.08598 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4078 Loss:0.07730 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4079 Loss:0.08250 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4080 Loss:0.07363 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4081 Loss:0.07832 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4082 Loss:0.09461 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4083 Loss:0.07455 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4084 Loss:0.07415 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4085 Loss:0.07509 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4086 Loss:0.08167 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4087 Loss:0.07856 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4088 Loss:0.07741 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4089 Loss:0.07206 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4090 Loss:0.07549 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4091 Loss:0.07998 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4092 Loss:0.08166 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4093 Loss:0.07289 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4094 Loss:0.07392 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4095 Loss:0.07529 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4096 Loss:0.07250 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4097 Loss:0.08676 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4098 Loss:0.07604 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4099 Loss:0.07293 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4100 Loss:0.07684 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4101 Loss:0.07139 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4102 Loss:0.07743 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4103 Loss:0.07432 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4104 Loss:0.07529 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4105 Loss:0.07259 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4106 Loss:0.08015 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4107 Loss:0.08107 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4108 Loss:0.07612 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4109 Loss:0.07788 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4110 Loss:0.07403 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4111 Loss:0.07912 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4112 Loss:0.07587 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4113 Loss:0.07403 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4114 Loss:0.07177 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4115 Loss:0.08025 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4116 Loss:0.07838 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4117 Loss:0.08148 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4118 Loss:0.07261 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4119 Loss:0.07465 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4120 Loss:0.07376 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4121 Loss:0.08786 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4122 Loss:0.07217 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4123 Loss:0.07939 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4124 Loss:0.07605 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4125 Loss:0.07433 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4126 Loss:0.07452 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4127 Loss:0.07057 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4128 Loss:0.07840 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4129 Loss:0.07833 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4130 Loss:0.07671 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4131 Loss:0.07353 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4132 Loss:0.07484 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4133 Loss:0.07380 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4134 Loss:0.07591 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4135 Loss:0.07843 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4136 Loss:0.07562 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4137 Loss:0.07240 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4138 Loss:0.08012 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4139 Loss:0.07456 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4140 Loss:0.08281 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4141 Loss:0.07246 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4142 Loss:0.07846 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4143 Loss:0.07821 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4144 Loss:0.07831 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4145 Loss:0.07439 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4146 Loss:0.08040 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4147 Loss:0.07589 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4148 Loss:0.09125 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4149 Loss:0.06728 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4150 Loss:0.07261 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4151 Loss:0.07624 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4152 Loss:0.07580 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4153 Loss:0.08642 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4154 Loss:0.07369 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4155 Loss:0.07414 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4156 Loss:0.07555 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4157 Loss:0.07735 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4158 Loss:0.07596 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4159 Loss:0.07541 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4160 Loss:0.08083 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4161 Loss:0.07947 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4162 Loss:0.07047 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4163 Loss:0.07839 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4164 Loss:0.06993 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4165 Loss:0.07366 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4166 Loss:0.07928 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4167 Loss:0.07318 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4168 Loss:0.07524 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4169 Loss:0.07054 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4170 Loss:0.08165 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4171 Loss:0.07387 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4172 Loss:0.06696 (Coord:0.01 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4173 Loss:0.07845 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4174 Loss:0.07362 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4175 Loss:0.08039 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4176 Loss:0.08559 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4177 Loss:0.07364 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4178 Loss:0.07562 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4179 Loss:0.07075 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4180 Loss:0.08489 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (480, 480)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4181 Loss:0.08135 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4182 Loss:0.08692 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4183 Loss:0.07903 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4184 Loss:0.07102 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4185 Loss:0.08201 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4186 Loss:0.07723 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4187 Loss:0.07118 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4188 Loss:0.07512 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4189 Loss:0.07421 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4190 Loss:0.07380 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (320, 320)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4191 Loss:0.08225 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4192 Loss:0.07373 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4193 Loss:0.07396 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4194 Loss:0.07520 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4195 Loss:0.07494 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4196 Loss:0.07605 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4197 Loss:0.07298 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4198 Loss:0.06957 (Coord:0.01 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4199 Loss:0.08383 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4200 Loss:0.08921 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4201 Loss:0.07416 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4202 Loss:0.07684 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4203 Loss:0.07795 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4204 Loss:0.08091 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4205 Loss:0.07739 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4206 Loss:0.06880 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4207 Loss:0.07107 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4208 Loss:0.07691 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4209 Loss:0.06951 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4210 Loss:0.08255 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4211 Loss:0.07502 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4212 Loss:0.07143 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4213 Loss:0.07750 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4214 Loss:0.07456 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4215 Loss:0.07368 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4216 Loss:0.07408 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4217 Loss:0.07954 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4218 Loss:0.07235 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4219 Loss:0.07342 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4220 Loss:0.07996 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4221 Loss:0.07422 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4222 Loss:0.07304 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4223 Loss:0.07310 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4224 Loss:0.07042 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4225 Loss:0.07977 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4226 Loss:0.07788 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4227 Loss:0.07290 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4228 Loss:0.07524 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4229 Loss:0.07269 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4230 Loss:0.07525 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4231 Loss:0.07012 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4232 Loss:0.07180 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4233 Loss:0.07486 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4234 Loss:0.07571 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4235 Loss:0.07604 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4236 Loss:0.07437 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4237 Loss:0.07034 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4238 Loss:0.08542 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4239 Loss:0.07051 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4240 Loss:0.07190 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (416, 416)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4241 Loss:0.07419 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4242 Loss:0.07061 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4243 Loss:0.07780 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4244 Loss:0.07672 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4245 Loss:0.07564 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4246 Loss:0.07579 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4247 Loss:0.07246 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4248 Loss:0.07157 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4249 Loss:0.07360 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4250 Loss:0.07703 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4251 Loss:0.07056 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4252 Loss:0.07702 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4253 Loss:0.07651 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4254 Loss:0.07526 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4255 Loss:0.08150 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4256 Loss:0.07594 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4257 Loss:0.06968 (Coord:0.01 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4258 Loss:0.08804 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4259 Loss:0.07222 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4260 Loss:0.08301 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4261 Loss:0.07132 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4262 Loss:0.06992 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4263 Loss:0.07635 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4264 Loss:0.07183 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4265 Loss:0.07494 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4266 Loss:0.08945 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4267 Loss:0.07249 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4268 Loss:0.07024 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4269 Loss:0.06849 (Coord:0.01 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4270 Loss:0.07514 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4271 Loss:0.07869 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4272 Loss:0.06985 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4273 Loss:0.08007 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4274 Loss:0.06710 (Coord:0.01 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4275 Loss:0.07863 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4276 Loss:0.06742 (Coord:0.01 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4277 Loss:0.08434 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4278 Loss:0.08480 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4279 Loss:0.06770 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4280 Loss:0.07669 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4281 Loss:0.08366 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4282 Loss:0.07336 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4283 Loss:0.07279 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4284 Loss:0.08210 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4285 Loss:0.07688 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4286 Loss:0.07269 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4287 Loss:0.06861 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4288 Loss:0.07152 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4289 Loss:0.06997 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4290 Loss:0.08290 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4291 Loss:0.07174 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4292 Loss:0.07278 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4293 Loss:0.07162 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4294 Loss:0.08118 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4295 Loss:0.07038 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4296 Loss:0.07169 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4297 Loss:0.08182 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4298 Loss:0.08023 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4299 Loss:0.07891 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4300 Loss:0.07433 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (352, 352)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4301 Loss:0.07278 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4302 Loss:0.07646 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4303 Loss:0.08737 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4304 Loss:0.07203 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4305 Loss:0.07612 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4306 Loss:0.07061 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4307 Loss:0.07365 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4308 Loss:0.07066 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4309 Loss:0.08330 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4310 Loss:0.07156 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4311 Loss:0.07757 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4312 Loss:0.07229 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4313 Loss:0.07386 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4314 Loss:0.06795 (Coord:0.01 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4315 Loss:0.08901 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4316 Loss:0.07198 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4317 Loss:0.07452 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4318 Loss:0.08321 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4319 Loss:0.07265 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4320 Loss:0.07822 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (544, 544)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4321 Loss:0.07229 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4322 Loss:0.07388 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4323 Loss:0.06900 (Coord:0.01 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4324 Loss:0.07041 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4325 Loss:0.07688 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4326 Loss:0.08176 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4327 Loss:0.07658 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4328 Loss:0.07251 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4329 Loss:0.06898 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4330 Loss:0.07796 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (384, 384)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4331 Loss:0.07253 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4332 Loss:0.07978 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4333 Loss:0.07489 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4334 Loss:0.08005 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4335 Loss:0.07272 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4336 Loss:0.07422 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4337 Loss:0.07388 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4338 Loss:0.07932 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4339 Loss:0.07574 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4340 Loss:0.07165 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (512, 512)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4341 Loss:0.07443 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4342 Loss:0.07298 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4343 Loss:0.07326 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4344 Loss:0.08414 (Coord:0.02 Conf:0.06 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4345 Loss:0.08344 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4346 Loss:0.07352 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4347 Loss:0.07579 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4348 Loss:0.06670 (Coord:0.01 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4349 Loss:0.07499 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4350 Loss:0.07261 (Coord:0.02 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[37mINFO      \u001b[00m Resizing network (448, 448)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4351 Loss:0.06734 (Coord:0.01 Conf:0.05 Cls:0.01)\n",
            "\u001b[01m\u001b[34mTRAIN     \u001b[00m 4352 Loss:0.09318 (Coord:0.02 Conf:0.06 Cls:0.01)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0c3JwcjONhL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d63f4e8f-35b5-4fc3-ff24-8feccf9eaa3c"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktaGzyjBSbsR",
        "colab_type": "text"
      },
      "source": [
        "# Perform inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18sSCrQ5RxJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile objectDetection-lightnet/example/bin/test.py\n",
        "\n",
        "#!/usr/bin/env python\n",
        "import os\n",
        "import argparse\n",
        "import logging\n",
        "from statistics import mean\n",
        "import torch\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import lightnet as ln\n",
        "import brambox as bb\n",
        "from datasetPerso import valveDataset\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "log = logging.getLogger('lightnet.VOC.test')\n",
        "\n",
        "\n",
        "class TestEngine:\n",
        "    def __init__(self, params, dataloader, **kwargs):\n",
        "        self.params = params\n",
        "        self.dataloader = dataloader\n",
        "\n",
        "        # extract data from params\n",
        "        self.post = params.post\n",
        "        self.loss = params.loss\n",
        "        self.network = params.network\n",
        "\n",
        "        # Setting kwargs\n",
        "        for k, v in kwargs.items():\n",
        "            if not hasattr(self, k):\n",
        "                setattr(self, k, v)\n",
        "            else:\n",
        "                log.error('{k} attribute already exists on TestEngine, not overwriting with `{v}`')\n",
        "\n",
        "    def __call__(self):\n",
        "        self.params.to(self.device)\n",
        "        self.network.eval()\n",
        "        self.loss.eval()    # This is necessary so the loss doesnt use its 'prefill' rule\n",
        "\n",
        "        if self.loss_format == 'none':\n",
        "            anno, det = self.test_none()\n",
        "        else:\n",
        "            anno, det = self.test_loss()\n",
        "\n",
        "        aps = []\n",
        "        for c in tqdm(self.params.class_label_map):\n",
        "            anno_c = anno[anno.class_label == c]\n",
        "            det_c = det[det.class_label == c]\n",
        "\n",
        "            # By default brambox considers ignored annos as regions -> we want to consider them as annos still\n",
        "            matched_det = bb.stat.match_det(det_c, anno_c, 0.5, criteria=bb.stat.coordinates.iou, ignore=bb.stat.IgnoreMethod.SINGLE)\n",
        "            pr = bb.stat.pr(matched_det, anno_c)\n",
        "\n",
        "            aps.append(bb.stat.ap(pr))\n",
        "\n",
        "        m_ap = round(100 * mean(aps), 2)\n",
        "        print(f'mAP: {m_ap:.2f}%')\n",
        "\n",
        "        if self.detection is not None:\n",
        "            def get_img_dim(name):\n",
        "                root = Path(r\"data/images/valves/\")\n",
        "                with Image.open(Path.joinpath(root, id + \".png\")) as img:\n",
        "                    return img.size\n",
        "\n",
        "            rlb = ln.data.transform.ReverseLetterbox(self.params.input_dimension, get_img_dim)\n",
        "            det = rlb(det)\n",
        "            bb.io.save(det, 'pandas', self.detection)\n",
        "\n",
        "    def test_none(self):\n",
        "        anno, det = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for idx, (data, target) in enumerate(tqdm(self.dataloader)):\n",
        "                data = data.to(self.device)\n",
        "                output = self.network(data)\n",
        "                output = self.post(output)\n",
        "\n",
        "                output.image = pd.Categorical.from_codes(output.image, dtype=target.image.dtype)\n",
        "                anno.append(target)\n",
        "                det.append(output)\n",
        "\n",
        "        anno = bb.util.concat(anno, ignore_index=True, sort=False)\n",
        "        det = bb.util.concat(det, ignore_index=True, sort=False)\n",
        "        return anno, det\n",
        "\n",
        "    def test_loss(self):\n",
        "        loss_dict = {'tot': [], 'coord': [], 'conf': [], 'cls': []}\n",
        "        anno, det = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for idx, (data, target) in enumerate(tqdm(self.dataloader)):\n",
        "                data = data.to(self.device)\n",
        "                output = self.network(data)\n",
        "                loss = self.loss(output, target)\n",
        "                output = self.post(output)\n",
        "\n",
        "                num_img = data.shape[0]\n",
        "                loss_dict['tot'].append(self.loss.loss_tot.item() * num_img)\n",
        "                loss_dict['coord'].append(self.loss.loss_coord.item() * num_img)\n",
        "                loss_dict['conf'].append(self.loss.loss_conf.item() * num_img)\n",
        "                loss_dict['cls'].append(self.loss.loss_cls.item() * num_img)\n",
        "\n",
        "                output.image = pd.Categorical.from_codes(output.image, dtype=target.image.dtype)\n",
        "                anno.append(target)\n",
        "                det.append(output)\n",
        "\n",
        "        anno = bb.util.concat(anno, ignore_index=True, sort=False)\n",
        "        det = bb.util.concat(det, ignore_index=True, sort=False)\n",
        "\n",
        "        loss_tot = sum(loss_dict['tot']) / len(anno.image.cat.categories)\n",
        "        loss_coord = sum(loss_dict['coord']) / len(anno.image.cat.categories)\n",
        "        loss_conf = sum(loss_dict['conf']) / len(anno.image.cat.categories)\n",
        "        loss_cls = sum(loss_dict['cls']) / len(anno.image.cat.categories)\n",
        "        if self.loss == 'percent':\n",
        "            loss_coord *= 100 / loss_tot\n",
        "            loss_conf *= 100 / loss_tot\n",
        "            loss_cls *= 100 / loss_tot\n",
        "            log.info(f'Loss:{loss_tot:.5f} (Coord:{loss_coord:.2f}% Conf:{loss_conf:.2f}% Class:{loss_cls:.2f}%)')\n",
        "        else:\n",
        "            log.info(f'Loss:{loss_tot:.5f} (Coord:{loss_coord:.2f} Conf:{loss_conf:.2f} Class:{loss_cls:.2f})')\n",
        "\n",
        "        return anno, det\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description='Test trained network',\n",
        "        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n",
        "    )\n",
        "    parser.add_argument('weight', help='Path to weight file')\n",
        "    parser.add_argument('-n', '--network', help='network config file', required=True)\n",
        "    parser.add_argument('-c', '--cuda', action='store_true', help='Use cuda')\n",
        "    parser.add_argument('-t', '--thresh', help='Detection Threshold', type=float, default=None)\n",
        "    parser.add_argument('-l', '--loss', help='How to display loss', choices=['abs', 'percent', 'none'], default='abs')\n",
        "    parser.add_argument('-a', '--anno', help='annotation folder', default='./data')\n",
        "    parser.add_argument('-d', '--det', help='Detection pandas file', default=None)\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Parse arguments\n",
        "    device = torch.device('cpu')\n",
        "    if args.cuda:\n",
        "        if torch.cuda.is_available():\n",
        "            log.debug('CUDA enabled')\n",
        "            device = torch.device('cuda')\n",
        "        else:\n",
        "            log.error('CUDA not available')\n",
        "\n",
        "    params = ln.engine.HyperParameters.from_file(args.network)\n",
        "    if args.weight.endswith('.state.pt'):\n",
        "        params.load(args.weight)\n",
        "    else:\n",
        "        params.network.load(args.weight)\n",
        "\n",
        "    if args.thresh is not None: # Overwrite threshold\n",
        "        params.post[0].conf_thresh = args.thresh\n",
        "\n",
        "    # Dataloader\n",
        "    dataPath = Path(args.anno)\n",
        "    testing_dataloader = torch.utils.data.DataLoader(\n",
        "        valveDataset(dataPath, params, False),\n",
        "        batch_size = params.mini_batch_size,\n",
        "        shuffle = True,\n",
        "        drop_last = True,\n",
        "        num_workers = 1,\n",
        "        pin_memory = True,\n",
        "        collate_fn = ln.data.brambox_collate,\n",
        "    )\n",
        "\n",
        "    # Start test\n",
        "    eng = TestEngine(\n",
        "        params, testing_dataloader,\n",
        "        device=device,\n",
        "        loss_format=args.loss,\n",
        "        detection=args.det,\n",
        "    )\n",
        "    eng()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxMZPQuISlag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python objectDetection-lightnet/example/bin/test.py \"objectDetection-lightnet/backup/weights_5000.state.pt\" -n \"objectDetection-lightnet/example/cfg/yolo.py\" -a \"objectDetection-lightnet/data/images/valves\" --cuda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVajlDO7eTtj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}